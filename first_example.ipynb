{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAPHIC_DEVICE = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAPHIC_DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = [189, 170, 189, 163, 183, 171, 185,\n",
    "168, 173, 183, 173, 173, 175, 178,\n",
    "183, 193, 178, 173, 174, 183, 183,\n",
    "180, 168, 180, 170, 178, 182, 180,\n",
    "183, 178, 182, 188, 175, 179, 183,\n",
    "193, 182, 183, 177, 185, 188, 188,\n",
    "182, 185, 191, 183]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_tensor = torch.tensor(heights, dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = torch.zeros(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor2 = torch.ones(1, 4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nparr = np.arange(10, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nparr.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_tensor = torch.from_numpy(nparr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_in_feet = heights_tensor / 30.48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_2_measures = torch.cat([heights_tensor, heights_in_feet])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_2_measures.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_reshaped = heights_2_measures.reshape(2, 46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_reshaped.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, indices = heights_reshaped.max(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2)\n",
    "transform = T.Compose(\n",
    "    [\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([.5], [.5])\n",
    "    ]\n",
    ")\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='.',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = torchvision.datasets.FashionMNIST(\n",
    "    root='.',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "text_labels=['t-shirt', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=300, figsize=(8,4))\n",
    "for i in range(24):\n",
    "    ax = plt.subplot(3, 8, i+1)\n",
    "    img = train_set[i][0]\n",
    "    img = img/2 + .5\n",
    "    img = img.reshape(28, 28)\n",
    "    plt.imshow(img, cmap='binary')\n",
    "    plt.axis('off')\n",
    "    plt.title(text_labels[train_set[i][1]], fontsize=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_train_set = [x for x in train_set if x[1] in (0, 9)]\n",
    "binary_test_set = [x for x in test_set if x[1] in (0, 9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils\n",
    "import torch.utils.data\n",
    "torch.manual_seed(2)\n",
    "batch_size = 64\n",
    "binary_train_loader = torch.utils.data.DataLoader(binary_train_set, batch_size=batch_size, shuffle=True)\n",
    "binary_test_loader = torch.utils.data.DataLoader(binary_test_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_model = nn.Sequential(\n",
    "    nn.Linear(28 ** 2, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 1),\n",
    "    nn.Dropout(p=.25),\n",
    "    nn.Sigmoid()\n",
    ").to(GRAPHIC_DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = .001\n",
    "optimizer = torch.optim.Adam(binary_model.parameters(), lr=lr)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    tloss = 0\n",
    "    for n, (imgs, labels) in enumerate(binary_train_loader):\n",
    "        imgs = imgs.reshape(-1, 28**2).to(GRAPHIC_DEVICE)\n",
    "        labels = torch.FloatTensor([x if x==0 else 1 for x in labels]).reshape(-1, 1).to(GRAPHIC_DEVICE)\n",
    "        preds = binary_model(imgs)\n",
    "        loss = loss_fn(preds, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tloss += loss.detach()\n",
    "    tloss /= n\n",
    "    print(f\"at epoch {i}, loss is {tloss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for imgs, labels in binary_test_loader:\n",
    "    imgs = imgs.reshape(-1, 28**2).to(GRAPHIC_DEVICE)\n",
    "    labels = torch.FloatTensor([x if x==0 else 1 for x in labels]).reshape(-1, 1).to(GRAPHIC_DEVICE)\n",
    "    preds = binary_model(imgs)\n",
    "    pred10 = torch.where(preds > .5, 1, 0)\n",
    "    correct = (pred10 == labels)\n",
    "    results.append(correct.detach().cpu().numpy().mean())\n",
    "accuracy = np.array(results).mean()\n",
    "print(f\"the accuracy of the predictions is {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2)\n",
    "train_set, val_set = torch.utils.data.random_split(train_set, [50000, 10000])\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, shuffle=True, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, shuffle=True, batch_size=batch_size)\n",
    "model=nn.Sequential(\n",
    "nn.Linear(28*28,256),\n",
    "nn.ReLU(),\n",
    "nn.Linear(256,128),\n",
    "nn.ReLU(),\n",
    "nn.Linear(128,64),\n",
    "nn.ReLU(),\n",
    "nn.Linear(64,10)\n",
    ").to(GRAPHIC_DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStop:\n",
    "    def __init__(self, patience=10):\n",
    "        self.patience = patience\n",
    "        self.steps = 0\n",
    "        self.min_loss = float('inf')\n",
    "\n",
    "    def stop(self, val_loss):\n",
    "        if val_loss < self.min_loss:\n",
    "            self.min_loss = val_loss\n",
    "            self.steps = 0\n",
    "        elif val_loss >= self.min_loss:\n",
    "            self.steps += 1\n",
    "        if self.steps >= self.patience:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopper = EarlyStop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = .001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch():\n",
    "    tloss = 0\n",
    "    for n, (imgs, labels) in enumerate(train_loader):\n",
    "        imgs = imgs.reshape(-1, 28 ** 2).to(GRAPHIC_DEVICE)\n",
    "        labels = labels.reshape(-1, ).to(GRAPHIC_DEVICE)\n",
    "        preds = model(imgs)\n",
    "        loss = loss_fn(preds, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tloss += loss.detach()\n",
    "    return tloss / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_epoch():\n",
    "    vloss = 0\n",
    "    for n, (imgs, labels) in enumerate(val_loader):\n",
    "        imgs = imgs.reshape(-1, 28 ** 2).to(GRAPHIC_DEVICE)\n",
    "        labels = labels.reshape(-1, ).to(GRAPHIC_DEVICE)\n",
    "        preds = model(imgs)\n",
    "        loss = loss_fn(preds, labels)\n",
    "        vloss += loss.detach()\n",
    "    return vloss / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    tloss = train_epoch()\n",
    "    vloss = val_epoch()\n",
    "    print(f'at epoch {i}: tloss is {tloss}, vloss is {vloss}')\n",
    "    if stopper.stop(vloss):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=300,figsize=(5,1))\n",
    "for i in range(5):\n",
    "    ax=plt.subplot(1,5, i + 1)\n",
    "    img=test_set[i][0]\n",
    "    label=test_set[i][1]\n",
    "    img=img/2+0.5\n",
    "    img=img.reshape(28, 28)\n",
    "    plt.imshow(img, cmap=\"binary\")\n",
    "    plt.axis('off')\n",
    "    plt.title(text_labels[label]+f\"; {label}\", fontsize=8)\n",
    "for i in range(5):\n",
    "    img,label = test_set[i]\n",
    "    img=img.reshape(-1,28*28).to(GRAPHIC_DEVICE)\n",
    "    pred=model(img)\n",
    "    index_pred=torch.argmax(pred,dim=1)\n",
    "    idx=index_pred.item()\n",
    "    print(f\"the label is {label}; the prediction is {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "for imgs,labels in test_loader:\n",
    "    imgs=imgs.reshape(-1,28*28).to(GRAPHIC_DEVICE)\n",
    "    labels=(labels).reshape(-1,).to(GRAPHIC_DEVICE)\n",
    "    preds=model(imgs)\n",
    "    pred10=torch.argmax(preds,dim=1)\n",
    "    correct=(pred10==labels)\n",
    "    results.append(correct.detach().cpu().numpy().mean())\n",
    "accuracy=np.array(results).mean()\n",
    "print(f\"the accuracy of the predictions is {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvidia-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
