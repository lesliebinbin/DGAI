{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs(\"files/maestro-v2.0.0/train\", exist_ok=True)\n",
    "# os.makedirs(\"files/maestro-v2.0.0/val\", exist_ok=True)\n",
    "# os.makedirs(\"files/maestro-v2.0.0/test\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "import pickle\n",
    "# from utils.processor import encode_midi\n",
    "# file=\"files/maestro-v2.0.0/maestro-v2.0.0.json\"\n",
    "# with open(file,\"r\") as fb:\n",
    "#     maestro_json=json.load(fb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in maestro_json:\n",
    "#     mid=rf'files/maestro-v2.0.0/{x[\"midi_filename\"]}'\n",
    "#     split_type = x[\"split\"]\n",
    "#     f_name = mid.split(\"/\")[-1] + \".pickle\"\n",
    "#     if(split_type == \"train\"):\n",
    "#         o_file = rf'files/maestro-v2.0.0/train/{f_name}'\n",
    "#     elif(split_type == \"validation\"):\n",
    "#         o_file = rf'files/maestro-v2.0.0/val/{f_name}'\n",
    "#     elif(split_type == \"test\"):\n",
    "#         o_file = rf'files/maestro-v2.0.0/test/{f_name}'\n",
    "#     prepped = encode_midi(mid)\n",
    "#     with open(o_file,\"wb\") as f:\n",
    "#         pickle.dump(prepped, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size=len(os.listdir('files/maestro-v2.0.0/train'))\n",
    "print(f\"there are {train_size} files in the train set\")\n",
    "val_size=len(os.listdir('files/maestro-v2.0.0/val'))\n",
    "print(f\"there are {val_size} files in the validation set\")\n",
    "test_size=len(os.listdir('files/maestro-v2.0.0/test'))\n",
    "print(f\"there are {test_size} files in the test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from utils.processor import encode_midi\n",
    "import pretty_midi\n",
    "from utils.processor import (_control_preprocess,\n",
    "    _note_preprocess,_divide_note,\n",
    "    _make_time_sift_events,_snote2events)\n",
    "\n",
    "file='MIDI-Unprocessed_Chamber1_MID--AUDIO_07_R3_2018_wav--2'\n",
    "name=rf'files/maestro-v2.0.0/2018/{file}.midi'\n",
    "\n",
    "# encode\n",
    "events=[]\n",
    "notes=[]\n",
    "\n",
    "# convert song to an easily-manipulable format\n",
    "song=pretty_midi.PrettyMIDI(name)\n",
    "for inst in song.instruments:\n",
    "    inst_notes=inst.notes\n",
    "    ctrls=_control_preprocess([ctrl for ctrl in \n",
    "       inst.control_changes if ctrl.number == 64])\n",
    "    notes += _note_preprocess(ctrls, inst_notes)\n",
    "dnotes = _divide_note(notes)    \n",
    "dnotes.sort(key=lambda x: x.time)    \n",
    "for i in range(5):\n",
    "    print(dnotes[i])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xys(folder):\n",
    "    files = [os.path.join(folder, f) for f in os.listdir(folder)]\n",
    "    xys = []\n",
    "    for f in files:\n",
    "        with open(f, 'rb') as fb:\n",
    "            music = pickle.load(fb)\n",
    "        music = torch.LongTensor(music)\n",
    "        x = torch.full((max_seq, ), 389, dtype=torch.long)\n",
    "        y = torch.full((max_seq, ), 389, dtype=torch.long)\n",
    "        length = len(music)\n",
    "        if length <= max_seq:\n",
    "            x[:length] = music\n",
    "            y[:length-1]=music[1:]\n",
    "            y[length-1]=388\n",
    "        else:\n",
    "            x=music[:max_seq]\n",
    "            y=music[1:max_seq+1]\n",
    "        xys.append((x, y))\n",
    "    return xys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfolder='files/maestro-v2.0.0/train'\n",
    "train=create_xys(trainfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valfolder='files/maestro-v2.0.0/val'\n",
    "testfolder='files/maestro-v2.0.0/test'\n",
    "print(\"processing the validation set\")\n",
    "val=create_xys(valfolder)\n",
    "print(\"processing the test set\")\n",
    "test=create_xys(testfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val1,_ =val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.processor import decode_midi\n",
    "file_path=\"files/val1.midi\"\n",
    "decode_midi(val1.cpu().numpy(), file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader=DataLoader(train,batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.n_layer = 6\n",
    "        self.n_head = 8\n",
    "        self.n_embd = 512\n",
    "        self.vocab_size = 390\n",
    "        self.block_size = 2048\n",
    "        self.embd_pdrop = 0.1\n",
    "        self.resid_pdrop = 0.1\n",
    "        self.attn_pdrop = 0.1\n",
    "\n",
    "\n",
    "config = Config()\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ch14util import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(config)\n",
    "model.to(device)\n",
    "num=sum(p.numel() for p in model.transformer.parameters())\n",
    "print(\"number of parameters: %.2fM\" % (num/1e6,))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_func=torch.nn.CrossEntropyLoss(ignore_index=389)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 484/484 [07:52<00:00,  1.02it/s, epoch=54, loss=1.6]\n",
      "100%|██████████| 484/484 [07:52<00:00,  1.02it/s, epoch=55, loss=1.58]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=56, loss=1.55]\n",
      "100%|██████████| 484/484 [07:52<00:00,  1.02it/s, epoch=57, loss=1.53]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=58, loss=1.51]\n",
      "100%|██████████| 484/484 [07:52<00:00,  1.02it/s, epoch=59, loss=1.48]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=60, loss=1.46]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=61, loss=1.43]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=62, loss=1.41]\n",
      "100%|██████████| 484/484 [07:52<00:00,  1.02it/s, epoch=63, loss=1.39]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=64, loss=1.37]\n",
      "100%|██████████| 484/484 [07:52<00:00,  1.02it/s, epoch=65, loss=1.35]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=66, loss=1.33]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=67, loss=1.31]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=68, loss=1.29]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=69, loss=1.27]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=70, loss=1.25]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=71, loss=1.23]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=72, loss=1.22]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=73, loss=1.2] \n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=74, loss=1.18]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=75, loss=1.16]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=76, loss=1.15]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=77, loss=1.13]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=78, loss=1.12]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=79, loss=1.1] \n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=80, loss=1.08]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=81, loss=1.07]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=82, loss=1.05] \n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=83, loss=1.04]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=84, loss=1.02] \n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=85, loss=1.01] \n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=86, loss=0.994]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=87, loss=0.983]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=88, loss=0.969]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=89, loss=0.956]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=90, loss=0.942]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=91, loss=0.932]\n",
      "100%|██████████| 484/484 [07:54<00:00,  1.02it/s, epoch=92, loss=0.916]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=93, loss=0.905]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=94, loss=0.894]\n",
      "100%|██████████| 484/484 [07:55<00:00,  1.02it/s, epoch=95, loss=0.882]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=96, loss=0.873]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=97, loss=0.858]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=98, loss=0.847]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=99, loss=0.836]\n",
      "100%|██████████| 484/484 [07:53<00:00,  1.02it/s, epoch=100, loss=0.827]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for i in range(1, 101):\n",
    "    loop = tqdm(trainloader, leave=True)\n",
    "    tloss = 0\n",
    "    for idx, (x, y) in enumerate(loop):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        output = model(x)\n",
    "        loss = loss_func(output.view(-1, output.size(-1)), y.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tloss += loss.item()\n",
    "        loop.set_postfix(loss=tloss/(idx+1), epoch=i)\n",
    "    torch.save(model.state_dict(), f\"files/musicTrans.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mac-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
