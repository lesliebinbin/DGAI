{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_path = kagglehub.dataset_download(handle='splcher/animefacedataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms as T\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.Resize((64, 64)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([.5, .5, .5], [.5, .5, .5]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ImageFolder(root=anime_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image0, _ = train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image0.permute(1, 2, 0)*.5 + .5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(imgs):\n",
    "    for i in range(32):\n",
    "        ax = plt.subplot(4, 8, i + 1)\n",
    "        plt.imshow(imgs[i].permute(1,2,0)/2+0.5)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.subplots_adjust(hspace=-0.6)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, _ = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3, out_channels=64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.LeakyReLU(.2, inplace=True),\n",
    "    nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(num_features=128),\n",
    "    nn.LeakyReLU(.2, inplace=True),\n",
    "    nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(num_features=256),\n",
    "    nn.LeakyReLU(.2, inplace=True),\n",
    "    nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(num_features=512),\n",
    "    nn.LeakyReLU(.2, inplace=True),\n",
    "    nn.Conv2d(in_channels=512, out_channels=1, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Flatten(),\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nn.Sequential(\n",
    "    nn.ConvTranspose2d(in_channels=100, out_channels=512, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "    nn.BatchNorm2d(512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.ConvTranspose2d(in_channels=64, out_channels=3, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.Tanh()\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_noise = torch.randn(32, 100, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "lr = .0002\n",
    "optimG = torch.optim.Adam(G.parameters(), lr=lr, betas=(.5, .999))\n",
    "optimD = torch.optim.Adam(D.parameters(), lr=lr, betas=(.5, .999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch():\n",
    "    noise=torch.randn(32,100,1,1).to(device=device)\n",
    "    fake_samples=G(noise).cpu().detach()\n",
    "    for i in range(32):\n",
    "        ax = plt.subplot(4, 8, i + 1)\n",
    "        img=(fake_samples.cpu().detach()[i]/2+0.5).permute(1,2,0)\n",
    "        plt.imshow(img)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.subplots_adjust(hspace=-0.6)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_D_on_real(real_samples):\n",
    "    optimD.zero_grad()\n",
    "    output = D(real_samples.to(device))\n",
    "    loss = loss_fn(output, torch.ones_like(output, dtype=torch.float32))\n",
    "    loss.backward() \n",
    "    optimD.step()\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_D_on_fake():\n",
    "    optimD.zero_grad()\n",
    "    fake_samples = G(torch.randn(batch_size, 100, 1, 1).to(device))\n",
    "    output = D(fake_samples)\n",
    "    loss = loss_fn(output, torch.zeros_like(output, dtype=torch.float32))\n",
    "    loss.backward()\n",
    "    optimD.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_G():\n",
    "    optimG.zero_grad()\n",
    "    generated_result = G(torch.randn(batch_size, 100, 1, 1).to(device))\n",
    "    output = D(generated_result)\n",
    "    loss = loss_fn(output, torch.ones_like(output, dtype=torch.float32))\n",
    "    loss.backward()\n",
    "    optimG.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=20):\n",
    "    for i in range(epochs):\n",
    "        gloss, dloss = 0, 0\n",
    "        for n, (real_samples, _) in enumerate(train_loader):\n",
    "            loss_D = train_D_on_real(real_samples)\n",
    "            dloss += loss_D\n",
    "            loss_D = train_D_on_fake()\n",
    "            dloss += loss_D\n",
    "            gloss += train_G()\n",
    "        gloss /= n\n",
    "        dloss /= n\n",
    "        print(f\"epoch {i+1}, dloss: {dloss}, gloss {gloss}\")\n",
    "        test_epoch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mac-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
