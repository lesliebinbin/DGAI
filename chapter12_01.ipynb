{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EedyOTzQn84a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21000,
     "status": "ok",
     "timestamp": 1733226635585,
     "user": {
      "displayName": "Haihua Zhang",
      "userId": "02616694619268944742"
     },
     "user_tz": -480
    },
    "id": "yMbiTTseoOXH",
    "outputId": "16f0d760-942b-47a5-c7ba-8a6af0a3e64b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ax4EQKq5n84b"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "t6Xa4NHZn84b"
   },
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1733226641079,
     "user": {
      "displayName": "Haihua Zhang",
      "userId": "02616694619268944742"
     },
     "user_tz": -480
    },
    "id": "A8a5M9oun84c",
    "outputId": "184e11d8-c9cc-4e6f-ebde-0a567a47ab37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4_pV_2BTn84d"
   },
   "outputs": [],
   "source": [
    "with open(\"files/OldManAndSea.txt\",\"r\", encoding='utf-8-sig') as f:\n",
    "    text=f.read()\n",
    "text=list(text)    #A\n",
    "for i in range(len(text)):\n",
    "    if text[i]=='\"':\n",
    "        if text[i+1]==' ' or text[i+1]=='\\n':\n",
    "            text[i]='”'    #B\n",
    "        if text[i+1]!=' ' and text[i+1]!='\\n':\n",
    "            text[i]='“'    #C\n",
    "    if text[i]==\"'\":\n",
    "        if text[i-1]!=' ' and text[i-1]!='\\n':\n",
    "            text[i]='’'    #D\n",
    "text=\"\".join(text)    #E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RJ1acBl1n84e"
   },
   "outputs": [],
   "source": [
    "with open(\"files/ToWhomTheBellTolls.txt\",\"r\", encoding='utf-8-sig') as f:\n",
    "    text1=f.read()\n",
    "with open(\"files/FarewellToArms.txt\",\"r\", encoding='utf-8-sig') as f:\n",
    "    text2=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1733226641079,
     "user": {
      "displayName": "Haihua Zhang",
      "userId": "02616694619268944742"
     },
     "user_tz": -480
    },
    "id": "zt6tmqwYn84e",
    "outputId": "4ee40021-7093-4855-f677-8e4da992505a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He was an old man who fished alone in a skiff in the Gulf Stream and he\n",
      "had gone eighty-four days now without taking a fish.  In the first\n",
      "forty days a boy had been with him.  But after forty days without a\n",
      "fish the boy’s parents had told him that th\n"
     ]
    }
   ],
   "source": [
    "text=text+\" \"+text1+\" \"+text2\n",
    "with open(\"files/ThreeNovels.txt\",\"w\", encoding='utf-8-sig') as f:\n",
    "    f.write(text)\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1733226641079,
     "user": {
      "displayName": "Haihua Zhang",
      "userId": "02616694619268944742"
     },
     "user_tz": -480
    },
    "id": "HD0t4TUVn84f",
    "outputId": "0dfa5833-5958-4b57-f3df-1931d9be1a6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '’', ':', '&', ',', ' ', ';', '‘', '-', ')', '.', '(', '?', '”', '“']\n",
      "10599\n"
     ]
    }
   ],
   "source": [
    "text=text.lower().replace(\"\\n\", \" \")\n",
    "chars=set(text.lower())\n",
    "punctuations=[i for i in chars if i.isalpha()==False\n",
    "and i.isdigit()==False]\n",
    "print(punctuations)\n",
    "for x in punctuations:\n",
    "    text=text.replace(f\"{x}\", f\" {x} \")\n",
    "text_tokenized=text.split()\n",
    "unique_tokens=set(text_tokenized)\n",
    "print(len(unique_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PkeUAs-Dn84g"
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fkOsfHoJn84h"
   },
   "outputs": [],
   "source": [
    "word_counts = Counter(text_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WBUTDN5Kn84h"
   },
   "outputs": [],
   "source": [
    "words = sorted(word_counts, key=word_counts.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "fu9HA-Iqn84h"
   },
   "outputs": [],
   "source": [
    "words.append(\"UNK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "sZQtUE_xn84h"
   },
   "outputs": [],
   "source": [
    "text_length=len(text_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1733226641580,
     "user": {
      "displayName": "Haihua Zhang",
      "userId": "02616694619268944742"
     },
     "user_tz": -480
    },
    "id": "aA2Swx1Dn84i",
    "outputId": "bb655cea-ea05-4a7d-ae72-500b0e9b2b59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364463"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1733226641580,
     "user": {
      "displayName": "Haihua Zhang",
      "userId": "02616694619268944742"
     },
     "user_tz": -480
    },
    "id": "ErR57AkOn84i",
    "outputId": "96aa253f-b923-4772-fbac-1ae875674edf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the text contains 364463 words\n",
      "there are 10600 unique tokens\n",
      "{'.': 0, 'the': 1, ',': 2, '“': 3, '”': 4, 'and': 5, 'i': 6, 'he': 7, 'to': 8, 'it': 9}\n",
      "{0: '.', 1: 'the', 2: ',', 3: '“', 4: '”', 5: 'and', 6: 'i', 7: 'he', 8: 'to', 9: 'it'}\n"
     ]
    }
   ],
   "source": [
    "ntokens=len(words)\n",
    "print(f\"the text contains {text_length} words\")\n",
    "print(f\"there are {ntokens} unique tokens\")\n",
    "word_to_int={v:k for k,v in enumerate(words)}\n",
    "int_to_word={v:k for k,v in word_to_int.items()}\n",
    "print({k:v for k,v in word_to_int.items() if k in words[:10]})\n",
    "print({k:v for k,v in int_to_word.items() if v in words[:10]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1733226641581,
     "user": {
      "displayName": "Haihua Zhang",
      "userId": "02616694619268944742"
     },
     "user_tz": -480
    },
    "id": "80WqkqwNn84i",
    "outputId": "04f681a4-7656-4682-9f74-9fef74ae3d36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'was', 'an', 'old', 'man', 'who', 'fished', 'alone', 'in', 'a', 'skiff', 'in', 'the', 'gulf', 'stream', 'and', 'he', 'had', 'gone', 'eighty']\n"
     ]
    }
   ],
   "source": [
    "print(text_tokenized[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "dnzqoUBLn84i"
   },
   "outputs": [],
   "source": [
    "wordidx=[word_to_int[w] for w in text_tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1733226641581,
     "user": {
      "displayName": "Haihua Zhang",
      "userId": "02616694619268944742"
     },
     "user_tz": -480
    },
    "id": "7Q2rHdESn84i",
    "outputId": "dc95365d-22e4-48d3-b9f4-5584873eb0da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 14, 99, 93, 63, 85, 3818, 311, 15, 11, 657, 15, 1, 2369, 514, 5, 7, 24, 220, 2016]\n"
     ]
    }
   ],
   "source": [
    "print([word_to_int[w] for w in text_tokenized[0:20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "kv3WugmKn84i"
   },
   "outputs": [],
   "source": [
    "seq_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Nrt4FQ1Fn84j"
   },
   "outputs": [],
   "source": [
    "xys = []\n",
    "for n in range(0, len(wordidx)-seq_length -1):\n",
    "    x = wordidx[n:n+seq_length]\n",
    "    y = wordidx[n+1:n+seq_length+1]\n",
    "    xys.append((torch.tensor(x), torch.tensor(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "rHk_63jhn84j"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "RhUQrtQ_n84j"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "batch_size=32\n",
    "loader = DataLoader(dataset=xys, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "4Jbgnc1sn84j"
   },
   "outputs": [],
   "source": [
    "x, y = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1733226671858,
     "user": {
      "displayName": "Haihua Zhang",
      "userId": "02616694619268944742"
     },
     "user_tz": -480
    },
    "id": "AdD4IACGn84j",
    "outputId": "321e50ad-6b1d-4668-bf7d-4ba7b54fc0f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1112,  734,   84,  ...,  208,   31,  432],\n",
       "        [   1, 1404,   15,  ...,   32,    7,  722],\n",
       "        [   3,  158,  412,  ...,    1,  617,   50],\n",
       "        ...,\n",
       "        [   8,  237,   17,  ...,    9,   21,   20],\n",
       "        [  89,   30,    0,  ...,    3,  105,  430],\n",
       "        [  49,   42,   12,  ...,    0,    4,    3]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1733226671858,
     "user": {
      "displayName": "Haihua Zhang",
      "userId": "02616694619268944742"
     },
     "user_tz": -480
    },
    "id": "y4g1Ra84n84j",
    "outputId": "adba0fa4-3595-472e-fce1-a88f4551a9f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 734,   84,   70,  ...,   31,  432,  665],\n",
       "        [1404,   15,    1,  ...,    7,  722,   19],\n",
       "        [ 158,  412, 2120,  ...,  617,   50,  703],\n",
       "        ...,\n",
       "        [ 237,   17,   51,  ...,   21,   20,   73],\n",
       "        [  30,    0,    3,  ...,  105,  430,   49],\n",
       "        [  42,   12,  167,  ...,    4,    3,   17]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Ms6zRSQGn84k"
   },
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return 0.5*x*(1.0+torch.tanh(np.sqrt(2.0/np.pi)* (x + 0.044715 * torch.pow(x, 3.0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "69vfzIJTn84k"
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.n_layer = 3\n",
    "        self.n_head = 4\n",
    "        self.n_embd = 256\n",
    "        self.vocab_size = ntokens\n",
    "        self.block_size = 128\n",
    "        self.embd_pdrop = 0.1\n",
    "        self.resid_pdrop = 0.1\n",
    "        self.attn_pdrop = 0.1\n",
    "config = Config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Qbsl2pmln84k"
   },
   "outputs": [],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
    "        self.attn_dropout = nn.Dropout(config.attn_pdrop)\n",
    "        self.resid_dropout = nn.Dropout(config.resid_pdrop)\n",
    "        self.register_buffer(\n",
    "            \"bias\",\n",
    "            torch.tril(torch.ones(config.block_size, config.block_size)).view(\n",
    "                1, 1, config.block_size, config.block_size\n",
    "            ),\n",
    "        )\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size()\n",
    "        q, k, v = self.c_attn(x).split(self.n_embd, dim=2)\n",
    "        hs = C // self.n_head\n",
    "        k = k.view(B, T, self.n_head, hs).transpose(1, 2)\n",
    "        q = q.view(B, T, self.n_head, hs).transpose(1, 2)\n",
    "        v = v.view(B, T, self.n_head, hs).transpose(1, 2)\n",
    "        att = (q @ k.transpose(-2, -1)) * (1.0 / np.sqrt(k.size(-1)))\n",
    "        att = att.masked_fill(self.bias[:, :, :T, :T] == 0, float(\"-inf\"))\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        att = self.attn_dropout(att)\n",
    "        y = att @ v\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        y = self.resid_dropout(self.c_proj(y))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "rWKY_g8pn84k"
   },
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
    "        self.mlp = nn.ModuleDict(\n",
    "            dict(\n",
    "                c_fc=nn.Linear(config.n_embd, 4 * config.n_embd),\n",
    "                c_proj=nn.Linear(4 * config.n_embd, config.n_embd),\n",
    "                act=GELU(),\n",
    "                dropout=nn.Dropout(config.resid_pdrop),\n",
    "            )\n",
    "        )\n",
    "        m = self.mlp\n",
    "        self.mlpf = lambda x: m.dropout(m.c_proj(m.act(m.c_fc(x))))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlpf(self.ln_2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "FVE1MLKen84k"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.block_size = config.block_size\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
    "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
    "            drop = nn.Dropout(config.embd_pdrop),\n",
    "            h = nn.ModuleList([Block(config)\n",
    "                               for _ in range(config.n_layer)]),\n",
    "            ln_f = nn.LayerNorm(config.n_embd),))\n",
    "        self.lm_head = nn.Linear(config.n_embd,\n",
    "                                 config.vocab_size, bias=False)\n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('c_proj.weight'):\n",
    "                torch.nn.init.normal_(p, mean=0.0,\n",
    "                  std=0.02/np.sqrt(2 * config.n_layer))\n",
    "    def forward(self, idx, targets=None):\n",
    "        b, t = idx.size()\n",
    "        pos = torch.arange(0,t,dtype=torch.long).unsqueeze(0).to(DEVICE)\n",
    "        tok_emb = self.transformer.wte(idx)\n",
    "        pos_emb = self.transformer.wpe(pos)\n",
    "        x = self.transformer.drop(tok_emb + pos_emb)\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "        x = self.transformer.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "UE9y7nBKn84l"
   },
   "outputs": [],
   "source": [
    "model = Model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4253,
     "status": "ok",
     "timestamp": 1733226676488,
     "user": {
      "displayName": "Haihua Zhang",
      "userId": "02616694619268944742"
     },
     "user_tz": -480
    },
    "id": "2DmOE0i5NSEQ",
    "outputId": "55147325-a851-4eee-e6c9-86c6c6c686b2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1733226676489,
     "user": {
      "displayName": "Haihua Zhang",
      "userId": "02616694619268944742"
     },
     "user_tz": -480
    },
    "id": "Uzmvxrzmn84l",
    "outputId": "b2376849-9b9a-4370-c80c-f2f397e0fd39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state_dict': OrderedDict([('transformer.wte.weight',\n",
       "               tensor([[ 0.1239, -0.4560, -0.2791,  ...,  0.8693, -0.4938, -0.1300],\n",
       "                       [-0.9079,  0.5983, -0.1562,  ...,  0.8004,  0.2874,  0.2528],\n",
       "                       [ 1.0717,  0.1306, -0.4871,  ...,  0.3896, -0.1419, -0.0393],\n",
       "                       ...,\n",
       "                       [ 2.3084, -0.1877, -0.2367,  ...,  0.1654, -1.5620,  1.6179],\n",
       "                       [-1.5988,  0.1459,  0.9029,  ...,  0.8002, -0.5080, -0.0231],\n",
       "                       [-0.8436, -0.2974, -0.2744,  ..., -0.8120,  0.3031, -1.5292]],\n",
       "                      device='mps:0')),\n",
       "              ('transformer.wpe.weight',\n",
       "               tensor([[-1.2650e+00, -2.5435e-01,  4.8539e-01,  ..., -1.0553e+00,\n",
       "                        -1.2801e+00,  2.7740e-01],\n",
       "                       [ 4.2821e-01, -4.5995e-01, -2.9265e-01,  ..., -6.5451e-01,\n",
       "                        -3.9146e-01,  3.7858e-01],\n",
       "                       [ 7.2509e-01, -5.4531e-01, -2.4856e-02,  ..., -2.2633e-01,\n",
       "                        -3.8538e-02,  6.4578e-01],\n",
       "                       ...,\n",
       "                       [-6.7912e-01, -7.1820e-01,  2.4219e-01,  ..., -8.0458e-03,\n",
       "                        -4.9063e-01, -7.3243e-02],\n",
       "                       [-4.0049e-01, -8.3018e-01,  6.4689e-04,  ...,  7.8126e-03,\n",
       "                        -6.7807e-01,  8.2183e-02],\n",
       "                       [-3.5724e-01, -8.4347e-01,  3.1528e-01,  ...,  2.8404e-01,\n",
       "                        -1.7444e-01,  7.4243e-02]], device='mps:0')),\n",
       "              ('transformer.h.0.ln_1.weight',\n",
       "               tensor([0.9834, 1.0221, 1.0408, 0.9010, 0.9773, 0.8741, 1.0433, 0.9208, 0.9612,\n",
       "                       1.0045, 0.8363, 0.9317, 0.9847, 0.9545, 0.9689, 0.9225, 1.0543, 0.8656,\n",
       "                       0.9657, 0.8711, 0.9422, 0.9837, 0.9456, 0.9919, 1.0098, 0.9499, 1.0065,\n",
       "                       0.9685, 0.9832, 1.0244, 0.9962, 1.0206, 0.9137, 0.9089, 1.0000, 0.9542,\n",
       "                       1.0614, 1.0164, 0.9726, 0.9958, 0.8980, 0.9623, 0.9037, 0.9732, 0.9011,\n",
       "                       0.9813, 1.0044, 0.9950, 1.0075, 1.0088, 0.9139, 0.8822, 1.0252, 1.1046,\n",
       "                       0.9679, 1.0279, 1.0433, 0.8267, 0.9330, 0.9374, 0.9637, 1.0445, 0.9162,\n",
       "                       1.0658, 0.9840, 1.0396, 0.9484, 0.9364, 0.9635, 0.9916, 0.9657, 1.0004,\n",
       "                       1.0074, 0.9501, 0.8939, 1.0317, 0.9579, 0.9703, 0.9842, 1.0231, 1.0111,\n",
       "                       1.0383, 0.9203, 1.0330, 0.9890, 0.9654, 0.8157, 1.0610, 0.9885, 0.9930,\n",
       "                       0.9764, 0.9640, 1.0032, 0.9861, 0.9861, 0.9332, 1.0346, 1.0183, 0.9230,\n",
       "                       0.9116, 0.9854, 1.0384, 0.9837, 1.0131, 0.9720, 0.9591, 1.0266, 0.9233,\n",
       "                       0.9923, 1.0126, 1.0310, 0.8909, 0.9434, 1.0151, 1.0327, 1.0241, 0.9362,\n",
       "                       0.9627, 0.9973, 1.0286, 0.9878, 0.9645, 1.0422, 1.0223, 0.9274, 0.9725,\n",
       "                       1.0053, 1.0115, 0.8607, 0.9330, 0.9755, 0.9385, 0.9903, 1.0475, 0.9429,\n",
       "                       0.9841, 0.9695, 0.9405, 1.0013, 0.9919, 0.9838, 0.9788, 0.9744, 0.9795,\n",
       "                       1.0589, 1.0255, 0.9321, 0.9828, 0.9825, 0.9691, 0.9139, 1.0460, 0.8681,\n",
       "                       1.0001, 1.0271, 0.9017, 1.0309, 1.0333, 1.0375, 1.0180, 0.9772, 0.9688,\n",
       "                       1.0845, 0.9774, 0.9942, 0.9968, 1.0447, 0.9693, 0.9690, 1.0091, 1.0035,\n",
       "                       0.9305, 0.9048, 0.9817, 0.9982, 1.0251, 0.9782, 0.9671, 0.9986, 0.9935,\n",
       "                       0.9783, 0.8974, 1.0035, 0.9440, 1.0374, 0.9118, 1.0094, 1.0389, 0.9400,\n",
       "                       0.9663, 0.9683, 0.9535, 1.0077, 1.0028, 0.9889, 0.9775, 0.9850, 0.9932,\n",
       "                       1.0119, 0.9453, 1.0267, 0.9493, 0.9541, 1.0115, 1.0133, 0.9565, 0.7592,\n",
       "                       0.9429, 1.0479, 1.0254, 0.8510, 0.8289, 0.9628, 1.0620, 0.9795, 1.0050,\n",
       "                       0.9295, 0.8516, 0.8776, 0.9361, 0.9228, 1.0232, 0.9066, 1.0475, 0.9941,\n",
       "                       1.0156, 0.9622, 0.9038, 0.9648, 0.8978, 0.9614, 1.0133, 0.9849, 1.0014,\n",
       "                       0.9453, 0.9831, 0.8576, 0.9586, 0.9105, 0.9608, 0.9844, 0.9801, 1.0104,\n",
       "                       0.6296, 0.9792, 0.9651, 0.9523, 1.0338, 0.9543, 1.0131, 0.9898, 0.9969,\n",
       "                       1.0258, 1.0089, 0.9586, 0.9628], device='mps:0')),\n",
       "              ('transformer.h.0.ln_1.bias',\n",
       "               tensor([ 0.0097,  0.0520, -0.0330,  0.0774, -0.1175,  0.0300, -0.0291,  0.0689,\n",
       "                       -0.0223, -0.0277,  0.1718, -0.1757,  0.1350,  0.0540, -0.0333,  0.0426,\n",
       "                        0.0937, -0.1111,  0.0182, -0.0253,  0.0609,  0.0784, -0.0192, -0.0487,\n",
       "                       -0.0634, -0.0129, -0.0597, -0.0165,  0.0873, -0.0255, -0.0381, -0.0249,\n",
       "                        0.1019,  0.0979, -0.0175, -0.0553, -0.0209, -0.0667, -0.0292,  0.0345,\n",
       "                       -0.0277,  0.0632,  0.0408, -0.0094,  0.0041, -0.0416, -0.0812, -0.0509,\n",
       "                        0.0171,  0.0160,  0.1134,  0.0097, -0.0292,  0.0067, -0.1064,  0.0785,\n",
       "                       -0.0213, -0.1102,  0.0394,  0.0437,  0.0376, -0.1011, -0.0393, -0.0316,\n",
       "                        0.0429,  0.0500,  0.0588, -0.1422,  0.0456,  0.0282, -0.0247,  0.0362,\n",
       "                       -0.0480, -0.0821,  0.1013, -0.0204, -0.1269,  0.0150, -0.0371,  0.0998,\n",
       "                       -0.0180, -0.0767,  0.0103,  0.0894, -0.0653, -0.0191, -0.0824, -0.0072,\n",
       "                       -0.0329, -0.0832,  0.0018, -0.0117,  0.0142, -0.0868,  0.0239,  0.0927,\n",
       "                       -0.0457, -0.0345, -0.0974, -0.0582,  0.0870, -0.0103, -0.1025, -0.0102,\n",
       "                       -0.0435, -0.0716, -0.0833, -0.0469,  0.0378,  0.0597, -0.0478, -0.0019,\n",
       "                       -0.0682,  0.0127, -0.0286,  0.0073, -0.0371, -0.0373,  0.0368, -0.0092,\n",
       "                       -0.0521, -0.0751, -0.0184, -0.0916, -0.0303, -0.0480, -0.0402,  0.0012,\n",
       "                       -0.0285, -0.0641, -0.0220,  0.0056,  0.0445,  0.0648,  0.1118,  0.0361,\n",
       "                       -0.0251, -0.1203, -0.0138, -0.0083, -0.0354,  0.0114,  0.0323, -0.0836,\n",
       "                       -0.0368, -0.0405, -0.0792, -0.0531, -0.0008,  0.0020,  0.0073, -0.0449,\n",
       "                        0.1454,  0.0191,  0.0261,  0.0745, -0.0098, -0.0167, -0.0062, -0.0399,\n",
       "                       -0.0174, -0.0195,  0.0630, -0.0113, -0.0752,  0.0383, -0.0736,  0.0268,\n",
       "                       -0.0806, -0.0277, -0.0148, -0.1321, -0.1418,  0.0579, -0.1278, -0.1372,\n",
       "                        0.0221,  0.0545, -0.0481, -0.0706, -0.0688,  0.0038, -0.0014, -0.0422,\n",
       "                       -0.0593,  0.0309, -0.0855,  0.0042,  0.0452, -0.0499,  0.0336, -0.1226,\n",
       "                       -0.0316, -0.0079,  0.0391, -0.0568,  0.0492,  0.0038,  0.1112, -0.0783,\n",
       "                        0.0176,  0.0021,  0.0561, -0.0281, -0.0109,  0.0634,  0.0489, -0.0320,\n",
       "                       -0.0058, -0.1557, -0.0131,  0.0268,  0.0106, -0.0536, -0.0465,  0.0358,\n",
       "                       -0.1126,  0.0375, -0.0401, -0.0187, -0.0553, -0.0853, -0.0236, -0.0467,\n",
       "                       -0.0373,  0.0165,  0.0210, -0.0018,  0.0421, -0.0229, -0.0612, -0.0825,\n",
       "                       -0.0207, -0.0437, -0.0421, -0.0181,  0.0653, -0.0767, -0.0248,  0.0181,\n",
       "                        0.0979, -0.0209,  0.0656, -0.2513,  0.0342, -0.0096,  0.0514, -0.0991,\n",
       "                       -0.1405, -0.0590, -0.0472, -0.0910,  0.0178,  0.0187,  0.0641, -0.0769],\n",
       "                      device='mps:0')),\n",
       "              ('transformer.h.0.attn.bias',\n",
       "               tensor([[[[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "                         [1., 1., 0.,  ..., 0., 0., 0.],\n",
       "                         [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "                         ...,\n",
       "                         [1., 1., 1.,  ..., 1., 0., 0.],\n",
       "                         [1., 1., 1.,  ..., 1., 1., 0.],\n",
       "                         [1., 1., 1.,  ..., 1., 1., 1.]]]], device='mps:0')),\n",
       "              ('transformer.h.0.attn.c_attn.weight',\n",
       "               tensor([[-0.0275, -0.0179, -0.0251,  ..., -0.0272, -0.0816, -0.0134],\n",
       "                       [ 0.1079,  0.0530, -0.0432,  ...,  0.0542,  0.0213,  0.0418],\n",
       "                       [ 0.0217,  0.0998, -0.1379,  ...,  0.0173, -0.0108,  0.0553],\n",
       "                       ...,\n",
       "                       [-0.0013,  0.0074, -0.0702,  ..., -0.0658, -0.0231,  0.0153],\n",
       "                       [-0.0348,  0.0773,  0.0332,  ...,  0.0902,  0.0296, -0.0755],\n",
       "                       [ 0.0468, -0.0349, -0.0573,  ...,  0.0074, -0.0668, -0.0172]],\n",
       "                      device='mps:0')),\n",
       "              ('transformer.h.0.attn.c_attn.bias',\n",
       "               tensor([-2.9980e-01,  6.4426e-01,  3.0292e-01, -1.8019e-01,  1.0655e-01,\n",
       "                        2.2400e-01,  1.7545e-01, -4.9587e-02,  3.8289e-01,  2.4461e-02,\n",
       "                       -4.4358e-01,  6.8466e-01, -2.6848e-01, -1.6202e-01,  1.7238e-01,\n",
       "                        7.0899e-02,  1.9054e-01,  2.9989e-01,  1.4115e-01, -4.2561e-01,\n",
       "                       -2.8125e-02, -6.7544e-01, -5.0875e-02, -3.1842e-01, -1.8326e-01,\n",
       "                        2.7774e-01,  3.4957e-01,  1.2637e-01,  1.8553e-01, -1.4367e-01,\n",
       "                        3.8845e-02,  4.4927e-01,  1.9013e-01,  9.5057e-02, -1.0368e-01,\n",
       "                        9.6993e-02,  1.7848e-01, -1.9834e-01,  9.7256e-02,  1.2897e-01,\n",
       "                       -1.6067e-01,  4.6896e-01, -2.7922e-01, -2.9265e-01,  9.3400e-03,\n",
       "                        3.3250e-01, -2.2489e-01, -4.4587e-01,  7.7314e-02, -1.6974e-01,\n",
       "                        7.7035e-02, -4.2456e-01,  5.1699e-01,  1.5267e-01,  8.7193e-02,\n",
       "                       -2.6352e-01, -1.0616e-01,  8.7422e-02, -6.3621e-01, -3.2387e-01,\n",
       "                        3.0203e-01, -2.4488e-01,  5.2334e-01, -1.8123e-01,  2.0916e-01,\n",
       "                       -4.5754e-01,  1.3862e-01,  4.8269e-02, -7.1313e-01, -9.8215e-02,\n",
       "                       -7.6831e-01,  5.3257e-02, -1.6600e-01,  4.7167e-01,  2.4587e-01,\n",
       "                        3.3094e-01,  5.5478e-01,  5.6435e-01,  1.1959e-01, -7.5701e-01,\n",
       "                        3.3338e-02,  2.1067e-01, -7.6647e-01, -3.6455e-01, -4.4854e-01,\n",
       "                        2.7158e-01, -1.8956e-01,  3.4607e-01,  1.2543e-01, -4.8564e-01,\n",
       "                        2.8706e-01, -4.5054e-02, -6.3717e-02, -2.1587e-01,  1.6603e-01,\n",
       "                        1.5307e-01,  4.5064e-01, -6.1112e-01, -4.2199e-01,  2.6379e-01,\n",
       "                       -1.9009e-01,  1.4027e-01,  8.5224e-02,  5.4636e-01,  5.5230e-01,\n",
       "                       -3.6427e-01, -1.4299e-02, -3.7728e-01, -1.9977e-01,  2.6053e-01,\n",
       "                        3.1802e-01, -1.7624e-01,  1.1317e-01, -7.2648e-02, -3.9672e-01,\n",
       "                       -5.8676e-01, -9.5857e-02,  2.4438e-01,  4.5366e-01,  3.5196e-01,\n",
       "                        1.7143e-01, -6.7242e-01,  8.5418e-01, -1.2554e-01,  3.6967e-02,\n",
       "                        2.3252e-01,  2.9732e-01, -3.2322e-02, -1.5810e-01,  4.5747e-01,\n",
       "                       -2.5523e-01, -1.2506e-01,  1.5078e-01,  1.0354e-01,  2.0127e-01,\n",
       "                        3.5804e-01, -4.1963e-01,  1.4923e-02,  2.1337e-01, -1.1588e-01,\n",
       "                       -3.5964e-01,  2.5375e-01, -1.1058e-01, -1.5576e-01,  1.8479e-01,\n",
       "                       -2.0902e-01, -1.1811e-01, -3.1506e-01,  1.1188e-01,  2.1431e-01,\n",
       "                       -1.9149e-01,  1.0053e-01, -5.6599e-02, -6.4531e-02, -2.8950e-01,\n",
       "                       -1.7903e-01,  9.7969e-03,  1.5500e-01,  2.6777e-02,  1.0090e-01,\n",
       "                       -1.2052e-01, -5.5592e-01,  1.8534e-02, -1.4564e-01,  2.5014e-01,\n",
       "                        1.7512e-01, -4.8406e-02, -2.5931e-01,  1.6778e-01,  2.0951e-01,\n",
       "                        1.9373e-01,  2.2509e-01,  8.1010e-02, -2.7989e-01,  3.8126e-01,\n",
       "                       -1.4363e-01, -3.6792e-01, -9.0782e-02,  3.3887e-01,  4.9289e-01,\n",
       "                       -1.7398e-01, -2.8382e-01,  8.5691e-02,  1.8617e-01,  1.8757e-01,\n",
       "                       -1.2219e-02, -9.9297e-02,  2.1975e-01, -1.9060e-01, -4.2358e-02,\n",
       "                       -9.5461e-02,  1.8928e-01, -2.4664e-01,  8.7726e-01, -5.6516e-01,\n",
       "                        6.2962e-01, -9.7950e-02, -5.8441e-01, -5.1491e-01,  4.4313e-01,\n",
       "                       -7.6225e-01, -3.4702e-01, -3.7302e-01, -1.1145e+00, -2.2882e-01,\n",
       "                       -2.6944e-01,  5.2987e-01,  1.0015e-02,  4.2426e-02,  7.7531e-02,\n",
       "                       -2.9802e-01,  6.3267e-01,  3.9421e-01,  3.6042e-01, -9.9539e-01,\n",
       "                       -1.0364e+00, -8.4542e-01, -9.9320e-01, -9.4703e-01, -8.3419e-01,\n",
       "                       -7.8277e-02,  1.3982e-01, -3.6132e-01, -6.3928e-02,  1.0505e+00,\n",
       "                       -2.0488e-01, -6.5719e-02, -2.5739e-01,  1.8734e-01, -1.7585e-01,\n",
       "                       -5.3867e-01,  1.7529e-01, -5.5585e-01, -2.4662e-01,  6.0798e-01,\n",
       "                        1.0334e+00,  5.4447e-02,  4.1286e-01,  9.9809e-01, -7.8701e-01,\n",
       "                        1.1306e+00, -9.0798e-01,  4.8039e-01,  3.2676e-02, -3.7798e-01,\n",
       "                        1.9805e-01, -2.8991e-01, -1.8518e-01,  7.7278e-02, -3.5601e-01,\n",
       "                        9.2979e-01, -1.8146e-01, -5.9814e-01,  2.1131e-01, -3.7302e-01,\n",
       "                       -1.9141e-01,  9.1566e-03, -5.6915e-02, -1.7652e-02,  6.9915e-03,\n",
       "                        6.4061e-03, -5.6877e-02, -3.1999e-02,  2.8708e-02,  3.5961e-02,\n",
       "                       -4.5623e-02, -4.3940e-02, -5.3966e-02,  5.9999e-02,  3.1541e-02,\n",
       "                        3.5155e-02,  3.4893e-02,  2.5282e-02, -2.4623e-02, -3.1542e-02,\n",
       "                       -2.0364e-02,  3.0106e-02,  1.4259e-02,  5.0500e-02, -1.0255e-02,\n",
       "                       -2.9488e-02,  4.5225e-02, -5.7388e-02,  1.7722e-02, -3.7302e-02,\n",
       "                        2.8278e-02, -5.6354e-03, -9.6780e-03,  2.4141e-02,  4.4238e-02,\n",
       "                        3.5701e-02, -5.7068e-03,  5.5166e-02,  4.4326e-02, -4.8717e-02,\n",
       "                       -3.5218e-02, -2.8436e-02, -6.2088e-03, -2.7005e-03,  1.3402e-03,\n",
       "                        4.9871e-02, -3.3890e-02, -4.4369e-04,  2.9839e-03,  4.4076e-02,\n",
       "                       -1.5374e-02, -3.1253e-02,  2.5816e-02,  5.4097e-02, -3.0553e-02,\n",
       "                       -5.0333e-02, -2.1175e-02, -1.9982e-02,  5.0288e-03,  5.8142e-02,\n",
       "                        5.2656e-03, -1.9911e-02, -4.8285e-03, -4.4882e-02, -4.2460e-02,\n",
       "                       -3.3685e-04, -2.3019e-02, -4.9433e-03, -2.0875e-02, -3.6953e-03,\n",
       "                        5.4385e-02,  3.7972e-02, -5.1366e-02, -1.1002e-02,  3.0778e-02,\n",
       "                       -5.8917e-02,  3.6687e-02, -2.3418e-02, -4.3852e-02,  1.6773e-02,\n",
       "                       -5.7375e-02, -4.3716e-02, -5.0052e-03,  4.9695e-02,  4.3362e-02,\n",
       "                        4.5190e-02,  3.9030e-02,  2.0780e-02, -1.0027e-02, -3.5948e-04,\n",
       "                       -4.7222e-03,  3.3082e-02, -4.6991e-02,  4.7618e-04, -1.3424e-02,\n",
       "                        2.5224e-02, -2.8261e-02,  5.9290e-02, -2.8730e-02, -4.9428e-02,\n",
       "                        1.1744e-02,  5.9217e-03,  2.2432e-02, -2.9715e-02, -5.4117e-03,\n",
       "                       -4.2993e-02, -7.5018e-03,  2.1681e-02, -6.0627e-02,  2.2752e-02,\n",
       "                       -1.0730e-02,  5.9560e-02,  1.8472e-02,  2.9812e-03,  5.7685e-02,\n",
       "                        5.5057e-02,  4.7214e-02, -1.1374e-02, -9.9169e-03,  2.3925e-02,\n",
       "                       -4.5685e-02,  3.7342e-02,  6.1693e-02, -2.1602e-02, -8.0193e-03,\n",
       "                       -3.7216e-02, -5.9555e-02, -5.6799e-02,  4.0666e-02, -5.8264e-02,\n",
       "                       -2.2505e-02, -5.9739e-02, -5.4645e-02,  2.0230e-02,  5.9936e-02,\n",
       "                       -3.2525e-02,  5.0155e-03, -5.5969e-02,  2.3081e-02, -5.5611e-02,\n",
       "                        3.1321e-02,  4.9954e-02, -1.1353e-02, -4.7343e-02,  4.8553e-02,\n",
       "                        3.3161e-02, -9.8477e-04, -3.8176e-02, -1.1842e-02, -2.6666e-03,\n",
       "                       -2.6111e-02,  3.5056e-02,  5.9284e-02, -8.2989e-03, -2.3555e-02,\n",
       "                        4.7860e-04,  4.5102e-02,  5.9776e-02,  2.8254e-02, -4.5975e-02,\n",
       "                       -4.8023e-02, -5.0017e-02,  6.1753e-02,  2.1566e-02, -3.6971e-02,\n",
       "                       -4.2196e-02,  1.5127e-02, -2.2661e-02, -4.9918e-03,  5.7687e-03,\n",
       "                        1.9204e-02, -4.0545e-02,  4.3719e-03,  2.4354e-02, -5.4779e-02,\n",
       "                       -5.4420e-02,  3.0833e-02, -3.2451e-02, -3.4097e-03, -2.5179e-03,\n",
       "                       -4.6560e-02, -1.6625e-02,  4.5540e-02, -5.1191e-02, -5.3175e-02,\n",
       "                        5.7026e-02,  4.4757e-02,  6.1488e-02,  5.7352e-02,  3.3970e-02,\n",
       "                        4.0589e-02, -4.2165e-02,  4.5334e-02,  4.7437e-02, -5.9888e-02,\n",
       "                        5.3822e-02,  5.1125e-04,  4.9223e-02, -1.8654e-02, -5.5136e-02,\n",
       "                        6.1554e-02, -1.3394e-02, -2.0247e-02, -5.2988e-02,  2.4485e-03,\n",
       "                        3.1409e-02,  4.7473e-02,  4.0250e-02,  2.8462e-02, -4.1731e-04,\n",
       "                       -6.8946e-03, -3.8107e-02,  1.7474e-02,  4.3509e-02,  3.3444e-02,\n",
       "                       -5.8678e-02, -5.6278e-02, -3.0087e-02, -1.6582e-02, -5.2431e-02,\n",
       "                       -5.4496e-02, -4.2433e-02, -2.3094e-02,  4.0139e-02,  6.2036e-02,\n",
       "                        2.8537e-02, -5.6617e-02, -2.9385e-03, -5.6724e-02,  1.9995e-02,\n",
       "                        1.5860e-02,  5.1758e-02,  1.3713e-02, -1.7700e-03, -2.5755e-02,\n",
       "                        3.3208e-02, -5.1575e-02, -3.4226e-02, -8.7324e-03, -1.2616e-02,\n",
       "                       -5.5744e-02, -3.9925e-02, -4.1788e-02, -5.6069e-02,  2.5816e-02,\n",
       "                        4.8405e-03, -1.9439e-02, -5.6027e-02, -4.0507e-02,  4.0433e-02,\n",
       "                        3.1715e-02, -5.9483e-02,  2.1145e-02, -4.0702e-02,  4.6817e-02,\n",
       "                        3.0278e-02, -2.1488e-02,  7.3087e-02,  9.2867e-02,  6.0092e-02,\n",
       "                       -5.8243e-02,  8.6495e-02,  9.6013e-02,  1.2086e-01,  3.1610e-02,\n",
       "                       -5.8772e-02,  9.3622e-03, -3.4124e-02,  3.0078e-02, -4.6283e-02,\n",
       "                       -4.2241e-03,  4.8434e-02,  3.8892e-02, -8.1129e-02, -4.8999e-03,\n",
       "                       -4.4064e-02,  5.7651e-02,  1.5297e-02, -1.3397e-02,  1.0127e-01,\n",
       "                        6.6896e-03,  2.6880e-02,  2.1249e-02, -3.6157e-02,  7.4925e-02,\n",
       "                        6.2903e-02, -3.0595e-02,  9.4385e-03,  4.5715e-02,  2.2306e-02,\n",
       "                       -1.0434e-02,  3.4058e-02,  1.1928e-01,  1.0385e-02,  1.4068e-01,\n",
       "                        1.0062e-01,  1.1380e-02,  6.3201e-02,  9.6786e-03, -3.8439e-04,\n",
       "                       -3.3249e-02, -4.3125e-02, -4.3194e-02, -9.8391e-02, -1.8847e-02,\n",
       "                        1.1014e-02,  1.1546e-01, -2.7003e-02, -2.5725e-02,  4.4545e-02,\n",
       "                        6.0031e-02, -6.4916e-02, -1.4491e-01,  3.3471e-02, -8.9801e-02,\n",
       "                        2.6928e-02, -9.1388e-02, -5.1852e-02, -7.1092e-02, -5.2583e-02,\n",
       "                        1.5452e-02, -2.5444e-02, -1.1808e-01, -9.0322e-02, -1.6156e-01,\n",
       "                        2.4841e-02,  1.3777e-02, -1.5981e-01,  2.7195e-02,  2.7600e-01,\n",
       "                        1.0565e-01, -1.7742e-01, -3.3302e-02,  5.7180e-02,  1.0252e-01,\n",
       "                       -1.5189e-02,  6.5121e-02, -1.2301e-02, -6.1753e-03, -9.3715e-03,\n",
       "                       -1.1880e-01,  1.8658e-02, -6.6750e-03,  5.4704e-02,  1.2238e-01,\n",
       "                       -6.6818e-03, -2.7161e-01,  1.4527e-01,  4.3904e-02,  1.0747e-02,\n",
       "                       -8.0178e-03,  2.3749e-01,  3.4348e-02,  1.9972e-01,  1.8380e-01,\n",
       "                       -1.2072e-02, -9.2106e-02, -2.0213e-01, -1.7719e-01,  1.0062e-01,\n",
       "                       -2.0084e-01,  5.8683e-02,  6.9516e-02,  6.0149e-02, -9.4355e-02,\n",
       "                       -6.1241e-02,  8.7774e-02,  4.1371e-02, -9.3593e-02, -4.9025e-02,\n",
       "                       -1.7333e-02,  5.9999e-02, -7.1846e-02, -5.7238e-02,  5.1325e-02,\n",
       "                       -2.7507e-01, -8.7837e-02,  7.1315e-02,  8.5428e-02, -1.3444e-01,\n",
       "                        7.7670e-02,  1.4483e-01, -9.4442e-03, -1.8110e-01,  7.5033e-02,\n",
       "                       -5.0833e-06, -2.0904e-02, -2.2949e-02, -6.2509e-03, -8.4250e-02,\n",
       "                        1.0610e-01,  5.6988e-02, -5.6701e-02, -5.5886e-02,  9.4667e-02,\n",
       "                        1.2359e-03, -1.2791e-01, -6.5693e-02,  2.8601e-02,  9.2545e-02,\n",
       "                        1.6048e-01, -3.9338e-02, -3.2411e-02, -1.3293e-01,  8.2556e-02,\n",
       "                       -1.3392e-01,  1.6348e-01,  4.3805e-02,  1.5118e-03, -9.9547e-02,\n",
       "                        2.5508e-02,  5.7835e-02,  3.1569e-02, -1.0361e-02, -1.5797e-01,\n",
       "                        5.7851e-02,  2.0815e-02, -1.1439e-01,  9.4179e-03,  1.0036e-01,\n",
       "                        5.2777e-02, -4.0437e-02, -1.3067e-01,  3.1347e-02,  1.0285e-01,\n",
       "                        1.1145e-01,  3.9589e-02,  1.5148e-01,  6.7743e-02,  6.7266e-02,\n",
       "                       -1.0816e-01,  2.6969e-02,  8.6929e-02,  1.4489e-01, -1.0392e-02,\n",
       "                       -1.3491e-01, -9.8196e-03,  6.4696e-02,  3.9733e-02, -5.5550e-02,\n",
       "                        1.3445e-01, -1.6314e-01, -4.2200e-02,  2.0532e-02,  1.5853e-01,\n",
       "                       -8.1896e-02,  6.8288e-02,  2.1870e-02,  7.2713e-02, -1.0221e-01,\n",
       "                       -5.2134e-02,  1.2374e-02, -1.2231e-01, -9.3121e-02, -5.8620e-02,\n",
       "                       -1.8479e-01,  1.2746e-01,  6.4448e-02, -2.0665e-02,  6.2828e-03,\n",
       "                        8.7558e-02, -4.5467e-02, -1.2022e-01,  6.1199e-02, -1.7824e-01,\n",
       "                       -4.2967e-02,  1.0188e-01,  1.3528e-02,  9.4459e-03, -3.9953e-02,\n",
       "                       -1.3877e-01, -3.1053e-02, -6.6014e-04,  1.0418e-01, -2.8672e-03,\n",
       "                       -3.4972e-02, -5.0785e-02, -1.0412e-01,  8.6941e-02,  1.1284e-01,\n",
       "                       -4.2779e-02, -3.6093e-02, -1.2752e-02, -1.8371e-02,  3.2172e-02,\n",
       "                        9.0764e-02,  9.9907e-02,  9.6566e-02,  9.7140e-02, -1.5133e-01,\n",
       "                        4.1795e-02, -2.7596e-02,  6.4782e-02,  3.0299e-02,  1.0736e-02,\n",
       "                       -9.8341e-03, -3.0299e-01, -5.5230e-03, -1.5523e-01,  1.1849e-01,\n",
       "                        1.1215e-02, -1.3267e-02,  1.3947e-02, -7.2266e-02,  1.7472e-01,\n",
       "                        4.6370e-02, -1.2506e-01,  9.4790e-02,  8.3638e-02, -5.6123e-02,\n",
       "                        1.9850e-02,  4.4712e-03,  5.2179e-02], device='mps:0')),\n",
       "              ('transformer.h.0.attn.c_proj.weight',\n",
       "               tensor([[-0.0375, -0.0243, -0.0834,  ..., -0.0172, -0.0495, -0.0667],\n",
       "                       [ 0.0965, -0.0532,  0.0676,  ...,  0.0066,  0.0897, -0.0506],\n",
       "                       [ 0.0373, -0.0016,  0.0147,  ..., -0.0548, -0.0145,  0.0390],\n",
       "                       ...,\n",
       "                       [-0.0008,  0.0504,  0.0609,  ..., -0.0274,  0.0117,  0.0553],\n",
       "                       [-0.0320,  0.0175,  0.0412,  ..., -0.0513, -0.0080, -0.0214],\n",
       "                       [-0.0260, -0.0478,  0.0218,  ...,  0.0450, -0.0157,  0.0355]],\n",
       "                      device='mps:0')),\n",
       "              ('transformer.h.0.attn.c_proj.bias',\n",
       "               tensor([-0.0980, -0.2707,  0.0343, -0.1058, -0.0991,  0.0284, -0.0621,  0.0028,\n",
       "                       -0.0929, -0.1315, -0.0353,  0.1230, -0.1167, -0.0340,  0.1972, -0.0531,\n",
       "                       -0.0554,  0.0185, -0.0037, -0.0505,  0.0461, -0.0105,  0.0668, -0.2021,\n",
       "                        0.0023,  0.0451, -0.0879, -0.0646, -0.0650,  0.0899, -0.0035, -0.0044,\n",
       "                        0.1140,  0.0643,  0.1000, -0.0515,  0.0266, -0.0882,  0.0335, -0.1308,\n",
       "                       -0.0718,  0.0244, -0.1575, -0.0599,  0.0531,  0.1890,  0.1621, -0.1178,\n",
       "                        0.0577, -0.2427, -0.2177, -0.2184,  0.0168,  0.1088, -0.0615, -0.0811,\n",
       "                       -0.0918,  0.1689, -0.0341, -0.0344,  0.1632, -0.0495, -0.1466,  0.0352,\n",
       "                       -0.0070, -0.2153, -0.0222,  0.1747, -0.0770, -0.1144, -0.0652, -0.2167,\n",
       "                        0.1668,  0.0526, -0.0499, -0.0789,  0.0076, -0.0552,  0.0591,  0.0381,\n",
       "                        0.1905,  0.0519, -0.0373, -0.0733,  0.0750, -0.0645,  0.0467, -0.0303,\n",
       "                        0.1583,  0.1486, -0.1858,  0.0406,  0.0203, -0.0370, -0.1322, -0.1232,\n",
       "                       -0.0652,  0.0840, -0.0440, -0.0184, -0.1616,  0.0908,  0.0665,  0.0999,\n",
       "                       -0.0957,  0.0468,  0.2680, -0.0296,  0.1086, -0.1036,  0.0224, -0.0882,\n",
       "                       -0.0027,  0.1050,  0.0444, -0.1003,  0.1049, -0.0562, -0.0243, -0.0819,\n",
       "                       -0.1170,  0.1813, -0.0261,  0.1233,  0.0083,  0.0708,  0.1714, -0.1665,\n",
       "                       -0.0821, -0.0217,  0.0549,  0.1375, -0.0226, -0.1211, -0.0067, -0.0893,\n",
       "                       -0.0741,  0.1518,  0.0336, -0.0898,  0.0669, -0.0494, -0.0066,  0.1111,\n",
       "                        0.2295, -0.0829,  0.1700,  0.0913,  0.0378,  0.1233,  0.0691,  0.0749,\n",
       "                       -0.0221,  0.0492, -0.0985, -0.0917,  0.2009,  0.0810, -0.0479, -0.0316,\n",
       "                       -0.0263,  0.2563, -0.0174,  0.0140, -0.1131, -0.1792,  0.0433,  0.0152,\n",
       "                        0.0278,  0.0791, -0.0819,  0.0742, -0.0858,  0.0503,  0.1118,  0.1210,\n",
       "                        0.1154, -0.0880,  0.0015,  0.1060,  0.1968,  0.0763,  0.0040, -0.1405,\n",
       "                        0.0507,  0.0798,  0.1378,  0.0521, -0.0789,  0.0446, -0.0828, -0.0863,\n",
       "                       -0.0590,  0.0622, -0.1197, -0.0193,  0.0435, -0.0455, -0.0555,  0.1243,\n",
       "                        0.1240, -0.1532, -0.0681,  0.0083, -0.0804, -0.0490, -0.0919,  0.0056,\n",
       "                       -0.0356,  0.0607, -0.0890, -0.1042, -0.0845, -0.0008, -0.1274, -0.0931,\n",
       "                        0.1717,  0.0035,  0.0904, -0.0831,  0.0438,  0.1336,  0.1056, -0.0367,\n",
       "                        0.1121,  0.0431, -0.0297, -0.0221,  0.1681,  0.0289,  0.0984,  0.0414,\n",
       "                        0.0959, -0.1106,  0.0747,  0.1119, -0.0879,  0.0790,  0.2224,  0.0492,\n",
       "                       -0.0360,  0.0423, -0.1343,  0.0270, -0.1531,  0.0093, -0.0894,  0.0867,\n",
       "                       -0.0130,  0.0319, -0.0717,  0.0142, -0.0075,  0.0557, -0.1461,  0.0519],\n",
       "                      device='mps:0')),\n",
       "              ('transformer.h.0.ln_2.weight',\n",
       "               tensor([0.9520, 0.9146, 1.0058, 0.9491, 0.8987, 0.7376, 0.9306, 0.8885, 0.9156,\n",
       "                       0.9050, 0.8570, 0.9179, 1.0098, 0.9677, 0.9673, 0.8439, 0.9993, 0.9060,\n",
       "                       0.9971, 0.9252, 0.9339, 0.9424, 0.9806, 0.8950, 0.9845, 0.9152, 0.9059,\n",
       "                       0.9389, 0.9519, 0.9691, 0.9045, 0.9766, 0.8625, 0.9031, 0.9591, 0.9475,\n",
       "                       1.0204, 0.9792, 0.8987, 0.9413, 0.9219, 0.9495, 0.9624, 0.9773, 0.8489,\n",
       "                       0.9255, 0.8987, 0.9029, 0.9195, 0.9732, 0.8979, 0.8252, 0.9589, 0.9898,\n",
       "                       0.9120, 1.0038, 0.9563, 0.8308, 0.8869, 1.0631, 0.8946, 0.9441, 0.8726,\n",
       "                       0.9247, 0.9390, 0.9117, 0.9221, 0.9384, 0.9138, 0.9762, 0.9443, 0.9207,\n",
       "                       0.9677, 0.9957, 0.9433, 0.9786, 0.9504, 0.8662, 0.9055, 0.9324, 0.9012,\n",
       "                       0.9265, 0.9608, 0.9784, 0.9348, 0.9470, 0.8670, 0.9633, 0.9825, 0.9625,\n",
       "                       0.9012, 0.9214, 0.9207, 1.0173, 0.8858, 0.8891, 0.9539, 0.9370, 0.9472,\n",
       "                       0.8312, 0.8949, 0.9822, 0.9115, 0.9186, 0.9403, 0.9655, 0.8985, 0.9442,\n",
       "                       1.0146, 0.9713, 1.0438, 0.9386, 0.8214, 0.9753, 1.0330, 0.9356, 0.8924,\n",
       "                       1.0007, 0.9467, 0.9574, 1.0050, 0.9516, 0.9639, 0.8882, 0.9381, 0.9076,\n",
       "                       0.9627, 0.9402, 0.9168, 0.9079, 0.9032, 0.8759, 0.9754, 0.9653, 0.9004,\n",
       "                       0.9353, 0.9517, 0.8663, 1.0110, 0.9182, 0.9149, 0.8854, 1.0107, 0.9912,\n",
       "                       0.9875, 1.0155, 0.9099, 0.9517, 0.9542, 0.9596, 0.8867, 0.9347, 0.9086,\n",
       "                       0.9650, 0.9809, 0.9059, 0.8983, 0.9906, 1.0176, 0.9083, 0.9652, 0.9170,\n",
       "                       0.9458, 0.9557, 0.9463, 0.9673, 0.9671, 0.9141, 0.9140, 0.9881, 0.9519,\n",
       "                       0.8894, 0.8922, 0.9301, 0.9263, 0.9699, 0.9042, 0.9309, 0.9109, 0.9556,\n",
       "                       0.9096, 0.8710, 0.9129, 0.9366, 0.9085, 0.8339, 0.9782, 0.9003, 0.9386,\n",
       "                       0.9478, 0.9930, 0.9072, 0.9759, 0.9657, 0.9496, 0.9155, 0.9738, 0.9843,\n",
       "                       0.9886, 0.9161, 0.9890, 0.8642, 0.8777, 0.9493, 0.9813, 0.9282, 0.8543,\n",
       "                       0.9504, 1.0099, 0.9353, 0.7950, 0.8416, 0.9650, 1.0052, 0.8969, 0.8982,\n",
       "                       0.8817, 0.8360, 0.8707, 0.9072, 0.8979, 0.9060, 0.9535, 0.9970, 0.9511,\n",
       "                       0.9836, 0.8933, 0.8748, 0.8891, 0.8927, 0.9804, 0.8924, 0.9661, 0.9155,\n",
       "                       0.9782, 0.8882, 0.8763, 0.9353, 0.5914, 0.9072, 0.9363, 0.8599, 1.0968,\n",
       "                       0.7363, 0.9454, 0.9654, 0.9234, 0.9582, 0.8851, 0.9307, 1.0060, 0.9901,\n",
       "                       0.8963, 0.9993, 0.9202, 0.9333], device='mps:0')),\n",
       "              ('transformer.h.0.ln_2.bias',\n",
       "               tensor([ 1.8222e-01, -2.6241e-01,  8.4725e-03, -7.9450e-02,  2.9137e-02,\n",
       "                        7.7522e-02,  3.7035e-03, -2.5654e-01,  7.6329e-02, -8.9665e-03,\n",
       "                       -1.5850e-01,  4.9391e-02,  3.4020e-02, -9.7449e-02,  1.0587e-01,\n",
       "                       -7.3298e-02, -6.5865e-02, -3.1382e-01,  7.4240e-02, -1.1865e-01,\n",
       "                        8.9477e-02,  8.1671e-02, -8.9012e-02,  8.0740e-02, -6.1424e-02,\n",
       "                        1.1469e-01, -2.0818e-01, -1.3289e-01,  7.1088e-02, -1.1085e-01,\n",
       "                       -8.9467e-03, -2.3625e-01,  1.7689e-01,  2.0871e-01, -2.5517e-02,\n",
       "                       -9.3151e-02,  1.3339e-02,  1.2852e-01,  1.3667e-01,  4.3135e-02,\n",
       "                       -1.8753e-01,  4.2305e-02, -1.2761e-01,  8.6897e-02,  6.4623e-02,\n",
       "                        2.1059e-02, -4.3271e-02,  3.3819e-02, -1.3208e-01, -2.7299e-01,\n",
       "                       -1.9713e-01, -1.8689e-01,  6.6741e-02,  8.7356e-03,  1.6734e-01,\n",
       "                        1.3647e-01, -1.3232e-01, -5.6115e-02,  1.0895e-01, -2.9225e-03,\n",
       "                       -3.5906e-02, -1.4406e-01, -1.1978e-01,  4.8239e-02,  2.7164e-01,\n",
       "                       -2.8215e-01,  9.8788e-02, -7.4765e-02,  3.7892e-02, -7.8454e-02,\n",
       "                        5.3236e-02, -5.3016e-05, -2.8390e-02,  1.5798e-01, -2.4786e-01,\n",
       "                       -1.2432e-01,  2.4618e-02, -1.5711e-01, -2.0778e-01,  9.2117e-02,\n",
       "                        1.5620e-01, -2.4452e-01, -5.5888e-03, -9.7353e-02,  2.0010e-01,\n",
       "                       -1.5090e-01, -9.6854e-02, -7.2739e-02, -3.1426e-02, -9.6764e-05,\n",
       "                       -4.0886e-02,  2.2220e-02, -7.5700e-04, -3.0203e-02, -3.0026e-01,\n",
       "                       -7.7922e-02,  1.0731e-01, -1.5525e-01, -1.2209e-02,  1.6177e-02,\n",
       "                       -5.0704e-02, -5.2805e-02, -8.7722e-02,  6.8505e-02, -1.1712e-01,\n",
       "                       -1.9502e-02,  8.8571e-02, -1.3026e-01,  1.2726e-01,  8.5881e-02,\n",
       "                       -1.1726e-01, -1.0233e-01,  8.4306e-02,  1.4012e-01, -1.4832e-01,\n",
       "                        5.0183e-02,  1.5769e-01,  5.0187e-02, -1.3948e-01, -1.1839e-01,\n",
       "                        1.5450e-02,  1.3724e-01, -8.4674e-02, -3.2512e-02, -3.2202e-02,\n",
       "                       -2.5143e-01, -1.2173e-02, -3.1154e-01,  3.6421e-02,  1.7407e-01,\n",
       "                       -1.0457e-02,  1.4955e-01,  1.5429e-01, -8.6002e-02, -6.5504e-02,\n",
       "                       -5.0751e-02,  6.4679e-02,  8.5619e-02, -4.5647e-02, -6.9709e-02,\n",
       "                        2.8262e-01, -9.6422e-02,  1.6334e-01, -6.8544e-02,  1.6773e-01,\n",
       "                       -2.1426e-01,  2.5499e-01, -3.3844e-01, -4.1895e-02,  1.6335e-02,\n",
       "                       -8.4573e-03,  1.2193e-01,  1.5144e-01, -8.8356e-02, -4.1529e-02,\n",
       "                       -1.4125e-01,  4.3823e-02, -4.4018e-02,  2.0633e-01,  6.6040e-02,\n",
       "                       -1.3777e-01,  2.5802e-02, -4.6913e-02, -9.5130e-02, -7.5378e-02,\n",
       "                       -8.4971e-02,  7.2060e-03, -5.2028e-02, -9.8749e-02,  6.5167e-02,\n",
       "                       -1.2318e-01,  5.3658e-01,  1.0533e-01, -4.3373e-02, -9.8466e-02,\n",
       "                       -3.4458e-02,  9.1770e-03, -3.4684e-02, -3.1764e-02, -4.1344e-02,\n",
       "                        9.3881e-03, -7.7334e-02, -1.4285e-01, -1.0857e-01, -7.2022e-02,\n",
       "                        1.1611e-01,  3.0747e-01,  2.4654e-02, -1.3850e-01, -3.0654e-02,\n",
       "                       -7.5946e-02,  3.5455e-02, -1.8399e-01, -3.2089e-02, -5.6464e-02,\n",
       "                       -5.2029e-02,  1.0624e-02,  1.7179e-02, -4.9640e-02, -4.6467e-02,\n",
       "                        1.0796e-01, -1.1904e-01, -7.3783e-02, -1.5227e-01, -1.7798e-01,\n",
       "                        4.4784e-02, -3.0317e-01, -5.5257e-02, -1.2148e-02,  1.8688e-02,\n",
       "                       -1.5179e-01, -3.6750e-01,  1.4882e-01,  7.1703e-02,  1.0749e-02,\n",
       "                       -5.9976e-02, -2.7489e-03,  8.6528e-02, -1.6208e-01, -1.5065e-01,\n",
       "                       -6.5606e-02, -8.4892e-02, -1.2667e-02, -7.7106e-02, -7.5310e-02,\n",
       "                        1.4467e-01, -6.0754e-02,  1.3781e-02, -1.2177e-01,  7.6913e-02,\n",
       "                       -1.3769e-01,  1.7287e-01, -2.4359e-01,  2.7029e-02, -1.2574e-01,\n",
       "                       -8.6629e-03, -7.6790e-02,  2.8097e-01,  3.0488e-01,  3.0026e-02,\n",
       "                       -1.4006e-01, -1.2867e-01, -1.0121e-02, -2.8096e-01,  6.7537e-03,\n",
       "                       -1.0811e-01,  3.5227e-02, -9.7856e-02,  1.0746e-01, -8.0695e-02,\n",
       "                        3.6232e-02, -6.6065e-02, -9.7943e-02,  1.1368e-01,  9.2288e-02,\n",
       "                       -2.6109e-01], device='mps:0')),\n",
       "              ('transformer.h.0.mlp.c_fc.weight',\n",
       "               tensor([[ 0.0008,  0.0512, -0.0303,  ...,  0.0422,  0.0183,  0.1438],\n",
       "                       [-0.0170,  0.0141, -0.0201,  ..., -0.0278, -0.0008,  0.1052],\n",
       "                       [ 0.0216,  0.0833, -0.0455,  ...,  0.1298, -0.0194,  0.1381],\n",
       "                       ...,\n",
       "                       [-0.1986,  0.0512,  0.0325,  ...,  0.0303,  0.0010,  0.1349],\n",
       "                       [-0.0699,  0.0531, -0.0799,  ...,  0.0563, -0.0457,  0.1182],\n",
       "                       [ 0.0797,  0.0349,  0.0828,  ..., -0.0780,  0.0284,  0.1031]],\n",
       "                      device='mps:0')),\n",
       "              ('transformer.h.0.mlp.c_fc.bias',\n",
       "               tensor([-0.0758,  0.0009, -0.1438,  ..., -0.0639, -0.0597, -0.2470],\n",
       "                      device='mps:0')),\n",
       "              ('transformer.h.0.mlp.c_proj.weight',\n",
       "               tensor([[ 0.0125, -0.0163, -0.0181,  ...,  0.0519, -0.0281,  0.0815],\n",
       "                       [-0.0922, -0.0753, -0.0690,  ..., -0.0251, -0.0477,  0.0898],\n",
       "                       [-0.0224, -0.0513,  0.0275,  ...,  0.0008, -0.0012,  0.0558],\n",
       "                       ...,\n",
       "                       [-0.0204, -0.0357, -0.1314,  ...,  0.0435, -0.0483,  0.0122],\n",
       "                       [ 0.0417,  0.0490,  0.0305,  ..., -0.0278,  0.0260, -0.0371],\n",
       "                       [ 0.0125,  0.0453, -0.1068,  ..., -0.0927, -0.0327,  0.1118]],\n",
       "                      device='mps:0')),\n",
       "              ('transformer.h.0.mlp.c_proj.bias',\n",
       "               tensor([ 3.0851e-03, -4.7106e-03, -2.1077e-03,  7.7303e-02,  2.5480e-02,\n",
       "                        6.5193e-02, -6.6386e-03,  4.5981e-03,  4.1350e-02, -8.9290e-02,\n",
       "                        4.6777e-02, -7.4364e-02, -1.9742e-02, -2.6458e-02,  8.7385e-03,\n",
       "                       -1.0968e-01,  1.0619e-02,  1.2138e-02, -5.2767e-02, -2.9158e-02,\n",
       "                        3.9614e-02, -1.8895e-02,  4.5445e-02, -7.8713e-02, -5.8730e-02,\n",
       "                        5.1861e-02,  1.9295e-02,  2.5381e-02,  3.3067e-02,  4.3666e-02,\n",
       "                       -4.0690e-02,  3.5440e-02, -1.6944e-02,  2.5475e-02,  2.3183e-03,\n",
       "                        5.0556e-02,  1.3079e-02, -2.8994e-02,  6.4337e-02,  2.2992e-02,\n",
       "                        2.0319e-02, -2.9399e-02, -7.9638e-04, -1.2289e-02, -4.5412e-02,\n",
       "                       -6.2662e-02, -1.7817e-02, -6.0833e-02,  2.4710e-02, -2.0013e-02,\n",
       "                        1.1191e-01, -3.5796e-02, -3.0741e-02,  3.2257e-02,  2.7374e-02,\n",
       "                        6.3836e-02,  2.6644e-02,  6.2836e-03,  4.6588e-02,  2.3077e-02,\n",
       "                       -5.6444e-02,  3.3982e-02, -5.2511e-02, -2.0980e-02, -6.3538e-02,\n",
       "                        3.7729e-02, -1.2763e-02,  3.6947e-02,  1.0193e-01,  2.3243e-02,\n",
       "                        2.7296e-02, -6.3362e-02, -6.7538e-03, -3.4640e-02,  1.3944e-02,\n",
       "                        4.5787e-02,  9.3935e-03, -1.1942e-01, -1.2649e-02,  5.2672e-02,\n",
       "                        3.8371e-02, -1.4672e-02, -7.8696e-03, -6.9093e-03, -4.8686e-02,\n",
       "                        1.6212e-02,  5.3636e-04,  3.9530e-03, -1.1452e-02,  3.6172e-03,\n",
       "                       -1.4765e-02, -1.4325e-02, -3.4578e-02, -9.8735e-03, -8.0242e-03,\n",
       "                        5.3544e-02,  1.2270e-02, -5.3180e-03, -2.7817e-02, -4.6828e-02,\n",
       "                       -4.0466e-03,  2.8779e-02,  4.5878e-02, -1.1672e-02, -4.4190e-02,\n",
       "                       -7.7301e-03,  1.0064e-02, -1.4698e-02,  1.3725e-02,  7.0202e-02,\n",
       "                       -2.1715e-02, -9.3630e-03, -7.4178e-03, -1.3144e-02, -2.3050e-02,\n",
       "                        4.0819e-02,  2.0991e-02, -1.3823e-03,  5.5540e-02, -1.1460e-02,\n",
       "                        5.6384e-03,  9.3424e-03,  5.3029e-02, -5.6872e-03, -5.6989e-02,\n",
       "                        5.8735e-02, -2.5687e-02, -5.7218e-04, -2.4275e-02,  1.3014e-02,\n",
       "                        1.1132e-02,  6.1295e-02,  2.3920e-02,  2.4313e-02,  2.8922e-02,\n",
       "                       -6.8822e-03, -2.1697e-02, -1.4904e-02, -2.2801e-02, -4.0305e-03,\n",
       "                       -5.8030e-03,  1.9474e-02,  4.3027e-02, -3.9992e-02,  2.9539e-02,\n",
       "                       -3.0474e-02,  3.3358e-02, -8.2333e-02, -4.4974e-04,  4.7587e-02,\n",
       "                        2.9146e-02,  3.6514e-03,  5.3333e-02,  1.9121e-02, -2.5707e-02,\n",
       "                       -1.2488e-02, -5.8356e-02, -1.1190e-02,  1.9098e-02, -8.0030e-02,\n",
       "                       -6.1034e-03, -1.2386e-02,  3.6270e-02,  3.9274e-02, -6.1289e-02,\n",
       "                        5.5439e-02, -2.0428e-02,  5.1111e-02,  3.4373e-02, -1.8919e-02,\n",
       "                       -1.6659e-03, -3.3349e-02, -9.6828e-02,  4.8278e-02, -2.5843e-02,\n",
       "                       -8.8741e-03,  4.7559e-02, -5.9819e-03,  4.3810e-02,  3.2845e-02,\n",
       "                        1.8318e-04,  1.3942e-04,  4.5496e-02, -1.5879e-02,  7.0495e-04,\n",
       "                        6.3538e-02, -7.8517e-02,  2.6642e-02,  5.8759e-02, -2.7793e-03,\n",
       "                       -3.2987e-02, -3.8437e-02,  5.9774e-02, -7.8503e-02,  8.9088e-02,\n",
       "                       -9.9405e-04, -3.2644e-03,  1.1489e-02,  4.9674e-02, -4.7024e-02,\n",
       "                       -1.0321e-02,  2.9189e-02,  4.8771e-02,  3.5064e-02, -3.2182e-02,\n",
       "                       -1.5679e-02, -3.1805e-02,  9.4697e-03, -5.1657e-02, -5.2641e-02,\n",
       "                       -2.3253e-02, -2.2587e-02, -1.3564e-03,  2.8779e-02, -2.1330e-02,\n",
       "                       -2.1010e-02,  1.7502e-02, -1.2875e-02, -4.6108e-03, -4.2103e-02,\n",
       "                       -3.3982e-02, -4.1472e-02,  3.8526e-04, -3.6497e-03,  1.0312e-02,\n",
       "                       -5.8014e-02,  2.0342e-02,  7.6697e-02, -3.3316e-02, -1.4822e-02,\n",
       "                        1.6176e-02,  5.2630e-02,  7.1344e-04, -4.1003e-03, -1.8667e-02,\n",
       "                       -5.6553e-02, -4.2349e-02, -3.3724e-02,  2.1898e-01,  6.0379e-02,\n",
       "                        3.9125e-02, -2.3831e-02,  7.1528e-02, -7.2868e-02, -7.6408e-04,\n",
       "                       -3.3736e-02, -5.5244e-02, -2.9433e-02, -8.2434e-02,  3.4797e-02,\n",
       "                        2.8162e-02, -4.5995e-02, -1.2050e-02,  2.5215e-02,  1.2894e-02,\n",
       "                        5.3078e-03], device='mps:0')),\n",
       "              ('transformer.h.1.ln_1.weight',\n",
       "               tensor([1.0311, 1.0535, 1.1545, 1.0499, 1.0865, 0.9338, 1.0568, 1.0345, 1.0825,\n",
       "                       1.0705, 1.0216, 1.0371, 1.0786, 1.0927, 1.0807, 1.0149, 1.1392, 1.0378,\n",
       "                       1.0375, 1.0115, 1.0927, 1.1042, 1.1465, 1.1393, 1.1099, 1.0034, 1.1193,\n",
       "                       1.0951, 1.0678, 1.0816, 1.0847, 1.1567, 1.0797, 1.0026, 1.0438, 1.0580,\n",
       "                       1.0837, 1.0799, 1.0404, 1.0727, 1.0588, 1.0692, 1.0297, 1.1093, 1.0746,\n",
       "                       1.0815, 1.1017, 1.0669, 1.0758, 1.1008, 1.0556, 0.9061, 1.1174, 1.1275,\n",
       "                       1.0890, 1.1167, 1.0744, 0.9766, 1.0466, 1.1073, 1.0476, 1.1385, 1.0160,\n",
       "                       1.0769, 1.0736, 1.1183, 1.0640, 1.0353, 1.0758, 1.0683, 1.0431, 1.0925,\n",
       "                       1.1278, 1.0633, 1.0517, 1.1035, 1.0877, 1.0575, 1.1148, 1.0922, 1.0632,\n",
       "                       1.0596, 1.0627, 1.0603, 1.0432, 1.0902, 0.9752, 1.1066, 1.0544, 1.0811,\n",
       "                       1.1178, 1.0230, 1.1190, 1.0935, 1.0378, 1.0027, 1.1053, 1.0677, 1.0639,\n",
       "                       1.0185, 1.1458, 1.1154, 1.0890, 1.1141, 1.0723, 1.0260, 1.0825, 1.0204,\n",
       "                       1.0903, 1.1015, 1.1146, 1.0211, 1.0584, 1.1082, 1.0975, 1.0245, 1.0123,\n",
       "                       1.0965, 1.0350, 1.0846, 1.1177, 1.0250, 1.0363, 1.0807, 1.0868, 1.0545,\n",
       "                       1.1044, 1.0868, 0.9874, 1.0608, 0.9969, 1.0129, 1.1009, 1.1551, 1.0451,\n",
       "                       1.0432, 1.0682, 0.9997, 1.1100, 1.0719, 1.0237, 1.0541, 1.0860, 1.1536,\n",
       "                       1.0723, 1.0925, 1.0311, 1.0665, 1.0579, 1.0854, 1.0410, 1.0906, 1.0779,\n",
       "                       1.1024, 1.0968, 1.0105, 1.1267, 1.1295, 1.1010, 1.0517, 1.0570, 1.0690,\n",
       "                       1.0797, 1.0786, 1.1374, 1.0420, 1.0920, 1.0892, 1.0566, 1.1554, 1.0390,\n",
       "                       1.0078, 1.0378, 1.0942, 1.1107, 1.1320, 1.0498, 1.0297, 1.0946, 1.0961,\n",
       "                       1.0202, 1.0398, 1.1156, 1.0423, 1.1032, 1.0117, 1.0884, 1.0525, 1.0829,\n",
       "                       1.1071, 1.0864, 1.0501, 1.1318, 1.1359, 1.1234, 1.0728, 1.1050, 1.0626,\n",
       "                       1.0865, 1.0498, 1.1215, 1.0807, 1.0567, 1.0850, 1.1212, 1.0354, 0.9131,\n",
       "                       1.0834, 1.1141, 1.1037, 0.8805, 0.9421, 1.1337, 1.1135, 1.0221, 1.0088,\n",
       "                       1.0532, 0.9611, 1.0256, 1.0738, 1.0317, 0.9838, 1.0837, 1.1337, 1.0885,\n",
       "                       1.0699, 1.0348, 1.0506, 1.0419, 1.0388, 1.0814, 1.0945, 1.1010, 1.0422,\n",
       "                       1.0643, 1.0830, 1.0240, 1.0333, 0.7902, 1.0129, 1.1140, 1.0979, 1.0914,\n",
       "                       0.8546, 1.0823, 1.0380, 1.0530, 1.0735, 1.0241, 1.1166, 1.0686, 1.1299,\n",
       "                       1.0810, 1.0693, 1.0370, 1.1023], device='mps:0')),\n",
       "              ('transformer.h.1.ln_1.bias',\n",
       "               tensor([-0.0193, -0.0966, -0.0672, -0.0083,  0.0775,  0.1331,  0.0093,  0.0252,\n",
       "                       -0.0339, -0.0429, -0.0031, -0.0098,  0.0096,  0.0091,  0.1426, -0.0187,\n",
       "                       -0.0448,  0.0371, -0.0064,  0.0021, -0.0007, -0.0186, -0.0479,  0.0397,\n",
       "                        0.0060,  0.0151, -0.0236,  0.0526,  0.0188,  0.0323, -0.0334, -0.0550,\n",
       "                        0.0669,  0.0682,  0.1214,  0.0293,  0.0177,  0.0542,  0.0180, -0.0035,\n",
       "                       -0.1083,  0.0163, -0.0045, -0.0172,  0.0528,  0.0720,  0.0591, -0.0098,\n",
       "                        0.0402, -0.1461, -0.0127, -0.1476, -0.0427,  0.0322,  0.0251,  0.0490,\n",
       "                       -0.0384, -0.0427, -0.0415, -0.0090,  0.0753, -0.0584, -0.0718,  0.0404,\n",
       "                        0.0543, -0.1119, -0.0216, -0.0013,  0.0184,  0.0351, -0.0051, -0.0891,\n",
       "                        0.0084, -0.0199,  0.0190,  0.0089, -0.0256, -0.0508, -0.0531,  0.0518,\n",
       "                       -0.0462, -0.0716, -0.0118, -0.0601,  0.0473, -0.0904,  0.0201, -0.0574,\n",
       "                        0.0827,  0.0641,  0.0077,  0.0369,  0.0533, -0.0027, -0.0885, -0.0453,\n",
       "                        0.0857,  0.0659, -0.0111,  0.0005, -0.0459, -0.0438, -0.0181, -0.0184,\n",
       "                       -0.0264, -0.0016,  0.0149, -0.0123,  0.0746,  0.0165,  0.0093, -0.0197,\n",
       "                        0.0523,  0.0110,  0.0165,  0.0014,  0.0104,  0.0525,  0.0464, -0.0411,\n",
       "                       -0.0687,  0.0124,  0.0147,  0.0920, -0.0437,  0.0551,  0.0784, -0.0117,\n",
       "                        0.0083,  0.0270,  0.0317,  0.0682,  0.0005,  0.0076, -0.0314, -0.0258,\n",
       "                        0.0602,  0.0331,  0.0025, -0.0409,  0.0789, -0.0942,  0.0426,  0.0217,\n",
       "                        0.1385, -0.0933,  0.1181, -0.0417,  0.0882,  0.0527, -0.0386,  0.1024,\n",
       "                       -0.0580, -0.0620, -0.0349, -0.1006,  0.1186,  0.0667,  0.0206,  0.0012,\n",
       "                       -0.0242,  0.0984,  0.1056, -0.0603, -0.1065, -0.0228, -0.0042, -0.0518,\n",
       "                       -0.0045,  0.0438, -0.1120,  0.0414, -0.0675,  0.0435,  0.0225,  0.0514,\n",
       "                        0.0499,  0.0391,  0.0487,  0.0451,  0.0827,  0.0515, -0.0685, -0.0858,\n",
       "                       -0.0049,  0.0246,  0.0738,  0.1037, -0.1020,  0.0145, -0.0755, -0.0060,\n",
       "                       -0.0060,  0.0266, -0.1257, -0.0550, -0.0152,  0.0004, -0.0050, -0.0013,\n",
       "                        0.0073, -0.0396, -0.0408, -0.0630, -0.0016,  0.0387,  0.0687, -0.0068,\n",
       "                        0.0130,  0.0965,  0.0619, -0.0094, -0.0703,  0.0185,  0.0039, -0.0237,\n",
       "                        0.0232,  0.0931, -0.0413, -0.0527,  0.0118,  0.0716,  0.0477, -0.0140,\n",
       "                        0.0135,  0.0370, -0.0398,  0.1043,  0.0172, -0.0259,  0.0433,  0.0596,\n",
       "                       -0.0483,  0.0033, -0.0739,  0.0597, -0.0480,  0.0523,  0.2833,  0.0158,\n",
       "                       -0.0700,  0.0139, -0.0824, -0.2226, -0.0612, -0.0053, -0.1266, -0.0141,\n",
       "                        0.0822,  0.0055,  0.0372, -0.0403, -0.0122,  0.0570, -0.0073, -0.0319],\n",
       "                      device='mps:0')),\n",
       "              ('transformer.h.1.attn.bias',\n",
       "               tensor([[[[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "                         [1., 1., 0.,  ..., 0., 0., 0.],\n",
       "                         [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "                         ...,\n",
       "                         [1., 1., 1.,  ..., 1., 0., 0.],\n",
       "                         [1., 1., 1.,  ..., 1., 1., 0.],\n",
       "                         [1., 1., 1.,  ..., 1., 1., 1.]]]], device='mps:0')),\n",
       "              ('transformer.h.1.attn.c_attn.weight',\n",
       "               tensor([[ 0.0356,  0.0767,  0.0302,  ..., -0.0129, -0.0376,  0.0276],\n",
       "                       [-0.0534,  0.0237, -0.0442,  ...,  0.0749, -0.0410,  0.0277],\n",
       "                       [ 0.0330,  0.0837,  0.0601,  ..., -0.0090,  0.0595,  0.0012],\n",
       "                       ...,\n",
       "                       [-0.0791, -0.0413, -0.0306,  ...,  0.0710, -0.1322, -0.0512],\n",
       "                       [ 0.0078, -0.0711,  0.1040,  ...,  0.0859,  0.0623,  0.0416],\n",
       "                       [ 0.0655,  0.0478, -0.0461,  ...,  0.1320,  0.1064, -0.0548]],\n",
       "                      device='mps:0')),\n",
       "              ('transformer.h.1.attn.c_attn.bias',\n",
       "               tensor([ 6.2490e-02, -7.7403e-02, -2.6012e-01,  1.6138e-01, -2.2834e-02,\n",
       "                       -3.3574e-01,  6.3691e-03,  2.1147e-01,  9.3285e-02, -3.1593e-01,\n",
       "                        7.4418e-02, -9.0262e-02,  3.5254e-01, -2.5806e-01, -3.8541e-01,\n",
       "                        2.8865e-01,  1.2431e-01, -1.2508e-01, -1.6247e-01,  6.9143e-02,\n",
       "                       -1.4433e-01, -9.2640e-02,  1.8200e-01, -2.1368e-01, -2.3583e-01,\n",
       "                       -4.7829e-02, -2.6451e-01, -2.1861e-01,  3.3763e-01,  2.0763e-01,\n",
       "                       -7.0819e-03,  1.5780e-01, -3.5228e-02,  1.8058e-01,  9.4785e-03,\n",
       "                        8.7038e-02,  3.1216e-01, -6.4001e-02,  1.2551e-01, -2.3741e-01,\n",
       "                        1.7639e-01,  4.0985e-02,  3.4224e-01,  3.3121e-01,  7.0081e-02,\n",
       "                        1.3430e-01, -6.6286e-02, -1.0901e-01,  2.7236e-01, -7.2918e-03,\n",
       "                       -6.4503e-02,  6.5641e-02,  2.1151e-01,  1.5909e-03,  1.6219e-02,\n",
       "                        2.8325e-01, -2.1592e-01, -1.2367e-02,  2.5658e-01,  1.0214e-01,\n",
       "                        1.7522e-01, -1.2526e-01, -4.0536e-02, -3.1370e-01, -3.5959e-01,\n",
       "                        2.4361e-01, -1.4328e-02,  2.0610e-01, -3.1771e-01,  4.2918e-02,\n",
       "                        7.8208e-02, -1.6368e-01, -1.3981e-01,  2.5368e-01, -2.1219e-01,\n",
       "                       -3.6007e-01,  6.9773e-02, -1.3796e-01,  1.9369e-01, -2.3824e-01,\n",
       "                       -1.6858e-01, -1.9081e-01,  3.7456e-02,  4.3933e-02,  1.9317e-01,\n",
       "                       -2.5078e-01, -2.5488e-01, -2.5059e-01, -6.6603e-02,  1.6113e-01,\n",
       "                       -1.0284e-01,  2.8368e-02,  3.4051e-01, -2.2379e-01, -3.6185e-01,\n",
       "                       -3.1531e-01,  2.6599e-01,  3.2596e-02, -1.5726e-02, -4.8478e-02,\n",
       "                        1.5608e-01,  2.1120e-01,  1.9143e-01, -3.0108e-01,  6.5258e-02,\n",
       "                       -2.2263e-01, -3.3016e-01, -1.8175e-01, -2.8994e-01, -2.1819e-01,\n",
       "                       -1.7793e-01,  3.2298e-01,  1.8557e-01, -4.8076e-01, -1.0217e-01,\n",
       "                       -1.9129e-02,  2.7985e-01,  6.7865e-02, -5.4600e-02,  3.1892e-01,\n",
       "                       -4.3276e-01, -1.2036e-01,  7.9829e-02,  2.6349e-01, -2.1028e-01,\n",
       "                       -2.2429e-01,  5.0869e-02, -1.1170e-01,  1.4627e-01,  2.5222e-02,\n",
       "                        2.5433e-01,  1.8455e-01, -4.2072e-02, -1.6743e-01,  3.6539e-01,\n",
       "                       -1.6479e-01, -1.4465e-01, -2.5552e-01,  4.6918e-01, -1.6095e-01,\n",
       "                       -1.3496e-01, -8.4252e-02, -2.6293e-02, -1.2431e-01, -1.5227e-01,\n",
       "                        2.1600e-01,  1.7708e-02,  2.3464e-01, -3.0497e-01,  2.9366e-01,\n",
       "                        3.1380e-01,  2.9447e-01,  1.4936e-01,  1.4098e-01,  3.2755e-01,\n",
       "                       -2.2595e-01, -1.5076e-01,  2.6714e-01, -3.5453e-02,  2.2814e-01,\n",
       "                       -2.3378e-01, -1.2839e-01,  4.4962e-02, -1.4276e-01, -2.2654e-02,\n",
       "                        1.6543e-01,  2.5706e-01, -1.3355e-01,  2.3161e-01,  2.0039e-01,\n",
       "                       -3.0055e-01, -1.3470e-01, -3.6195e-02, -3.1410e-01,  1.1833e-01,\n",
       "                       -1.7720e-01,  1.1904e-01,  2.2014e-02,  1.0941e-02,  1.0767e-01,\n",
       "                        5.8672e-02,  1.9245e-01, -1.8404e-01, -1.4878e-01, -2.9868e-01,\n",
       "                        2.0341e-01,  6.9789e-02,  2.9718e-01, -3.3484e-01, -3.1736e-01,\n",
       "                       -1.3053e-01,  8.2243e-02, -1.4247e-01,  1.6830e-01,  2.0909e-01,\n",
       "                        7.1477e-02,  2.0020e-01, -3.9203e-02,  1.4373e-01, -9.6806e-02,\n",
       "                       -2.3118e-01, -1.0383e-01, -1.3246e-01,  1.5789e-01, -3.2913e-01,\n",
       "                        3.6952e-01, -1.2702e-01,  1.7773e-01,  7.8116e-02,  1.1539e-02,\n",
       "                       -1.1826e-01, -2.2742e-01,  8.4559e-02, -3.0590e-04, -7.9919e-02,\n",
       "                        1.5599e-01, -1.3969e-01, -3.9238e-01,  1.2461e-01, -2.1279e-01,\n",
       "                        1.7110e-01, -9.4742e-02, -2.5199e-02,  9.6682e-02,  1.0361e-01,\n",
       "                        4.0752e-01,  1.3534e-01, -5.4792e-03, -3.3151e-02, -2.1668e-01,\n",
       "                       -1.4056e-01,  2.5304e-01,  9.0568e-02,  2.5216e-02, -5.0602e-03,\n",
       "                        4.0197e-01,  1.1325e-01,  1.0715e-01, -1.0964e-01,  6.1419e-02,\n",
       "                       -2.1526e-01,  2.7123e-01,  1.6570e-01,  3.7583e-01, -5.4665e-02,\n",
       "                        3.9093e-02,  3.0983e-01,  1.9970e-01, -1.0153e-01, -1.1531e-01,\n",
       "                        6.8990e-02, -2.9164e-01, -2.2603e-01,  2.1317e-01,  2.0792e-01,\n",
       "                        2.1477e-01, -2.5254e-02, -2.8277e-02,  1.2123e-03,  2.3865e-02,\n",
       "                       -2.4917e-02, -2.6203e-02, -4.8591e-02, -5.6277e-02,  5.2240e-02,\n",
       "                        3.4333e-02,  3.9662e-02, -3.8673e-03,  7.4598e-03, -1.6987e-02,\n",
       "                        7.1992e-03,  3.7435e-02, -5.2294e-02,  4.2502e-02, -4.0357e-02,\n",
       "                       -2.7998e-03,  1.3097e-02, -3.0807e-02, -3.3992e-02,  4.0150e-02,\n",
       "                        4.5208e-02,  3.0372e-02, -1.0549e-02, -4.7446e-02, -5.8550e-02,\n",
       "                       -1.5187e-02,  2.2926e-02,  2.5036e-02, -3.5675e-03,  5.2761e-02,\n",
       "                       -5.8091e-02, -6.0060e-02, -2.1688e-02, -1.7044e-02, -6.1347e-02,\n",
       "                        1.7007e-02, -1.0027e-03, -3.8574e-02,  4.9154e-02, -5.4355e-02,\n",
       "                        4.1423e-02,  4.2870e-03, -5.6188e-02,  5.4955e-02, -1.7600e-03,\n",
       "                        4.6217e-02, -5.9367e-05,  4.9488e-02,  3.3835e-02, -5.3905e-02,\n",
       "                       -6.4332e-02, -4.0866e-02,  3.5305e-02,  4.7282e-02, -2.7300e-02,\n",
       "                        3.8647e-02, -5.3559e-02, -2.0603e-02, -4.0406e-03,  3.5274e-02,\n",
       "                        2.3512e-02,  5.4173e-02,  5.5511e-02, -1.7597e-02,  2.2774e-02,\n",
       "                       -3.5731e-02, -3.8371e-02, -1.1957e-02, -5.3333e-02,  3.9619e-02,\n",
       "                       -2.0324e-02, -3.1939e-02,  1.1798e-02,  2.2615e-03, -4.8331e-02,\n",
       "                        8.3547e-03, -2.4944e-02, -1.2036e-02, -1.1228e-02, -4.0003e-03,\n",
       "                       -3.4700e-02,  3.6429e-02, -4.3198e-02, -2.4779e-03, -2.8407e-02,\n",
       "                       -1.3580e-02, -5.5778e-02, -4.5284e-02, -3.8663e-03, -1.5654e-02,\n",
       "                       -2.3194e-02,  2.7838e-02, -4.2202e-02, -4.5623e-02,  1.5509e-02,\n",
       "                       -3.8108e-02, -4.6987e-02,  8.0083e-03,  5.9879e-02, -5.6062e-03,\n",
       "                        3.5725e-02, -3.4319e-02, -1.8001e-02,  5.0468e-02,  4.6123e-02,\n",
       "                       -4.1162e-03,  4.2123e-02,  3.0823e-02,  2.6551e-02, -2.4742e-02,\n",
       "                        5.3686e-03,  4.2677e-02,  5.8179e-02, -4.1986e-02, -4.1382e-02,\n",
       "                        5.7262e-02,  6.1442e-02, -2.8044e-02,  3.3804e-02, -3.7152e-03,\n",
       "                        4.2383e-02, -5.7441e-02, -1.4495e-02,  1.1829e-02,  4.1150e-02,\n",
       "                       -3.8588e-02,  3.9909e-02, -3.0718e-02,  3.5748e-02, -4.3556e-02,\n",
       "                        4.0213e-02, -1.2662e-02,  1.0112e-02,  4.6414e-03, -5.1851e-02,\n",
       "                        1.5298e-02, -3.1242e-02, -1.2593e-04, -2.4748e-02,  1.6539e-02,\n",
       "                        3.6025e-02, -2.1551e-02,  2.8652e-02,  1.4855e-02, -2.8336e-02,\n",
       "                        5.1082e-02,  4.0857e-03,  2.2344e-02,  1.4812e-02,  5.5985e-02,\n",
       "                       -5.1035e-02,  2.0129e-02, -2.4018e-02, -6.0377e-02,  1.2626e-02,\n",
       "                        6.0820e-03, -9.8285e-03,  2.2062e-02, -2.1870e-02, -3.8317e-02,\n",
       "                        4.6398e-02,  2.5150e-02, -4.3634e-02, -5.0416e-02,  5.1454e-03,\n",
       "                        2.5361e-04,  5.6754e-02, -5.4349e-02, -1.7509e-02,  1.5994e-02,\n",
       "                        1.2457e-02,  3.6186e-03,  2.2263e-02, -3.9634e-02,  1.2356e-02,\n",
       "                       -3.0114e-02,  7.7650e-03,  5.7929e-02, -5.7671e-02,  5.2997e-02,\n",
       "                       -1.3235e-02,  1.4660e-02, -1.4969e-02,  7.9689e-03, -1.3495e-02,\n",
       "                        5.4200e-02, -6.1510e-02, -1.9951e-02,  9.2054e-03,  6.4570e-02,\n",
       "                        4.8249e-02,  2.7266e-02, -3.6093e-02,  2.2060e-02,  5.2841e-02,\n",
       "                        5.0145e-02,  3.7897e-02,  1.9369e-02,  4.8692e-02, -6.0539e-03,\n",
       "                       -4.7926e-03, -2.9312e-03,  3.6980e-03, -8.8628e-03,  3.8619e-02,\n",
       "                       -2.6200e-02,  2.3889e-02, -1.0475e-02,  6.2281e-02, -4.9586e-02,\n",
       "                       -4.4127e-02, -2.8225e-02, -2.4269e-02,  4.0512e-02,  1.4432e-02,\n",
       "                       -6.2785e-02,  3.6175e-02,  1.6347e-02,  2.0775e-02, -6.7935e-03,\n",
       "                        6.0579e-02,  1.3272e-02,  6.2603e-02,  4.2564e-02,  3.8830e-02,\n",
       "                        8.4338e-03,  4.5023e-02, -3.4833e-02,  6.2774e-02,  7.3193e-03,\n",
       "                       -3.4034e-02, -3.5664e-02, -4.2483e-02,  2.6531e-02,  1.8456e-02,\n",
       "                        4.6772e-02,  8.9723e-03, -4.9199e-02,  7.0125e-03, -4.9095e-02,\n",
       "                        1.4158e-02,  1.8403e-02, -5.3381e-02,  5.8246e-02, -3.9215e-02,\n",
       "                       -3.5693e-02, -2.8825e-02,  5.7897e-02,  1.2868e-02,  2.8319e-02,\n",
       "                        4.1384e-02,  4.2767e-02, -4.0256e-02,  1.4891e-01, -1.2190e-01,\n",
       "                       -3.1421e-02, -1.0954e-01,  5.8231e-02, -6.0725e-02, -3.1859e-02,\n",
       "                        2.3286e-02,  2.7791e-02, -5.0239e-02, -3.0114e-02,  4.1219e-02,\n",
       "                       -8.1376e-02,  2.3160e-02, -3.6885e-02,  3.2692e-02,  4.7710e-02,\n",
       "                       -2.0466e-02, -5.7452e-02,  8.8276e-02, -4.4814e-03, -3.6234e-02,\n",
       "                        7.2460e-03, -1.6106e-02, -1.0071e-01,  5.2473e-02,  5.2840e-02,\n",
       "                        5.8970e-03, -4.3908e-02, -8.2252e-02,  7.7664e-02,  7.6145e-02,\n",
       "                        1.9169e-02, -1.9454e-02,  4.5184e-03, -3.2657e-02, -1.5526e-03,\n",
       "                        4.6544e-02,  5.1265e-02,  9.7920e-03, -1.0525e-01, -7.1495e-02,\n",
       "                       -1.6700e-02, -6.7571e-03,  6.8306e-03,  7.0272e-02, -7.9642e-02,\n",
       "                        8.3615e-02, -5.4422e-02,  1.3778e-01, -1.1332e-01, -4.2461e-02,\n",
       "                        2.6179e-02,  2.3653e-02,  4.8593e-02, -5.8105e-02, -6.3617e-02,\n",
       "                        7.3763e-02,  3.4874e-02, -1.0252e-01, -6.3994e-03, -2.0436e-03,\n",
       "                        5.1100e-02,  1.6632e-02,  3.4511e-02, -2.2100e-02,  3.5181e-02,\n",
       "                        3.9972e-02, -8.2602e-02, -1.4214e-02, -3.0539e-02,  3.4334e-02,\n",
       "                        1.2825e-01, -5.5645e-02,  8.5698e-02, -7.5059e-02, -9.9704e-02,\n",
       "                       -8.8427e-02, -3.2841e-02, -4.2180e-02,  4.1400e-02,  3.5984e-02,\n",
       "                       -2.0537e-02,  7.6898e-03,  3.6300e-02, -1.0429e-01,  5.0538e-02,\n",
       "                        1.7879e-02, -2.2697e-03,  4.3511e-02, -8.9720e-02, -3.7027e-02,\n",
       "                        3.9857e-02, -1.5545e-02,  3.9834e-02,  3.3447e-02,  9.6286e-02,\n",
       "                       -1.5877e-02, -1.0451e-01, -4.3253e-02, -2.5624e-02,  9.7469e-02,\n",
       "                       -3.8756e-02,  3.6747e-02, -4.3493e-03, -8.7555e-05,  5.3127e-02,\n",
       "                       -3.3925e-02,  1.1344e-01,  1.1029e-02, -2.4397e-02,  3.2618e-02,\n",
       "                       -5.0127e-03,  6.2193e-02, -2.6585e-02,  4.9084e-02,  1.1996e-02,\n",
       "                        2.9007e-02,  7.4916e-02, -1.0486e-01, -5.3990e-02, -8.6721e-02,\n",
       "                        2.4833e-02,  1.8241e-02,  7.7450e-02,  5.2748e-02,  5.0513e-02,\n",
       "                       -1.4133e-03, -4.7482e-02,  2.1268e-02,  7.6047e-02, -1.4076e-01,\n",
       "                       -2.1002e-02,  4.2439e-03, -2.9982e-02, -1.5627e-02,  6.3701e-02,\n",
       "                       -4.6584e-02, -2.7703e-02,  5.9421e-03, -3.9997e-02,  3.3325e-02,\n",
       "                       -1.7942e-02, -2.4755e-02, -1.1921e-02,  1.4505e-02, -2.9846e-02,\n",
       "                        9.7735e-02, -6.5600e-02,  3.9876e-03, -1.6187e-02,  5.0383e-02,\n",
       "                        1.8965e-02, -3.7924e-03, -1.9214e-02,  6.3259e-03,  5.0092e-02,\n",
       "                       -4.4678e-02,  8.3394e-04,  1.3877e-02, -1.0488e-02,  1.1021e-02,\n",
       "                       -5.0113e-02, -1.5111e-02, -6.2498e-02, -3.0052e-02, -5.7934e-03,\n",
       "                       -5.4064e-02,  2.3226e-04,  4.2501e-02, -9.2569e-03,  2.9524e-02,\n",
       "                        3.0309e-02,  5.9702e-02, -1.5779e-02, -4.0762e-02,  1.1230e-02,\n",
       "                       -6.3179e-02,  5.9936e-02, -3.1001e-02, -1.7476e-02,  5.9311e-02,\n",
       "                        4.4436e-02, -7.0900e-02, -8.8685e-03,  1.7923e-02, -7.0989e-02,\n",
       "                       -5.9072e-03, -1.0686e-02,  5.2125e-02, -8.7003e-03,  2.6778e-02,\n",
       "                       -8.1869e-02, -1.1780e-02,  2.1020e-02,  2.6746e-02,  8.2614e-03,\n",
       "                       -1.7456e-03, -3.3110e-02,  4.5933e-02,  1.3896e-02, -3.4261e-02,\n",
       "                       -4.3322e-02,  5.5702e-02,  3.4066e-02, -4.8410e-03, -5.5534e-02,\n",
       "                       -8.4388e-02, -7.0322e-02, -2.9222e-02, -4.1034e-02, -3.3308e-02,\n",
       "                       -1.0361e-01,  2.3375e-02, -7.4758e-03,  5.5306e-02,  8.0066e-02,\n",
       "                        1.9519e-02,  1.5339e-02, -4.9860e-03,  4.1625e-02, -1.3550e-02,\n",
       "                        4.6829e-02, -3.4455e-02,  8.0726e-02, -5.5670e-02, -1.9321e-03,\n",
       "                        8.6427e-02, -8.0471e-03,  1.5938e-03, -1.3139e-02,  7.1543e-02,\n",
       "                       -5.7559e-02, -2.5104e-02, -7.1206e-02, -2.3061e-02, -2.4515e-02,\n",
       "                        1.5988e-02,  6.8631e-03, -1.0869e-02,  4.3894e-02, -1.1934e-02,\n",
       "                       -9.4571e-03, -4.0310e-02, -9.3063e-02, -6.3371e-02,  6.7627e-02,\n",
       "                       -4.5994e-02, -1.9009e-02, -4.9948e-02, -3.8631e-02, -1.7268e-03,\n",
       "                       -3.2541e-02,  6.3205e-02,  1.3662e-02], device='mps:0')),\n",
       "              ('transformer.h.1.attn.c_proj.weight',\n",
       "               tensor([[-4.2993e-03,  9.4738e-02, -8.3900e-02,  ..., -2.0549e-03,\n",
       "                         7.4649e-02, -6.1894e-02],\n",
       "                       [ 1.7025e-02,  2.9533e-02,  4.8411e-02,  ...,  6.0643e-02,\n",
       "                         7.5693e-02, -1.0027e-02],\n",
       "                       [ 7.1821e-02,  3.0427e-02, -1.2217e-01,  ...,  4.5345e-02,\n",
       "                        -3.3190e-05,  4.7045e-02],\n",
       "                       ...,\n",
       "                       [-3.0503e-02, -6.6326e-02, -2.6065e-02,  ..., -1.1405e-02,\n",
       "                        -2.0664e-02, -8.6850e-03],\n",
       "                       [ 3.0675e-03,  2.1156e-02, -4.3152e-02,  ...,  3.2050e-02,\n",
       "                        -4.4902e-02, -1.5176e-02],\n",
       "                       [ 1.1298e-02, -1.0162e-02,  7.5463e-02,  ...,  2.6039e-02,\n",
       "                         4.7238e-02, -2.6456e-02]], device='mps:0')),\n",
       "              ('transformer.h.1.attn.c_proj.bias',\n",
       "               tensor([ 2.2822e-02,  4.3811e-02,  7.1651e-02,  4.5180e-02,  1.4521e-01,\n",
       "                       -6.6760e-02, -3.9567e-02, -5.4623e-02, -2.8525e-02, -4.6649e-03,\n",
       "                        7.5447e-02,  4.7869e-03, -9.1845e-02, -5.5897e-02, -6.4780e-02,\n",
       "                        2.1488e-03, -1.9671e-02, -3.4827e-02,  7.3595e-03, -1.0536e-01,\n",
       "                       -1.9016e-02,  8.0023e-03,  1.7180e-02, -1.0406e-01, -1.0527e-01,\n",
       "                        1.1249e-01,  1.4344e-02,  1.1146e-01,  6.1813e-02,  2.6942e-02,\n",
       "                       -3.8057e-02,  8.8310e-02, -9.3872e-02,  5.0190e-02, -3.7543e-02,\n",
       "                        7.5280e-02,  1.3529e-01,  1.9491e-02, -7.7275e-03,  5.4455e-02,\n",
       "                        6.6637e-02, -1.6582e-02, -5.1568e-02,  3.9961e-02,  1.8141e-01,\n",
       "                        1.0609e-02, -8.4106e-04, -7.8724e-02,  4.8546e-02,  3.1946e-02,\n",
       "                        2.8985e-02,  6.3223e-02, -9.3063e-02,  7.8608e-02,  5.0467e-02,\n",
       "                        5.1946e-02,  4.9081e-02,  3.4489e-03,  1.1202e-01, -2.7534e-03,\n",
       "                        3.1904e-02,  4.0217e-02,  1.0982e-02,  8.8120e-02, -1.3813e-02,\n",
       "                       -8.0343e-02,  1.8755e-02,  5.7287e-02,  4.7100e-02,  6.4580e-02,\n",
       "                        5.2354e-02, -6.1317e-02, -3.6352e-02,  1.0211e-01, -5.5999e-02,\n",
       "                        3.3396e-02,  8.1508e-02, -7.5280e-03,  5.9304e-02,  5.0744e-02,\n",
       "                       -8.6988e-02, -4.7073e-02,  2.4506e-02, -2.6427e-02,  4.5287e-03,\n",
       "                       -6.9870e-02,  2.7912e-02, -1.5486e-02,  7.4072e-02,  3.3566e-02,\n",
       "                       -1.5583e-02, -3.3133e-02, -3.2762e-03, -2.4616e-02, -1.0869e-01,\n",
       "                        7.7520e-02,  8.9455e-02, -8.2365e-02, -1.0312e-01,  9.2398e-02,\n",
       "                        3.1454e-02,  3.0846e-03,  6.1228e-02,  1.7813e-02,  1.5698e-02,\n",
       "                       -8.5268e-02,  1.4684e-01, -2.7219e-02,  1.2763e-01,  6.2684e-02,\n",
       "                       -1.2711e-02,  6.5129e-02, -5.9209e-02, -4.0555e-02, -4.8792e-02,\n",
       "                       -6.5416e-02, -1.2353e-01,  8.4529e-02, -2.3508e-02, -1.3229e-01,\n",
       "                        1.0759e-01,  1.2515e-02, -8.1906e-03, -8.1378e-02,  1.0341e-01,\n",
       "                       -3.5287e-02, -3.6603e-02, -4.8683e-02, -1.1422e-02,  3.4774e-02,\n",
       "                        7.6008e-04, -1.0222e-02, -6.4751e-02, -4.8481e-03, -4.7805e-02,\n",
       "                        1.3120e-01,  4.2207e-02,  1.4161e-01, -1.1543e-01, -3.3498e-02,\n",
       "                       -1.1106e-02, -1.5581e-02,  1.0778e-01,  8.5285e-02,  8.5987e-02,\n",
       "                        3.7595e-02, -2.2592e-02, -8.2672e-02, -1.0767e-01,  5.2546e-02,\n",
       "                        7.0184e-02,  9.6834e-02, -4.1252e-02, -2.3690e-02, -3.4189e-02,\n",
       "                       -1.6480e-01, -9.4468e-02,  1.2485e-02,  1.6091e-01, -3.2072e-02,\n",
       "                        2.1610e-02, -7.6696e-02, -5.3431e-02, -1.3962e-03,  6.5862e-02,\n",
       "                       -4.6781e-02, -3.9880e-02, -5.5551e-02,  3.9625e-02, -6.5980e-02,\n",
       "                       -5.2128e-02,  8.9989e-03, -1.7421e-02,  1.4006e-01,  4.6743e-03,\n",
       "                       -1.0079e-01,  1.6164e-02, -6.9939e-02, -1.7620e-02, -5.2972e-02,\n",
       "                        9.0823e-02, -2.0300e-03, -7.9408e-02,  2.7319e-02, -4.8346e-02,\n",
       "                       -2.4058e-02,  1.0274e-01,  5.9876e-02, -6.2063e-03, -7.0497e-03,\n",
       "                        6.3379e-02,  1.5545e-02, -1.3794e-01, -1.3810e-01,  4.3491e-02,\n",
       "                       -4.8067e-02,  2.9567e-02,  5.6540e-02, -5.6149e-02, -6.0237e-02,\n",
       "                       -5.6163e-02, -4.1068e-02,  2.1565e-02, -1.9928e-02,  3.6905e-03,\n",
       "                       -9.1336e-02, -5.2345e-02,  3.2605e-02, -4.2060e-03, -4.6019e-02,\n",
       "                        1.5938e-02, -3.9180e-02, -4.2546e-02,  4.0029e-03, -9.6267e-02,\n",
       "                       -3.2494e-03,  5.5741e-02, -2.9910e-02, -3.3409e-02, -1.0272e-01,\n",
       "                       -3.9258e-02, -5.0882e-02,  4.8465e-02, -1.2381e-02, -1.4581e-01,\n",
       "                       -7.1856e-02, -5.7834e-02, -3.1404e-02, -3.8181e-02, -9.3095e-02,\n",
       "                       -1.8165e-02,  2.5185e-02, -1.2213e-01,  9.4551e-02, -1.3823e-01,\n",
       "                        8.0218e-02, -1.8705e-01,  1.0119e-01, -6.8741e-01,  9.7948e-02,\n",
       "                       -7.1587e-02, -4.4450e-04,  9.1789e-02, -3.0527e-03,  8.4496e-02,\n",
       "                       -9.5089e-02, -4.6860e-02,  6.7111e-02,  4.9504e-02,  4.7577e-02,\n",
       "                        8.9607e-02, -9.5110e-03,  2.0050e-02,  9.9402e-02, -3.6661e-02,\n",
       "                       -3.1879e-02], device='mps:0')),\n",
       "              ('transformer.h.1.ln_2.weight',\n",
       "               tensor([1.1486, 1.1643, 1.2891, 1.1871, 1.2043, 0.8509, 1.2014, 1.0958, 1.1984,\n",
       "                       1.1245, 1.1238, 1.1957, 1.2494, 1.2493, 1.2551, 1.1156, 1.2445, 1.2378,\n",
       "                       1.1816, 1.1774, 1.1684, 1.1102, 1.2281, 1.1531, 1.1960, 1.1355, 1.1954,\n",
       "                       1.1836, 1.2528, 1.3177, 1.1223, 1.2237, 1.1510, 1.1724, 1.1867, 1.1799,\n",
       "                       1.2733, 1.1768, 1.2124, 1.1868, 1.2948, 1.2424, 1.2226, 1.2246, 1.0806,\n",
       "                       1.2457, 1.1355, 1.1676, 1.1922, 1.2303, 1.1166, 1.0192, 1.2111, 1.2550,\n",
       "                       1.1894, 1.2197, 1.1893, 1.0706, 1.1458, 1.2631, 1.1842, 1.1450, 1.1385,\n",
       "                       1.1177, 1.2639, 1.2650, 1.2057, 1.1431, 1.1903, 1.1902, 1.2682, 1.1736,\n",
       "                       1.2175, 1.2805, 1.2275, 1.2779, 1.2499, 1.1134, 1.1160, 1.1836, 1.0946,\n",
       "                       1.3055, 1.2529, 1.3003, 1.1756, 1.1633, 1.1322, 1.2763, 1.2112, 1.1834,\n",
       "                       1.1625, 1.1771, 1.2675, 1.2718, 1.1109, 1.1673, 1.2299, 1.2068, 1.1475,\n",
       "                       1.0663, 1.1525, 1.2022, 1.1271, 1.2437, 1.1814, 1.1508, 1.1440, 1.1870,\n",
       "                       1.2256, 1.2183, 1.3278, 1.1352, 1.0629, 1.2465, 1.3047, 1.1567, 1.1426,\n",
       "                       1.2281, 1.1968, 1.2386, 1.1575, 1.1828, 1.2221, 1.1763, 1.2552, 1.0907,\n",
       "                       1.1878, 1.2266, 1.1508, 1.1343, 1.1877, 1.1217, 1.2935, 1.2360, 1.2130,\n",
       "                       1.2545, 1.2876, 1.1148, 1.2722, 1.1389, 1.1685, 1.1528, 1.1810, 1.3057,\n",
       "                       1.1930, 1.2285, 1.2259, 1.1903, 1.1775, 1.1704, 1.1682, 1.2151, 1.1824,\n",
       "                       1.2599, 1.2488, 1.1715, 1.1738, 1.2725, 1.3346, 1.1259, 1.2280, 1.2362,\n",
       "                       1.1643, 1.2041, 1.2074, 1.1878, 1.3050, 1.1923, 1.1370, 1.2019, 1.2122,\n",
       "                       1.1458, 1.0923, 1.1463, 1.1475, 1.2241, 1.1751, 1.2224, 1.1050, 1.1345,\n",
       "                       1.2059, 1.0994, 1.1838, 1.2026, 1.2057, 1.0822, 1.2165, 1.2072, 1.1603,\n",
       "                       1.1701, 1.2240, 1.1327, 1.2728, 1.1771, 1.2026, 1.1845, 1.1974, 1.1780,\n",
       "                       1.2385, 1.1334, 1.2651, 1.1405, 1.1466, 1.2364, 1.2861, 1.2101, 1.1238,\n",
       "                       1.2479, 1.2408, 1.2046, 1.0014, 1.1066, 1.2972, 1.2655, 1.1818, 1.1679,\n",
       "                       1.1059, 1.0389, 1.1549, 1.1174, 1.1807, 1.1868, 1.2159, 1.2016, 1.1465,\n",
       "                       1.1852, 1.1248, 1.1577, 1.1296, 1.1116, 1.2422, 1.1539, 1.1694, 1.1620,\n",
       "                       1.2344, 1.1810, 1.1087, 1.1856, 0.4385, 1.1267, 1.2107, 1.1361, 1.2650,\n",
       "                       0.8809, 1.2164, 1.2435, 1.1644, 1.1289, 1.1436, 1.1519, 1.2899, 1.2389,\n",
       "                       1.1947, 1.2656, 1.1777, 1.2111], device='mps:0')),\n",
       "              ('transformer.h.1.ln_2.bias',\n",
       "               tensor([ 1.9322e-01, -1.3698e-01,  4.9136e-02,  1.6188e-01,  2.4607e-02,\n",
       "                        3.1055e-01,  5.9546e-03, -1.0337e-01, -6.2870e-02,  2.4625e-02,\n",
       "                       -1.2082e-01, -2.5119e-02,  6.9120e-02, -2.5368e-02,  1.0027e-01,\n",
       "                       -1.5362e-01,  8.5468e-05, -4.1536e-02,  2.0554e-03, -3.0034e-01,\n",
       "                        2.1912e-01, -1.0732e-01, -5.5022e-02,  1.0519e-01, -7.8876e-02,\n",
       "                        9.1202e-04, -1.5050e-01,  7.1592e-02,  8.9582e-02,  1.3469e-01,\n",
       "                       -2.1178e-01, -1.7988e-01,  1.0648e-01,  1.0108e-01, -3.6600e-02,\n",
       "                       -7.4832e-02,  1.6896e-01,  2.3381e-01,  1.8182e-01,  1.8803e-01,\n",
       "                       -1.9900e-01,  1.0363e-01,  8.9884e-04, -2.2926e-02, -1.7146e-02,\n",
       "                       -1.0425e-03,  2.9685e-02, -9.3321e-02,  6.5408e-02, -3.6038e-01,\n",
       "                       -1.3278e-01, -2.8078e-01, -9.1287e-02,  3.3618e-01,  2.5630e-01,\n",
       "                        2.5898e-01, -1.4014e-01, -1.0682e-01, -1.1323e-01,  1.3661e-01,\n",
       "                        2.1258e-01, -1.9254e-01, -8.1440e-02,  2.2047e-01,  1.1020e-01,\n",
       "                       -3.8501e-02, -1.0244e-02,  1.7811e-02,  4.3278e-02,  3.4848e-01,\n",
       "                        9.8210e-02, -4.5298e-02, -3.9291e-03, -5.9865e-02,  4.3402e-02,\n",
       "                       -1.3435e-01, -2.6074e-02, -1.9070e-01, -5.6870e-02,  7.0834e-02,\n",
       "                        2.4814e-01, -2.7150e-01, -1.7300e-02, -1.4755e-01, -1.0823e-02,\n",
       "                       -5.0082e-03,  1.5356e-01, -2.2207e-01,  1.3194e-01,  2.7892e-01,\n",
       "                       -7.0098e-03,  2.1772e-01,  2.7100e-02, -1.0751e-02, -1.8753e-01,\n",
       "                       -1.9379e-04, -8.0487e-02, -3.0153e-02,  1.6576e-02, -1.1732e-01,\n",
       "                       -6.7871e-02, -1.3205e-01, -7.8864e-02,  7.3248e-02, -7.7786e-03,\n",
       "                        1.0796e-01,  1.9814e-02, -1.8579e-01,  1.4224e-01,  9.3032e-02,\n",
       "                       -3.0517e-01,  4.3918e-02,  1.6955e-01,  2.1202e-02,  2.3616e-02,\n",
       "                       -7.1449e-02,  1.0294e-01,  1.0682e-01, -1.0022e-01, -1.2945e-01,\n",
       "                       -4.8698e-03,  2.1481e-01,  2.9362e-01,  2.0432e-02, -3.1050e-02,\n",
       "                        1.0115e-01,  2.0868e-01, -6.0835e-02, -7.7271e-02,  1.1925e-01,\n",
       "                        8.6937e-03,  9.7905e-02,  2.8123e-01,  6.0112e-02,  1.2977e-01,\n",
       "                       -1.3237e-01,  1.4468e-01,  1.7611e-01, -2.1923e-01, -6.1014e-02,\n",
       "                        2.6012e-01, -1.6484e-01,  1.8304e-01,  1.4591e-01,  3.0860e-01,\n",
       "                       -2.0598e-01,  6.2155e-02, -2.4960e-01,  2.5568e-01,  1.3589e-01,\n",
       "                        9.1662e-03,  1.8861e-01, -2.6335e-02, -1.7121e-02, -1.1948e-01,\n",
       "                       -2.5802e-01,  2.6367e-01,  1.9955e-01,  2.0566e-01,  2.2150e-01,\n",
       "                       -5.0642e-02,  2.1759e-01,  9.4901e-02, -1.9320e-02, -1.3962e-01,\n",
       "                       -1.3742e-01, -1.6952e-01, -2.5214e-02,  1.8611e-01, -1.3827e-01,\n",
       "                       -5.2272e-02,  3.2437e-01, -8.6259e-02,  1.3044e-01,  1.1333e-01,\n",
       "                        3.4159e-02,  6.9581e-02, -1.3478e-01, -1.0711e-01,  2.8754e-02,\n",
       "                        2.5375e-01,  1.4427e-01,  3.1234e-03, -8.4739e-02,  1.6251e-01,\n",
       "                        7.1783e-02, -1.5712e-01,  1.0513e-01, -1.7535e-02, -2.3714e-02,\n",
       "                       -9.7601e-02, -7.6001e-02, -2.7883e-01,  1.8899e-01, -1.2232e-01,\n",
       "                       -2.1799e-02, -1.3311e-01,  1.5464e-01, -9.7237e-03, -2.2723e-01,\n",
       "                       -1.6043e-01, -1.6595e-01, -4.4701e-02, -1.0751e-01, -1.7921e-01,\n",
       "                        5.1005e-02, -7.4538e-02, -4.4492e-02, -1.5286e-01,  1.1225e-01,\n",
       "                       -7.6688e-02, -2.9244e-01, -1.8306e-01,  9.5780e-02, -1.0399e-01,\n",
       "                        1.0248e-03, -1.8972e-01,  2.1628e-02,  2.4121e-02, -1.5085e-01,\n",
       "                       -6.9501e-02, -7.4362e-02, -1.2427e-01,  6.6131e-02, -2.2392e-01,\n",
       "                        1.5656e-01, -1.7956e-01,  2.0663e-01, -1.2340e-01, -1.9057e-02,\n",
       "                        3.3218e-02,  7.6244e-02, -1.3914e-01, -3.4097e-02, -3.8228e-02,\n",
       "                        1.8458e-01, -9.4766e-02,  2.4470e-01,  3.0942e-01,  6.9967e-02,\n",
       "                        7.5016e-02,  2.7554e-02,  8.4821e-02, -2.7757e-01,  3.5734e-02,\n",
       "                       -4.6330e-02, -2.8597e-01, -1.7207e-01,  1.3806e-01, -4.6652e-02,\n",
       "                        1.6536e-01, -1.0179e-01,  2.8070e-01,  2.1384e-01,  5.2529e-02,\n",
       "                       -1.1404e-01], device='mps:0')),\n",
       "              ('transformer.h.1.mlp.c_fc.weight',\n",
       "               tensor([[ 0.0776,  0.0241, -0.1171,  ..., -0.1390, -0.0556, -0.0411],\n",
       "                       [-0.0908,  0.0198,  0.0797,  ..., -0.0344,  0.0696, -0.0384],\n",
       "                       [-0.0886,  0.0057, -0.0397,  ..., -0.0216,  0.0276, -0.0460],\n",
       "                       ...,\n",
       "                       [-0.0976,  0.0140,  0.1052,  ...,  0.1121,  0.0441,  0.0410],\n",
       "                       [ 0.0384, -0.0221, -0.0909,  ..., -0.0635,  0.0895,  0.0284],\n",
       "                       [-0.1572, -0.0127,  0.0071,  ..., -0.0777,  0.0899, -0.0068]],\n",
       "                      device='mps:0')),\n",
       "              ('transformer.h.1.mlp.c_fc.bias',\n",
       "               tensor([-0.1875, -0.0487, -0.0339,  ...,  0.0330, -0.1293, -0.1448],\n",
       "                      device='mps:0')),\n",
       "              ('transformer.h.1.mlp.c_proj.weight',\n",
       "               tensor([[ 0.0100, -0.0496,  0.0078,  ..., -0.0461, -0.0373, -0.1236],\n",
       "                       [-0.0566, -0.0034, -0.1008,  ...,  0.0092,  0.0135,  0.0289],\n",
       "                       [ 0.0427, -0.0012, -0.0196,  ..., -0.0736,  0.0740, -0.1124],\n",
       "                       ...,\n",
       "                       [ 0.0021,  0.0529, -0.1071,  ..., -0.0319, -0.0268, -0.0260],\n",
       "                       [ 0.0016, -0.0753, -0.0128,  ..., -0.0040,  0.0378,  0.1013],\n",
       "                       [ 0.0173,  0.0359,  0.0334,  ...,  0.0288,  0.0214,  0.0584]],\n",
       "                      device='mps:0')),\n",
       "              ('transformer.h.1.mlp.c_proj.bias',\n",
       "               tensor([ 4.5444e-02,  1.1086e-01, -4.0700e-02,  1.3824e-01,  1.1542e-01,\n",
       "                       -2.0872e-02, -6.6663e-03, -9.9983e-03,  7.5138e-02,  1.0227e-02,\n",
       "                        4.5340e-02, -1.2949e-01,  4.1700e-03, -1.9089e-02, -4.8114e-02,\n",
       "                       -1.3608e-01,  5.8230e-02, -1.3547e-02, -4.8778e-02, -6.5336e-02,\n",
       "                        3.5788e-02, -8.7632e-03, -5.8207e-02, -1.0644e-03, -1.2526e-02,\n",
       "                        3.2476e-03,  6.8826e-02,  5.0504e-02,  5.0186e-02,  5.8690e-02,\n",
       "                       -2.9468e-02, -9.4937e-03, -8.2432e-02,  2.9037e-02, -5.3386e-03,\n",
       "                        1.4145e-01, -7.6410e-03,  7.5990e-02,  8.6434e-02,  7.9373e-02,\n",
       "                       -4.9557e-03,  3.5534e-03,  1.2333e-01,  3.6347e-02, -2.4966e-02,\n",
       "                       -5.3057e-02, -1.7734e-01, -1.2127e-01, -1.0260e-02,  4.5454e-02,\n",
       "                        1.8516e-01,  6.8806e-02,  1.1077e-02,  5.0558e-03,  1.0331e-01,\n",
       "                        3.8218e-02,  6.8546e-02, -8.5666e-02, -3.6071e-02, -6.8432e-03,\n",
       "                       -5.4104e-02,  1.0502e-01, -4.3647e-02, -1.6815e-02, -3.3864e-02,\n",
       "                        1.5078e-01, -1.6483e-02, -6.5828e-02,  1.1591e-01,  1.6107e-02,\n",
       "                        7.1855e-02,  8.7855e-04, -9.2445e-02, -2.1130e-02,  4.2842e-02,\n",
       "                        1.1706e-01,  7.2522e-03, -1.5796e-01, -7.6973e-02, -3.6483e-02,\n",
       "                       -2.7101e-03, -1.1502e-01,  9.6357e-02,  4.4135e-02, -1.5457e-01,\n",
       "                        2.8510e-02,  5.3603e-02,  1.8239e-02,  1.5943e-02, -6.1146e-02,\n",
       "                        8.1698e-02, -4.2774e-02, -1.5411e-02,  2.6443e-02,  2.5975e-02,\n",
       "                        2.9232e-02,  3.1691e-02, -1.0973e-01,  2.8306e-02, -1.1011e-01,\n",
       "                        7.1434e-02,  9.3358e-02,  5.8146e-02, -9.5748e-02,  2.9595e-02,\n",
       "                       -5.7518e-02, -1.8991e-02, -4.1821e-02,  5.6544e-02,  3.8081e-02,\n",
       "                       -5.6288e-02, -1.7870e-02, -8.4814e-02, -1.1318e-01,  2.8474e-03,\n",
       "                        2.8490e-02, -6.0715e-02,  1.1589e-02,  6.3336e-02, -3.2736e-02,\n",
       "                        5.3624e-03, -6.9021e-02,  9.1011e-02, -5.6890e-02, -7.6673e-02,\n",
       "                        6.4775e-02, -9.7551e-02,  1.0304e-01,  3.9183e-02, -4.5731e-03,\n",
       "                        2.2309e-03,  3.8186e-02,  1.8698e-02,  1.2226e-01,  7.0446e-02,\n",
       "                        2.7743e-02, -3.1393e-03, -8.6763e-02,  2.7011e-02, -7.3709e-02,\n",
       "                       -1.3948e-01,  5.4316e-02,  4.2723e-02, -6.5585e-02, -7.3398e-02,\n",
       "                       -5.2187e-03, -1.2078e-03, -6.0703e-02, -1.9097e-02,  9.6802e-02,\n",
       "                       -2.4983e-02,  1.2164e-04,  2.4212e-02,  6.9844e-02, -8.5047e-03,\n",
       "                        1.2001e-01, -6.8884e-02, -2.4401e-02, -1.3681e-03, -4.6740e-02,\n",
       "                       -3.1922e-02, -8.6968e-02,  8.7160e-03,  3.1410e-02,  3.7609e-02,\n",
       "                        1.2148e-01, -6.0362e-02, -5.9022e-02,  5.8087e-02, -8.0593e-02,\n",
       "                       -5.1259e-02,  1.8704e-02, -2.6633e-02,  8.4087e-02, -6.0293e-02,\n",
       "                       -8.7070e-02,  5.4196e-02,  3.1530e-02,  2.4768e-02, -4.8406e-02,\n",
       "                       -5.3109e-02, -5.5805e-02,  7.0075e-02,  2.8656e-02, -2.2492e-02,\n",
       "                        6.2177e-02, -1.6940e-01, -2.5674e-02,  1.6642e-01, -4.0387e-02,\n",
       "                        1.5249e-03, -6.7095e-02,  5.9511e-02, -1.4353e-01,  7.6342e-02,\n",
       "                       -3.8230e-02, -1.1606e-03, -9.6831e-03,  1.0399e-01, -9.4779e-02,\n",
       "                       -5.4184e-02,  1.4968e-01,  1.9557e-02,  4.7003e-02, -1.9169e-02,\n",
       "                       -1.6396e-02,  4.4256e-03, -2.4447e-02,  4.2241e-02, -7.9444e-02,\n",
       "                        2.0683e-02,  4.4828e-02,  4.5867e-03,  2.3158e-02, -4.1261e-03,\n",
       "                        1.0366e-01, -7.9279e-02, -8.9269e-02, -1.1171e-01,  5.8452e-02,\n",
       "                       -5.3622e-02,  4.5369e-03, -5.2164e-02, -2.8882e-02,  3.1730e-02,\n",
       "                        5.0102e-02,  1.8193e-02,  9.0406e-03, -3.3303e-02, -5.4007e-02,\n",
       "                        6.6423e-02,  5.6752e-03, -4.1873e-02,  1.9881e-02, -9.4667e-02,\n",
       "                       -8.9699e-02,  5.2038e-02, -4.5414e-02, -7.4881e-02,  5.0410e-02,\n",
       "                        8.1473e-03, -4.0786e-02,  1.5074e-01, -8.2291e-02,  9.6433e-02,\n",
       "                       -1.8666e-02,  1.4494e-02, -7.6701e-02, -1.2940e-01,  5.6726e-02,\n",
       "                        1.1252e-02, -3.0530e-03, -3.1789e-02,  2.1069e-02,  1.4982e-02,\n",
       "                       -6.8014e-04], device='mps:0')),\n",
       "              ('transformer.h.2.ln_1.weight',\n",
       "               tensor([1.0981, 1.1833, 1.1613, 1.1238, 1.1444, 0.8282, 1.1937, 1.1012, 1.1543,\n",
       "                       1.1268, 1.0566, 1.1131, 1.1360, 1.1515, 1.1786, 1.1158, 1.1381, 1.1406,\n",
       "                       1.1244, 1.1464, 1.1473, 1.1400, 1.1819, 1.1393, 1.1386, 1.1045, 1.1539,\n",
       "                       1.1381, 1.1072, 1.2408, 1.1159, 1.0893, 1.1187, 1.1263, 1.1587, 1.1356,\n",
       "                       1.1724, 1.1331, 1.1573, 1.2034, 1.1434, 1.1907, 1.1487, 1.1281, 1.0765,\n",
       "                       1.1693, 1.1470, 1.1121, 1.1920, 1.1965, 1.1213, 0.9657, 1.1424, 1.1474,\n",
       "                       1.1489, 1.1997, 1.1456, 1.0873, 1.0817, 1.1635, 1.1298, 1.1281, 1.0837,\n",
       "                       1.0512, 1.1627, 1.1636, 1.1377, 1.1128, 1.1806, 1.1488, 1.2087, 1.0971,\n",
       "                       1.1620, 1.1690, 1.1539, 1.1511, 1.1242, 1.0518, 1.1053, 1.0946, 1.2236,\n",
       "                       1.1428, 1.1838, 1.2052, 1.1290, 1.1151, 1.0947, 1.1902, 1.1544, 1.1224,\n",
       "                       1.1839, 1.1021, 1.1673, 1.1947, 1.0507, 1.0970, 1.0890, 1.1436, 1.1578,\n",
       "                       1.0606, 1.1103, 1.1294, 1.1130, 1.1718, 1.1328, 1.1407, 1.0910, 1.0944,\n",
       "                       1.1510, 1.1568, 1.1545, 1.1824, 1.0299, 1.1721, 1.1788, 1.0686, 1.1327,\n",
       "                       1.1214, 1.1000, 1.1763, 1.1350, 1.1172, 1.1187, 1.1026, 1.1862, 1.0893,\n",
       "                       1.2171, 1.1632, 1.1417, 1.1012, 1.0986, 1.0819, 1.1444, 1.2216, 1.1487,\n",
       "                       1.1256, 1.1841, 1.0686, 1.2352, 1.1438, 1.0859, 1.0980, 1.1942, 1.1422,\n",
       "                       1.1362, 1.1945, 1.0838, 1.1416, 1.1818, 1.1498, 1.0949, 1.0641, 1.0998,\n",
       "                       1.1906, 1.1877, 1.0960, 1.1892, 1.1875, 1.1856, 1.1190, 1.1901, 1.1462,\n",
       "                       1.0787, 1.1698, 1.2078, 1.1699, 1.1849, 1.1158, 1.0566, 1.1701, 1.1696,\n",
       "                       1.0615, 1.0978, 1.2048, 1.1263, 1.2013, 1.0996, 1.1590, 1.0490, 1.0928,\n",
       "                       1.0462, 1.0745, 1.1558, 1.1219, 1.1374, 1.0721, 1.1334, 1.0834, 1.1649,\n",
       "                       1.1445, 1.1083, 1.1287, 1.2106, 1.1394, 1.1441, 1.2235, 1.1379, 1.1165,\n",
       "                       1.1636, 1.1039, 1.1714, 1.0847, 1.1347, 1.2143, 1.1718, 1.1466, 1.0767,\n",
       "                       1.2099, 1.1571, 1.1130, 0.9389, 1.0086, 1.2263, 1.1734, 1.0998, 1.0972,\n",
       "                       1.1090, 1.0273, 1.1182, 1.0940, 1.1297, 1.1072, 1.1567, 1.1352, 1.1172,\n",
       "                       1.1533, 1.1008, 1.0966, 1.0967, 1.0597, 1.1392, 1.0862, 1.1625, 1.0888,\n",
       "                       1.1320, 1.1175, 1.1118, 1.1130, 0.7483, 1.1171, 1.1261, 1.0912, 1.2065,\n",
       "                       0.9146, 1.1908, 1.1524, 1.0825, 1.1269, 1.1345, 1.1054, 1.2213, 1.2619,\n",
       "                       1.1326, 1.1343, 1.1571, 1.2162], device='mps:0')),\n",
       "              ('transformer.h.2.ln_1.bias',\n",
       "               tensor([-0.0116, -0.0385,  0.0107,  0.0004,  0.0816,  0.1830, -0.0253, -0.0388,\n",
       "                        0.0231, -0.0660, -0.0690,  0.0373, -0.0538, -0.0494,  0.0864, -0.0412,\n",
       "                       -0.0575,  0.0220,  0.0613, -0.0265,  0.0259, -0.0427, -0.0088,  0.0350,\n",
       "                       -0.0469,  0.0340, -0.0046, -0.0279,  0.0107, -0.0004, -0.0044, -0.0414,\n",
       "                        0.0096,  0.0901,  0.0766, -0.1002, -0.0486,  0.0113, -0.0073,  0.0233,\n",
       "                        0.0079, -0.0374, -0.0861,  0.0801, -0.0345, -0.0426,  0.0498,  0.0832,\n",
       "                       -0.0161, -0.0905, -0.0917, -0.1804, -0.0793,  0.0234, -0.0527,  0.0372,\n",
       "                       -0.0845, -0.0198, -0.0586, -0.0737,  0.1601,  0.0426, -0.0420,  0.0715,\n",
       "                        0.0121, -0.0922,  0.0375,  0.0591, -0.0226, -0.0341,  0.0180,  0.0079,\n",
       "                        0.0026,  0.1161,  0.0319, -0.0373,  0.0707, -0.0545,  0.0029,  0.0490,\n",
       "                        0.0464, -0.0617, -0.0562, -0.0698,  0.0589, -0.0617,  0.0017, -0.0589,\n",
       "                        0.0878,  0.0452,  0.0134,  0.0454, -0.0204,  0.0213, -0.0684, -0.0385,\n",
       "                        0.0702,  0.0870, -0.0326,  0.0399, -0.0401, -0.0405,  0.0124, -0.0827,\n",
       "                       -0.0335,  0.0328,  0.0630, -0.0022,  0.0150, -0.0082,  0.0874,  0.0328,\n",
       "                       -0.0617,  0.0829,  0.0296, -0.0257, -0.0033,  0.0324,  0.0376, -0.0181,\n",
       "                        0.0526,  0.0917,  0.0123,  0.0425, -0.0085, -0.0157,  0.1055, -0.0320,\n",
       "                       -0.0357, -0.0703,  0.0177, -0.0124,  0.0338, -0.0246, -0.0988, -0.0359,\n",
       "                        0.0769,  0.0056, -0.0281, -0.0633,  0.1765, -0.0597,  0.0165, -0.0241,\n",
       "                        0.1303, -0.1008,  0.1027,  0.0242,  0.0122, -0.0192,  0.0222,  0.0935,\n",
       "                       -0.0730,  0.0211,  0.0032, -0.0063,  0.0719,  0.0009,  0.1328,  0.1059,\n",
       "                       -0.0169,  0.0723,  0.1431, -0.0373, -0.0684, -0.0237, -0.0459, -0.0119,\n",
       "                        0.0073, -0.0477, -0.0151,  0.0189, -0.0276,  0.0305, -0.0390,  0.0377,\n",
       "                        0.0623, -0.0639,  0.0837,  0.0471,  0.0630,  0.0503, -0.0735, -0.0344,\n",
       "                        0.0127,  0.0068,  0.0740,  0.0253,  0.0019,  0.1262, -0.0040,  0.0684,\n",
       "                       -0.0534,  0.0688, -0.0800,  0.0055, -0.0277,  0.1050, -0.1054, -0.0076,\n",
       "                        0.0297, -0.0041, -0.0247, -0.0622, -0.0075,  0.0297, -0.0162, -0.0081,\n",
       "                        0.0422,  0.0878, -0.0510, -0.0297, -0.0427,  0.0108,  0.0288, -0.0611,\n",
       "                        0.0023,  0.0327,  0.1062, -0.0772, -0.0737,  0.0709,  0.0036,  0.0474,\n",
       "                       -0.0441, -0.0523,  0.0022,  0.0343, -0.0865,  0.0672, -0.1337,  0.0372,\n",
       "                       -0.0774,  0.0486, -0.0923,  0.0260, -0.0763, -0.0041,  0.3413, -0.0153,\n",
       "                       -0.0007,  0.0204, -0.1679, -0.0629, -0.1093, -0.0138, -0.1197,  0.0521,\n",
       "                        0.0861, -0.0165,  0.0511, -0.0629,  0.0451, -0.0084, -0.0778, -0.0980],\n",
       "                      device='mps:0')),\n",
       "              ('transformer.h.2.attn.bias',\n",
       "               tensor([[[[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "                         [1., 1., 0.,  ..., 0., 0., 0.],\n",
       "                         [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "                         ...,\n",
       "                         [1., 1., 1.,  ..., 1., 0., 0.],\n",
       "                         [1., 1., 1.,  ..., 1., 1., 0.],\n",
       "                         [1., 1., 1.,  ..., 1., 1., 1.]]]], device='mps:0')),\n",
       "              ('transformer.h.2.attn.c_attn.weight',\n",
       "               tensor([[ 0.1067, -0.0059, -0.0560,  ...,  0.0334,  0.0292, -0.0206],\n",
       "                       [ 0.0056,  0.0485,  0.0322,  ...,  0.0858, -0.0019,  0.0578],\n",
       "                       [ 0.0743, -0.0370,  0.0689,  ..., -0.0423,  0.0749,  0.0829],\n",
       "                       ...,\n",
       "                       [ 0.0621,  0.0893, -0.0106,  ...,  0.0889,  0.2665, -0.0316],\n",
       "                       [ 0.0631,  0.1670, -0.0687,  ..., -0.0340,  0.0384, -0.0091],\n",
       "                       [ 0.0112,  0.0800,  0.0153,  ..., -0.0430,  0.0125,  0.0077]],\n",
       "                      device='mps:0')),\n",
       "              ('transformer.h.2.attn.c_attn.bias',\n",
       "               tensor([ 1.7130e-01,  2.4512e-01,  3.4019e-01, -2.4605e-02,  2.6739e-01,\n",
       "                       -3.8751e-02, -1.8580e-01, -1.2621e-01, -4.4290e-02,  1.2384e-01,\n",
       "                       -2.5782e-02, -2.1416e-01,  4.2191e-02,  2.5778e-01,  8.7180e-02,\n",
       "                       -1.7854e-01, -2.1059e-01,  2.8815e-01, -5.2115e-02,  2.7570e-01,\n",
       "                        5.9865e-02, -1.5192e-01, -2.3537e-01, -2.7099e-01,  3.2772e-01,\n",
       "                        7.5195e-02, -2.2599e-01, -1.1875e-01, -8.9375e-02,  2.1519e-02,\n",
       "                       -1.6794e-01, -2.8564e-01, -8.5155e-02,  2.3003e-01,  6.5827e-02,\n",
       "                       -2.1444e-01, -1.7606e-01, -2.4228e-01, -3.3556e-02,  1.7596e-01,\n",
       "                       -3.5152e-01,  5.3442e-02,  3.0767e-01, -3.3774e-01, -2.4611e-01,\n",
       "                        7.2395e-02, -1.0543e-01,  1.1922e-01,  6.2249e-02, -2.4507e-01,\n",
       "                        2.3361e-01, -1.6965e-01,  1.7850e-02, -1.3064e-01,  1.5630e-01,\n",
       "                       -8.5042e-02, -5.5247e-02,  7.1136e-02, -7.8542e-02,  1.3937e-01,\n",
       "                        2.5005e-01,  1.1965e-01, -1.3185e-02, -3.3660e-01, -6.2673e-02,\n",
       "                        3.6734e-02,  5.7516e-02,  9.0589e-02,  1.7712e-01, -6.4282e-02,\n",
       "                       -8.5343e-02, -3.5136e-01,  2.4928e-01, -2.5218e-01, -1.5055e-01,\n",
       "                        1.7863e-01,  3.1485e-01, -6.8724e-04, -2.3193e-01,  1.4810e-01,\n",
       "                        1.0324e-01, -7.6482e-02, -8.4126e-02, -2.2835e-01, -4.3847e-02,\n",
       "                       -2.0824e-01,  9.7490e-02,  3.1663e-02, -3.9849e-02,  1.2296e-01,\n",
       "                       -8.8615e-02,  3.1297e-01, -2.6055e-01,  4.8924e-02, -1.3569e-01,\n",
       "                       -1.1570e-01, -2.1895e-02,  3.0266e-01,  1.2011e-01,  2.5962e-01,\n",
       "                       -1.7954e-01,  3.2138e-01, -2.1495e-02, -1.8941e-01, -6.3840e-02,\n",
       "                        1.9756e-02, -1.2720e-01, -1.4253e-02,  1.7600e-01, -2.3806e-01,\n",
       "                       -4.3301e-01, -2.1615e-01, -4.7650e-01,  8.9477e-02, -3.1813e-01,\n",
       "                        6.5541e-02, -1.0643e-01,  3.4529e-02, -1.8898e-01, -5.4276e-02,\n",
       "                        1.0867e-01, -1.9323e-01,  7.9727e-03, -5.1728e-01,  3.3838e-01,\n",
       "                       -2.5362e-01,  2.6268e-01,  2.1395e-01,  3.6552e-01,  1.3490e-01,\n",
       "                        2.2086e-01,  1.9949e-01, -2.6829e-01,  5.6386e-02, -9.8873e-02,\n",
       "                       -7.7382e-02, -2.2139e-01, -5.9401e-02, -2.0774e-02, -8.4962e-02,\n",
       "                       -1.5570e-01, -5.1915e-02, -2.7193e-01, -3.4452e-01, -9.0736e-02,\n",
       "                        4.2282e-01,  2.8445e-02, -1.9763e-01,  1.4982e-01,  1.8643e-01,\n",
       "                        2.7158e-01,  1.7676e-01,  2.7966e-01,  1.9234e-01, -9.8309e-02,\n",
       "                       -2.9857e-01, -7.2906e-02,  1.7606e-01,  1.2606e-01, -1.2877e-01,\n",
       "                       -1.3836e-01,  3.0387e-01,  8.2840e-02,  1.4734e-01,  1.4163e-01,\n",
       "                        1.8824e-01,  1.6685e-01, -1.2426e-01, -1.3291e-03, -1.0725e-01,\n",
       "                        6.6733e-02, -1.2702e-01,  2.8378e-02,  9.6761e-02,  9.2995e-02,\n",
       "                        1.9562e-02,  4.0833e-01, -3.7183e-01, -9.5853e-02, -1.1395e-01,\n",
       "                        3.4302e-01, -1.0618e-01,  1.0810e-01,  2.9426e-01, -2.2983e-01,\n",
       "                       -2.2797e-01, -3.0987e-01,  3.7347e-02, -9.6648e-02, -1.2708e-01,\n",
       "                        1.7392e-01,  8.5607e-02,  3.5872e-01, -5.1611e-02, -1.9735e-01,\n",
       "                       -1.0277e-01,  1.1441e-01,  2.2816e-01,  1.6279e-01,  1.6020e-01,\n",
       "                        2.5343e-01, -6.7710e-02,  2.3066e-01, -2.1048e-01, -1.1676e-01,\n",
       "                        8.5340e-02,  1.1390e-01, -1.4552e-01,  4.6411e-02, -2.8909e-01,\n",
       "                        1.2729e-02, -5.5300e-02,  6.7834e-02,  2.0000e-01,  2.7316e-01,\n",
       "                        2.4021e-02, -1.5774e-01, -1.2977e-01,  1.6315e-01, -2.3208e-01,\n",
       "                       -2.1710e-01,  3.5649e-01, -1.7514e-01, -1.0814e-01,  1.2988e-01,\n",
       "                       -6.3767e-02, -2.4266e-01,  3.2613e-01,  3.4217e-01,  1.0103e-01,\n",
       "                       -1.7728e-01,  1.2848e-01,  2.6598e-02,  1.1286e-01,  4.5962e-01,\n",
       "                        2.5977e-01, -3.5727e-02,  8.8465e-02, -3.1631e-01,  4.0733e-01,\n",
       "                        3.8725e-01, -1.9809e-01, -3.0966e-01,  2.6358e-01,  1.7868e-01,\n",
       "                        1.2559e-01, -1.3507e-01,  1.1226e-02,  1.1580e-02,  8.2942e-02,\n",
       "                       -7.5541e-02,  7.2572e-02, -2.7414e-02,  1.0111e-01, -2.7129e-01,\n",
       "                       -1.4663e-01, -5.8020e-02, -3.4489e-02,  1.5308e-02, -3.6336e-02,\n",
       "                       -5.7617e-03, -6.3860e-02,  1.7267e-02, -3.6977e-02,  1.7749e-02,\n",
       "                       -1.5494e-03, -7.4742e-03,  3.3972e-02,  5.6454e-03,  1.5763e-02,\n",
       "                       -6.1682e-03, -6.0368e-02, -3.5013e-02,  5.5220e-02,  2.8077e-02,\n",
       "                        2.5730e-02,  5.6082e-02, -3.4667e-02, -2.2244e-03,  5.4196e-02,\n",
       "                       -4.4228e-02, -5.0039e-02, -2.6635e-02, -3.2844e-02,  1.9789e-02,\n",
       "                       -1.1790e-02, -5.5319e-02, -3.4032e-02,  3.5351e-02,  4.9792e-02,\n",
       "                        9.5444e-03,  1.9648e-02,  2.7539e-02,  1.4915e-02, -6.0143e-02,\n",
       "                       -1.9912e-02,  2.2924e-02,  5.6618e-02,  8.1567e-03,  2.0346e-02,\n",
       "                        4.2904e-02,  6.3073e-03,  2.2158e-02,  3.8311e-02, -2.4826e-02,\n",
       "                        1.8927e-03, -3.4230e-02, -2.4946e-02,  2.5602e-02, -1.9653e-03,\n",
       "                        3.5159e-03,  4.8156e-02,  5.7191e-02,  1.8403e-02,  5.4205e-02,\n",
       "                       -3.5620e-02,  6.4814e-02, -2.9668e-02,  5.0121e-02,  2.2018e-02,\n",
       "                       -2.8345e-02,  2.8915e-02, -1.7572e-03, -4.4309e-03,  9.7609e-03,\n",
       "                       -6.1964e-02,  2.2005e-02, -6.1668e-02,  4.4273e-02, -2.3676e-03,\n",
       "                        3.9638e-02, -2.8754e-02,  1.9651e-02,  2.0843e-02, -9.1964e-04,\n",
       "                        4.3415e-02, -4.2804e-02, -2.3930e-02, -6.1265e-02,  1.0348e-02,\n",
       "                        1.5077e-02, -6.5513e-02,  6.6861e-02, -4.7040e-02,  5.2380e-02,\n",
       "                        6.5699e-03, -2.7372e-02,  6.2285e-02, -3.7676e-02,  5.9460e-02,\n",
       "                       -6.8615e-02, -3.0148e-02, -4.9011e-02,  4.2732e-02, -2.7705e-02,\n",
       "                        1.0457e-02, -5.3207e-02, -4.6815e-02,  1.4146e-02,  4.6767e-02,\n",
       "                        6.5227e-03, -4.1984e-02,  6.6377e-03,  2.2688e-02, -4.8019e-03,\n",
       "                       -5.0400e-02,  5.7933e-03, -1.0735e-02,  5.8012e-02, -6.4339e-03,\n",
       "                        4.0581e-02,  5.7868e-02,  5.0473e-02, -4.4550e-02, -1.6284e-02,\n",
       "                        3.4067e-02,  8.3940e-03,  3.0605e-02,  4.9248e-02,  3.8392e-02,\n",
       "                       -9.2930e-03,  7.3955e-03,  3.9979e-02,  9.2680e-03, -1.1925e-02,\n",
       "                       -5.0534e-02,  1.2992e-02,  8.0943e-03, -3.7756e-02, -4.5637e-02,\n",
       "                       -9.1519e-03,  3.3497e-02, -4.8669e-02, -1.6582e-02, -7.1817e-03,\n",
       "                        4.5818e-02, -3.4893e-02, -2.0288e-02, -1.4428e-03, -2.5696e-02,\n",
       "                       -4.3231e-02, -3.5923e-03, -2.2486e-02, -4.0450e-02, -1.3757e-02,\n",
       "                       -4.3596e-02, -1.3016e-02,  1.7242e-02,  1.3896e-02,  5.8109e-02,\n",
       "                       -1.4603e-02,  1.1025e-02,  8.0932e-03, -1.4845e-02, -2.6110e-02,\n",
       "                        3.0033e-02, -2.7949e-02, -4.2999e-02, -1.1250e-02, -3.0466e-03,\n",
       "                        5.0767e-02,  2.4208e-02,  1.0105e-02, -5.1108e-02,  2.7951e-02,\n",
       "                       -3.4406e-02, -5.7638e-02, -2.2697e-02, -2.3155e-02, -1.3413e-02,\n",
       "                       -2.9454e-02,  1.4738e-03,  3.9362e-03,  4.7375e-02,  5.7629e-02,\n",
       "                       -3.4915e-02,  5.2034e-02, -4.8464e-02,  1.5387e-02, -1.2966e-02,\n",
       "                        4.7413e-02,  2.3770e-02,  5.3194e-02,  3.9111e-03,  2.6994e-02,\n",
       "                        2.2458e-02, -2.5887e-02,  4.0084e-02,  4.9996e-02,  2.6832e-02,\n",
       "                        3.7617e-02, -5.0058e-02, -2.2730e-02, -2.0747e-02,  4.3185e-02,\n",
       "                       -1.5678e-03, -2.0222e-03, -1.2055e-02,  3.7921e-02,  5.2729e-02,\n",
       "                        6.0460e-02, -3.4022e-02, -1.9831e-02, -6.2804e-02, -5.2359e-02,\n",
       "                       -5.3453e-03,  3.6486e-02,  4.0861e-02, -6.1151e-02,  6.3137e-02,\n",
       "                       -5.7016e-02, -2.0669e-02,  3.8689e-02,  5.5345e-02, -4.6883e-02,\n",
       "                       -3.2223e-02,  1.8900e-02,  3.0689e-02,  9.9666e-03, -4.0595e-02,\n",
       "                       -3.6000e-02, -1.8611e-02,  1.3679e-02, -5.6477e-02,  1.0640e-02,\n",
       "                        5.9246e-02,  2.4910e-02, -1.3007e-03,  5.8994e-02,  4.2605e-03,\n",
       "                       -4.7061e-02,  3.8564e-02,  5.2558e-02,  4.5688e-02,  4.9439e-02,\n",
       "                       -3.3823e-02, -5.2604e-02, -4.8890e-02, -3.2031e-03,  1.3540e-02,\n",
       "                        1.8676e-02, -2.0580e-02, -2.1892e-02,  2.9863e-02,  1.7674e-02,\n",
       "                        3.7986e-02,  1.3767e-02,  5.2306e-02, -4.8977e-02,  1.2604e-02,\n",
       "                        3.0100e-02, -3.4544e-02, -3.1307e-02, -2.5749e-03,  5.5299e-02,\n",
       "                        4.4960e-03,  6.5397e-03,  3.0077e-02, -7.6382e-02, -1.5444e-02,\n",
       "                        7.8661e-03, -3.3232e-04,  5.7839e-02, -5.6256e-02, -9.8716e-02,\n",
       "                       -4.9968e-03,  6.5976e-02,  7.7065e-02, -5.5905e-02,  1.2429e-01,\n",
       "                       -4.0717e-02,  8.1555e-04,  2.7520e-02, -1.1259e-02,  6.2514e-02,\n",
       "                       -2.7353e-02,  8.5164e-02,  8.1437e-02,  9.8088e-02, -5.5929e-02,\n",
       "                       -3.6578e-03,  6.8588e-02,  5.8795e-02, -6.3278e-03,  5.4891e-02,\n",
       "                       -4.0333e-02,  5.9475e-02,  3.5855e-02,  5.8733e-02, -1.0187e-01,\n",
       "                       -1.8615e-02, -3.5711e-02, -9.9289e-02,  1.5144e-02, -3.8847e-03,\n",
       "                       -4.8347e-03, -4.1995e-02, -1.1565e-02,  2.9472e-03, -3.8594e-03,\n",
       "                        1.9235e-02,  1.5995e-02,  1.3242e-03, -1.2665e-02, -5.2920e-03,\n",
       "                        8.1893e-03,  8.5586e-02,  8.0285e-03,  4.2597e-02,  1.6124e-02,\n",
       "                        6.4999e-02,  1.6649e-02, -5.1191e-02, -3.7586e-02,  1.0385e-02,\n",
       "                       -6.7059e-02,  4.7892e-02,  8.4174e-02, -2.7039e-02,  3.9985e-02,\n",
       "                        1.6003e-01,  7.3591e-02,  8.1607e-02, -9.5662e-03,  8.0290e-02,\n",
       "                        1.7220e-02, -8.0025e-02, -5.0965e-02, -4.0393e-02, -1.6046e-02,\n",
       "                       -4.8805e-02, -5.8872e-02, -1.7953e-02, -4.7730e-02,  1.6042e-02,\n",
       "                        1.5267e-02,  4.6913e-02,  1.1988e-01,  9.3843e-02, -3.0870e-02,\n",
       "                       -6.4788e-02, -1.0366e-01,  1.3283e-02, -8.8672e-02, -7.2885e-02,\n",
       "                        7.5584e-02, -6.5740e-02, -4.5476e-02, -6.4418e-04, -1.6621e-02,\n",
       "                        2.8777e-02,  5.5388e-02, -2.4594e-03,  1.3803e-01,  5.9595e-02,\n",
       "                       -2.1058e-02, -1.0755e-02, -2.6192e-02,  6.2032e-02, -2.9112e-02,\n",
       "                        6.2613e-02,  4.3366e-02, -3.2847e-02, -1.4824e-01,  5.1080e-02,\n",
       "                       -2.7017e-02, -1.0945e-02, -1.6089e-02, -7.2260e-02, -9.9954e-02,\n",
       "                       -5.4579e-02,  2.4893e-03, -4.7113e-02, -7.6885e-02, -3.9164e-02,\n",
       "                        1.4460e-02, -1.0531e-02,  4.3161e-02,  6.2215e-02,  3.9382e-02,\n",
       "                        9.5630e-03, -2.3302e-02, -5.7582e-02,  3.8557e-02,  6.3596e-03,\n",
       "                        3.1632e-02,  7.5489e-02, -2.5321e-02, -1.2295e-03, -5.0087e-02,\n",
       "                        4.4518e-02, -6.2538e-02,  1.0921e-01,  1.0507e-01,  1.4977e-02,\n",
       "                        5.7727e-02,  5.6544e-02, -7.8945e-02, -6.1886e-02, -5.6518e-02,\n",
       "                       -3.8697e-02, -5.9625e-02, -3.3002e-02, -4.4739e-03, -1.0834e-02,\n",
       "                        4.4843e-03,  7.0414e-02,  1.0810e-01,  1.0053e-01, -6.9940e-02,\n",
       "                        1.9896e-02, -6.7690e-02,  1.0590e-01,  2.8833e-02,  3.0381e-02,\n",
       "                        3.2739e-02,  7.4557e-02,  1.1954e-03, -6.2275e-04,  4.3520e-02,\n",
       "                       -9.9605e-03, -9.0352e-03, -1.1825e-02, -8.9557e-03, -4.6918e-02,\n",
       "                        1.0215e-02,  1.1442e-02, -6.0986e-02,  5.8801e-02,  3.9387e-02,\n",
       "                       -1.6204e-02, -2.0226e-02,  3.1966e-02, -5.9686e-02, -3.8626e-02,\n",
       "                       -3.4362e-02,  6.5968e-03, -6.1713e-02,  3.0558e-03, -4.5940e-02,\n",
       "                        3.5903e-02, -8.5241e-02,  1.5420e-02,  1.3131e-02, -2.0428e-02,\n",
       "                        4.2327e-02,  6.0903e-03,  1.0474e-02,  7.7697e-02, -7.3340e-03,\n",
       "                        1.4931e-02, -6.4286e-02, -7.8745e-03,  6.9540e-02,  2.7417e-02,\n",
       "                        1.0169e-02, -3.4776e-02, -6.9483e-02, -1.3036e-02, -1.2050e-02,\n",
       "                        2.2229e-02,  6.2485e-02, -5.7488e-02, -3.4291e-02, -4.4057e-02,\n",
       "                       -2.0669e-02, -2.8158e-02,  1.1206e-01, -1.1360e-02, -1.7807e-02,\n",
       "                       -5.4468e-03, -1.6853e-02, -8.6345e-03, -3.8503e-03,  5.8961e-02,\n",
       "                       -1.7273e-01,  6.2612e-02,  2.3121e-02,  6.5816e-02, -7.5908e-02,\n",
       "                       -6.2700e-02,  1.1601e-02,  2.2290e-02,  1.8460e-02,  5.1061e-02,\n",
       "                        7.0736e-02,  3.5553e-02,  7.9820e-02,  5.8483e-02, -5.3329e-02,\n",
       "                       -2.5997e-02, -6.9003e-02,  1.6017e-02,  4.2897e-02, -9.4873e-02,\n",
       "                       -1.1439e-04, -4.1690e-02, -9.2828e-02,  2.5838e-02,  4.5805e-02,\n",
       "                       -2.1896e-04, -5.6588e-02, -7.9738e-03,  1.0195e-01,  9.2310e-02,\n",
       "                        3.5655e-02,  2.2369e-02,  1.8139e-02], device='mps:0')),\n",
       "              ('transformer.h.2.attn.c_proj.weight',\n",
       "               tensor([[-0.0751,  0.0552, -0.0799,  ...,  0.0781, -0.0228, -0.0168],\n",
       "                       [-0.0635,  0.1250, -0.0121,  ..., -0.0186,  0.0206,  0.0488],\n",
       "                       [ 0.0864,  0.0874, -0.0071,  ..., -0.0112, -0.0950, -0.0332],\n",
       "                       ...,\n",
       "                       [-0.0768,  0.0982,  0.1098,  ..., -0.0635,  0.0207,  0.0322],\n",
       "                       [ 0.0500,  0.0119, -0.0583,  ..., -0.0555, -0.0096,  0.0402],\n",
       "                       [ 0.0088, -0.1014, -0.0604,  ...,  0.0314,  0.0212,  0.1594]],\n",
       "                      device='mps:0')),\n",
       "              ('transformer.h.2.attn.c_proj.bias',\n",
       "               tensor([-3.1481e-02, -7.0237e-02, -1.5265e-02,  4.9983e-03,  1.1522e-01,\n",
       "                       -1.9567e-01, -9.1739e-02,  5.7451e-02, -8.4420e-02,  7.9658e-02,\n",
       "                        2.6805e-02,  4.9275e-02,  8.1306e-02, -6.0985e-02,  1.1830e-02,\n",
       "                        2.0718e-02, -4.5775e-02, -3.6881e-02, -1.2750e-02,  2.1045e-03,\n",
       "                       -2.1745e-02, -1.3095e-02,  3.7148e-02, -4.7656e-02, -5.6571e-02,\n",
       "                        7.6831e-02, -7.3384e-02,  1.6374e-01,  7.4235e-02,  7.9565e-02,\n",
       "                        7.6693e-02,  7.3067e-02,  4.4193e-03, -8.3324e-02, -3.0493e-02,\n",
       "                       -2.1567e-02,  6.8979e-02,  5.7070e-02,  6.4190e-02,  7.0266e-02,\n",
       "                       -4.7624e-03, -1.3764e-02,  9.5639e-02,  7.7160e-02,  2.9430e-02,\n",
       "                       -2.4180e-02,  1.2064e-01, -7.8045e-02,  4.9231e-02, -8.8432e-02,\n",
       "                       -1.3537e-02,  9.0322e-02, -2.1811e-02, -5.9545e-04,  6.3665e-02,\n",
       "                       -4.3754e-02, -2.7035e-02,  1.0178e-01, -2.5978e-02,  9.8781e-02,\n",
       "                        8.3589e-02, -1.0885e-01, -5.3109e-03,  2.2763e-02, -5.4251e-03,\n",
       "                        2.7034e-03,  6.7837e-02, -7.1172e-02, -2.1330e-02,  3.5385e-02,\n",
       "                        4.7992e-02,  1.4566e-02, -1.2690e-02, -9.5750e-03,  1.5016e-01,\n",
       "                       -1.5546e-02, -4.5739e-02,  1.5775e-01, -9.6733e-02,  1.8600e-03,\n",
       "                       -2.4257e-02,  1.1279e-02,  6.9064e-02,  6.8512e-02, -2.4392e-02,\n",
       "                       -1.7575e-03,  1.9067e-01, -8.8112e-02,  8.5298e-02,  3.0465e-02,\n",
       "                       -1.5559e-02, -6.0907e-02, -1.5308e-02, -8.6342e-02,  2.7784e-02,\n",
       "                       -8.2872e-02, -1.3189e-02,  4.7824e-02,  2.5050e-02, -1.7746e-02,\n",
       "                        1.7861e-02, -1.8369e-02, -1.3336e-02,  3.1740e-02,  7.6068e-02,\n",
       "                       -7.8538e-03, -1.1537e-02, -2.7378e-02, -3.3877e-02,  1.4324e-01,\n",
       "                        1.5070e-02,  4.8681e-02,  7.8362e-02, -1.4087e-01,  1.9236e-02,\n",
       "                       -3.1816e-03, -5.4780e-02,  3.2908e-02,  3.2485e-02, -9.3744e-02,\n",
       "                        7.3464e-02, -3.7239e-02, -6.6038e-02, -1.6411e-02,  1.1152e-01,\n",
       "                       -5.3241e-02,  8.4434e-02, -6.1075e-02, -7.2891e-02,  2.6325e-02,\n",
       "                       -6.6674e-02,  5.0360e-02, -5.0482e-02,  6.8115e-03, -3.2620e-02,\n",
       "                        1.8288e-02, -4.2115e-02,  7.0200e-02, -2.6154e-02, -4.8295e-02,\n",
       "                       -9.5397e-02, -3.8936e-02,  4.3926e-02,  3.5337e-02, -8.4958e-02,\n",
       "                        2.1878e-02,  2.1148e-02,  4.4839e-03, -3.6611e-02,  1.8487e-02,\n",
       "                       -2.8417e-02,  9.7102e-02, -2.7002e-02,  2.7559e-02, -8.6420e-02,\n",
       "                       -9.5335e-02, -4.1827e-02,  1.8949e-01,  1.0827e-03, -3.7506e-02,\n",
       "                        8.6134e-02, -2.4071e-02,  1.9758e-02,  3.5249e-04,  2.1274e-02,\n",
       "                       -1.7052e-02,  6.1772e-02, -5.6100e-02, -1.2133e-01, -7.5110e-02,\n",
       "                       -7.6376e-02, -5.0172e-02, -2.4435e-02,  5.6674e-02,  3.6766e-02,\n",
       "                        8.7844e-03, -5.7176e-02, -1.5098e-02, -1.2489e-01, -5.9009e-02,\n",
       "                        1.6881e-01,  8.6902e-02,  9.0524e-02,  7.9995e-02, -9.3089e-02,\n",
       "                       -1.0152e-01,  1.1202e-01,  5.9763e-02,  5.5479e-02, -4.4823e-02,\n",
       "                       -1.0141e-01, -1.0314e-01, -4.5596e-02,  3.4639e-02,  1.3707e-02,\n",
       "                       -8.9127e-03, -2.4346e-03, -3.9898e-02,  1.3956e-02,  5.5701e-03,\n",
       "                       -1.1121e-01,  1.4179e-03, -9.3918e-02, -1.1860e-01,  1.9790e-02,\n",
       "                       -1.3748e-01, -1.5813e-02, -6.9071e-02,  1.4248e-02,  5.2896e-02,\n",
       "                        7.9991e-02,  3.1316e-04,  4.8173e-03, -1.0563e-01, -8.6725e-02,\n",
       "                       -3.6031e-02,  1.1491e-02,  3.2437e-02, -7.5051e-02,  1.5142e-02,\n",
       "                        1.4400e-02,  8.1571e-02,  1.4408e-02,  8.7933e-02, -8.1181e-02,\n",
       "                       -2.6628e-02, -5.2354e-02,  1.1695e-02, -9.4630e-03, -3.5042e-02,\n",
       "                        7.9495e-02, -9.8869e-02,  7.0776e-02,  2.2378e-01, -8.1439e-02,\n",
       "                        1.2303e-02, -4.8270e-02,  4.8802e-02, -9.2253e-01, -1.0184e-01,\n",
       "                       -4.6053e-02, -1.6587e-02,  1.3343e-01,  3.5146e-02,  6.8973e-02,\n",
       "                       -4.5561e-02, -1.1582e-01,  5.0201e-03,  1.1878e-02, -1.6130e-02,\n",
       "                        6.7561e-02,  1.8797e-02, -3.2836e-02,  4.8908e-02,  7.9776e-02,\n",
       "                       -1.1156e-01], device='mps:0')),\n",
       "              ('transformer.h.2.ln_2.weight',\n",
       "               tensor([1.4401, 1.4783, 1.5110, 1.3876, 1.3848, 1.0262, 1.4442, 1.3621, 1.4094,\n",
       "                       1.2986, 1.3427, 1.3942, 1.3818, 1.4508, 1.4683, 1.3542, 1.4459, 1.4276,\n",
       "                       1.4265, 1.4242, 1.3763, 1.3798, 1.5045, 1.3787, 1.3593, 1.3456, 1.3959,\n",
       "                       1.3563, 1.3837, 1.5684, 1.3357, 1.3867, 1.3502, 1.4272, 1.3995, 1.3656,\n",
       "                       1.4818, 1.3916, 1.4220, 1.4023, 1.4927, 1.4377, 1.4365, 1.4275, 1.2240,\n",
       "                       1.4501, 1.3315, 1.3892, 1.4356, 1.4796, 1.3924, 1.2035, 1.3762, 1.4611,\n",
       "                       1.3608, 1.3736, 1.4535, 1.3546, 1.3393, 1.5142, 1.4775, 1.3251, 1.4192,\n",
       "                       1.4091, 1.4303, 1.4763, 1.4341, 1.4043, 1.3707, 1.3654, 1.4126, 1.3996,\n",
       "                       1.3991, 1.4535, 1.3934, 1.5045, 1.4094, 1.2508, 1.3380, 1.3468, 1.3746,\n",
       "                       1.5021, 1.4912, 1.5034, 1.4860, 1.4381, 1.3707, 1.5181, 1.4475, 1.4215,\n",
       "                       1.2896, 1.4189, 1.4833, 1.4698, 1.2708, 1.4482, 1.4332, 1.4656, 1.3337,\n",
       "                       1.3426, 1.3976, 1.4021, 1.3731, 1.3634, 1.3977, 1.4016, 1.3687, 1.3945,\n",
       "                       1.4960, 1.4182, 1.5584, 1.4187, 1.2020, 1.4056, 1.5206, 1.3818, 1.3958,\n",
       "                       1.4897, 1.3787, 1.4294, 1.3902, 1.4188, 1.3954, 1.4154, 1.4831, 1.3149,\n",
       "                       1.4093, 1.4504, 1.4063, 1.3212, 1.3472, 1.3272, 1.5145, 1.4912, 1.3612,\n",
       "                       1.4362, 1.4303, 1.3524, 1.5515, 1.2985, 1.3919, 1.3924, 1.5220, 1.4862,\n",
       "                       1.3702, 1.4601, 1.3504, 1.3916, 1.4252, 1.4827, 1.3536, 1.4078, 1.3863,\n",
       "                       1.4306, 1.4124, 1.3753, 1.2999, 1.5041, 1.5551, 1.3344, 1.4447, 1.4338,\n",
       "                       1.3611, 1.4321, 1.4551, 1.3596, 1.4953, 1.3798, 1.3122, 1.4552, 1.3856,\n",
       "                       1.3623, 1.2571, 1.4836, 1.3732, 1.4939, 1.3088, 1.5005, 1.2899, 1.3873,\n",
       "                       1.3005, 1.3371, 1.4121, 1.3983, 1.4545, 1.2913, 1.4620, 1.3100, 1.4467,\n",
       "                       1.3675, 1.4797, 1.4224, 1.4990, 1.4262, 1.4875, 1.3588, 1.3965, 1.3579,\n",
       "                       1.4765, 1.4035, 1.5253, 1.3988, 1.3732, 1.4819, 1.4372, 1.3902, 1.3845,\n",
       "                       1.4239, 1.4450, 1.3929, 1.1514, 1.2955, 1.4461, 1.5626, 1.3590, 1.3835,\n",
       "                       1.3788, 1.2482, 1.3039, 1.3285, 1.4109, 1.4291, 1.4053, 1.3672, 1.4249,\n",
       "                       1.4182, 1.4398, 1.3433, 1.4120, 1.2963, 1.4389, 1.3916, 1.4686, 1.4415,\n",
       "                       1.4358, 1.3743, 1.3124, 1.3702, 0.4127, 1.3603, 1.3738, 1.3258, 1.5277,\n",
       "                       1.1126, 1.4673, 1.3994, 1.3515, 1.3976, 1.4270, 1.3653, 1.5026, 1.4388,\n",
       "                       1.3773, 1.3436, 1.4479, 1.5298], device='mps:0')),\n",
       "              ('transformer.h.2.ln_2.bias',\n",
       "               tensor([ 0.0406, -0.2067, -0.0733,  0.0934,  0.1968,  0.1324, -0.1210,  0.0072,\n",
       "                        0.0060, -0.2061, -0.0112, -0.0997, -0.1040, -0.2112, -0.0293, -0.1339,\n",
       "                       -0.1055, -0.0176,  0.1494, -0.1431, -0.1037, -0.1673, -0.0417,  0.0735,\n",
       "                       -0.0489,  0.0820, -0.1146,  0.0914,  0.2121,  0.2533, -0.1880, -0.0717,\n",
       "                        0.2025,  0.0668,  0.1855, -0.1424,  0.1275,  0.1525,  0.3316,  0.1578,\n",
       "                       -0.0253,  0.0385,  0.0485,  0.0300, -0.1940,  0.0968,  0.1124,  0.0449,\n",
       "                        0.2318, -0.1195,  0.0683, -0.1694, -0.2121,  0.2050,  0.1884,  0.1650,\n",
       "                       -0.0529, -0.2447, -0.2483,  0.0480,  0.2273,  0.0083, -0.0808,  0.1405,\n",
       "                        0.1045,  0.0280, -0.0125,  0.1528,  0.1396,  0.2329,  0.3417, -0.0450,\n",
       "                       -0.0479,  0.0621, -0.1645, -0.0198,  0.0441, -0.1329, -0.0037,  0.1758,\n",
       "                        0.2971, -0.1320,  0.0157, -0.1518, -0.2177, -0.2028,  0.1153, -0.0566,\n",
       "                        0.1674,  0.3312,  0.1649,  0.1217, -0.1576, -0.0211, -0.2780, -0.0035,\n",
       "                       -0.1246,  0.0715, -0.0251, -0.2151, -0.1033, -0.0465,  0.0903, -0.0347,\n",
       "                        0.1619,  0.0483,  0.0743, -0.3039,  0.1910,  0.1066,  0.0287, -0.1671,\n",
       "                       -0.0757, -0.1227, -0.0792, -0.0426,  0.0351,  0.1448, -0.1294, -0.2690,\n",
       "                       -0.0895,  0.0507,  0.1086,  0.1218, -0.0106,  0.3092,  0.1844,  0.0447,\n",
       "                       -0.1633,  0.1389,  0.0923,  0.0819,  0.1556,  0.1565, -0.1409, -0.1142,\n",
       "                        0.0470,  0.1386, -0.0149, -0.0363, -0.1049, -0.0989,  0.2577, -0.1008,\n",
       "                        0.1310, -0.1359,  0.0442, -0.1961,  0.1718,  0.1463, -0.0309,  0.1172,\n",
       "                       -0.1434,  0.1422, -0.1746,  0.0410,  0.2145,  0.0751,  0.2281, -0.0169,\n",
       "                        0.0175,  0.0643,  0.1545,  0.0498,  0.0340, -0.2914, -0.1646, -0.1742,\n",
       "                        0.1477, -0.0968, -0.2460,  0.1648, -0.2872,  0.2075, -0.1173,  0.0415,\n",
       "                        0.1441, -0.1647,  0.0690, -0.1297,  0.2482,  0.2114,  0.1282, -0.2060,\n",
       "                        0.1533, -0.1318, -0.1981,  0.0321,  0.0970, -0.2013,  0.0317, -0.0435,\n",
       "                       -0.1709,  0.1040, -0.2435, -0.1417, -0.0397,  0.2749, -0.0084, -0.0995,\n",
       "                       -0.3530, -0.1823,  0.0347, -0.2626, -0.0571, -0.2274, -0.0112, -0.1045,\n",
       "                       -0.1142,  0.2430,  0.1699, -0.1950, -0.3233,  0.1936, -0.0436, -0.0109,\n",
       "                       -0.2041, -0.0696, -0.2399, -0.1845,  0.1743,  0.0865, -0.1729,  0.2016,\n",
       "                       -0.1313,  0.2049, -0.3284,  0.1665, -0.2487, -0.1580,  0.0164,  0.1417,\n",
       "                        0.0119,  0.0309,  0.0466,  0.0064, -0.1670,  0.0354,  0.4381,  0.0446,\n",
       "                        0.0985, -0.0618,  0.0905, -0.5299, -0.0504, -0.2560, -0.2747, -0.0716,\n",
       "                        0.0855,  0.1496,  0.2526, -0.0609, -0.0222,  0.1687, -0.2426, -0.1714],\n",
       "                      device='mps:0')),\n",
       "              ('transformer.h.2.mlp.c_fc.weight',\n",
       "               tensor([[ 0.0708,  0.0495, -0.0361,  ...,  0.0583,  0.1126,  0.0277],\n",
       "                       [ 0.0178,  0.0160, -0.0427,  ..., -0.1027, -0.0145, -0.0689],\n",
       "                       [ 0.0785,  0.1190, -0.0576,  ..., -0.0207,  0.1141,  0.0510],\n",
       "                       ...,\n",
       "                       [ 0.0846, -0.0084,  0.0428,  ..., -0.1330,  0.0471, -0.0595],\n",
       "                       [ 0.0650,  0.0496,  0.0730,  ..., -0.0481, -0.0254, -0.1227],\n",
       "                       [ 0.0280, -0.0179,  0.0202,  ...,  0.0277,  0.0078,  0.0346]],\n",
       "                      device='mps:0')),\n",
       "              ('transformer.h.2.mlp.c_fc.bias',\n",
       "               tensor([-0.1433, -0.0427, -0.0544,  ..., -0.1277, -0.0495,  0.1511],\n",
       "                      device='mps:0')),\n",
       "              ('transformer.h.2.mlp.c_proj.weight',\n",
       "               tensor([[-0.0324,  0.1030, -0.1755,  ..., -0.0121,  0.0895,  0.0894],\n",
       "                       [-0.0680, -0.0632,  0.0257,  ...,  0.0270,  0.0215, -0.0543],\n",
       "                       [-0.0935,  0.0334, -0.0066,  ...,  0.0783, -0.0709,  0.0620],\n",
       "                       ...,\n",
       "                       [ 0.0115, -0.0102, -0.1171,  ..., -0.0968,  0.0816, -0.0375],\n",
       "                       [-0.0505,  0.0170, -0.0792,  ...,  0.0017, -0.0567,  0.0072],\n",
       "                       [-0.0155, -0.0880,  0.0177,  ...,  0.0610,  0.0272,  0.0026]],\n",
       "                      device='mps:0')),\n",
       "              ('transformer.h.2.mlp.c_proj.bias',\n",
       "               tensor([ 1.0501e-02,  7.7580e-03, -7.5431e-02,  8.0999e-02,  1.0781e-02,\n",
       "                       -1.1324e-01, -4.8422e-02, -6.0015e-03,  3.6122e-02, -1.1110e-02,\n",
       "                        8.1615e-02, -1.5953e-02,  1.5277e-02,  1.9100e-02, -4.4448e-02,\n",
       "                        5.0466e-03,  4.1178e-02,  8.0355e-03, -1.2278e-02, -8.3136e-02,\n",
       "                       -7.4591e-02,  8.2146e-02, -5.9006e-02, -3.2010e-03,  4.7827e-02,\n",
       "                       -1.9240e-02, -9.2690e-03,  6.1285e-03, -1.8500e-02,  1.1075e-02,\n",
       "                       -4.5420e-02,  4.7587e-03,  6.9947e-02,  4.3859e-02,  5.2947e-02,\n",
       "                        5.1682e-02,  4.1067e-03,  2.5143e-02,  5.2433e-02,  1.5521e-02,\n",
       "                       -1.7822e-02, -7.6558e-03,  7.8246e-02, -4.4766e-02, -4.8085e-02,\n",
       "                       -6.9139e-02,  6.9887e-02, -4.6221e-03,  5.4837e-02, -4.4513e-03,\n",
       "                        1.4809e-01,  1.3909e-01, -2.7567e-02,  5.9020e-02,  7.0730e-02,\n",
       "                       -1.1325e-02,  4.2856e-02, -3.0948e-02,  4.0418e-02,  2.8999e-02,\n",
       "                        1.3163e-02,  8.6540e-02,  8.6702e-03,  2.1731e-02,  1.5944e-02,\n",
       "                        4.8700e-02, -1.0684e-02,  6.8251e-02, -6.0209e-02,  1.6901e-02,\n",
       "                        2.0192e-02,  3.2369e-03, -5.2232e-02,  5.0648e-02,  7.6562e-03,\n",
       "                       -8.0707e-03, -1.0998e-01, -1.6013e-02,  2.3523e-02, -4.9168e-03,\n",
       "                       -8.3696e-02,  7.6895e-03,  8.2241e-02,  4.6687e-02, -6.2975e-02,\n",
       "                       -3.2142e-02, -5.4649e-02, -4.2062e-02,  9.4252e-02,  2.8010e-02,\n",
       "                        9.2195e-02,  8.2355e-04, -6.4480e-02,  2.3608e-02, -4.9140e-02,\n",
       "                       -8.0925e-02,  2.5662e-02, -7.5484e-02, -6.4201e-02, -4.4794e-02,\n",
       "                        5.0471e-02, -2.1433e-02,  2.3637e-02, -1.1180e-02,  2.5772e-02,\n",
       "                        1.3656e-02, -3.1984e-02, -6.3058e-02,  1.3065e-02, -7.6226e-02,\n",
       "                       -4.8388e-02, -7.9597e-02,  5.5357e-03,  1.4587e-02,  6.8286e-03,\n",
       "                       -4.9071e-02,  1.0972e-01,  2.0865e-02,  2.2685e-03, -2.0980e-02,\n",
       "                       -4.4335e-02, -2.9025e-02,  2.5650e-02,  6.5891e-03,  1.2100e-04,\n",
       "                        5.9396e-02, -2.9949e-02,  8.8415e-02, -1.8131e-02,  3.1553e-03,\n",
       "                        1.1575e-02,  1.2134e-02,  2.6744e-02,  3.3576e-02, -1.8002e-02,\n",
       "                       -8.3812e-02,  8.1643e-02,  4.8946e-02, -3.5758e-02,  9.2822e-02,\n",
       "                       -3.4046e-02, -5.4945e-03,  8.4025e-02, -1.1881e-03, -4.5313e-02,\n",
       "                       -3.2030e-03, -4.1845e-02, -2.6616e-02, -4.2049e-02,  3.7375e-02,\n",
       "                        1.4273e-02,  1.7374e-02, -7.2783e-02,  1.7564e-02, -5.9109e-02,\n",
       "                        6.2192e-02,  4.5097e-02,  2.9740e-02,  7.9104e-02,  7.0662e-02,\n",
       "                        7.2660e-02, -3.7010e-02,  3.6160e-03, -3.6498e-02,  3.0691e-02,\n",
       "                       -3.8253e-02, -4.0255e-03, -2.4024e-02,  9.1240e-02,  7.8441e-02,\n",
       "                       -6.4819e-02,  8.7881e-03, -3.8304e-02,  2.9382e-02, -8.8184e-03,\n",
       "                        1.0023e-03, -7.3982e-02,  2.6460e-02, -5.3001e-02, -1.7997e-02,\n",
       "                        6.0684e-02, -2.4257e-03,  3.3213e-02, -5.1848e-02,  5.1335e-02,\n",
       "                       -6.7214e-02, -4.5375e-02,  7.9262e-02,  4.3897e-02, -8.2674e-02,\n",
       "                       -2.4101e-02, -3.7353e-02, -1.1201e-01, -4.6975e-03,  4.5203e-04,\n",
       "                       -2.1213e-02,  3.2174e-02, -3.2018e-02, -5.0347e-02, -6.0035e-03,\n",
       "                       -4.9658e-02, -4.6054e-03, -5.6575e-02, -6.7495e-03, -4.9820e-02,\n",
       "                       -2.9064e-02, -7.8034e-02, -8.5348e-02, -3.7210e-02,  2.5044e-02,\n",
       "                        6.4751e-02, -5.1463e-03, -6.4433e-02,  3.5463e-02, -3.8748e-02,\n",
       "                        1.6241e-02, -3.5254e-02, -1.0918e-02,  2.8632e-02, -8.0431e-03,\n",
       "                        2.2539e-02,  4.0135e-02, -3.1918e-02,  1.6329e-02, -2.7808e-02,\n",
       "                        1.3841e-01, -2.8115e-02,  4.4711e-02, -7.4167e-03, -1.3630e-02,\n",
       "                        7.8952e-02,  5.2664e-02, -5.5597e-02,  9.9962e-02,  2.2438e-02,\n",
       "                       -6.3718e-02,  6.9670e-02,  3.9380e-02,  1.5706e-01, -6.0430e-02,\n",
       "                       -4.5722e-02,  4.2865e-02, -1.5237e-02,  6.6482e-02,  7.8115e-02,\n",
       "                       -2.4681e-02, -1.3843e-02, -6.8736e-02, -5.1672e-02,  6.6679e-03,\n",
       "                       -2.3702e-02, -3.8635e-02,  5.1290e-02,  9.2436e-02,  2.0946e-02,\n",
       "                       -6.1627e-03], device='mps:0')),\n",
       "              ('transformer.ln_f.weight',\n",
       "               tensor([3.8022, 3.8545, 4.1284, 4.0762, 3.9356, 3.0069, 4.0333, 4.0074, 3.8766,\n",
       "                       3.7769, 3.8171, 4.0125, 3.8667, 3.9582, 3.9072, 3.9138, 3.9949, 3.6968,\n",
       "                       3.9745, 3.8870, 3.6747, 4.0586, 4.0624, 4.1628, 4.0331, 3.8968, 4.0532,\n",
       "                       3.6691, 3.9919, 4.1571, 3.8666, 4.0443, 3.9116, 3.8273, 3.9254, 3.8901,\n",
       "                       3.9750, 3.7980, 3.9489, 3.9241, 3.9909, 4.1304, 4.1167, 4.0407, 4.0365,\n",
       "                       3.9669, 3.7799, 3.9327, 4.1166, 4.1737, 3.8637, 3.3594, 3.9607, 3.9691,\n",
       "                       3.7920, 3.9975, 4.1607, 3.6816, 3.7958, 3.9674, 3.8056, 3.7602, 3.9804,\n",
       "                       3.6525, 3.9822, 4.0564, 3.8844, 3.9923, 4.0659, 4.0266, 3.9342, 3.8579,\n",
       "                       3.9351, 3.9434, 3.8698, 4.1025, 4.0503, 3.9896, 4.0488, 3.9703, 3.9567,\n",
       "                       3.9079, 3.9895, 4.0553, 3.9306, 4.0060, 3.7442, 4.1007, 4.0249, 3.9428,\n",
       "                       3.9689, 3.8963, 4.0657, 4.1286, 3.7588, 3.7374, 3.9619, 3.9828, 3.8020,\n",
       "                       3.9127, 3.9035, 3.8611, 3.8836, 3.9958, 4.1300, 3.9664, 3.7871, 3.8113,\n",
       "                       3.9292, 4.0932, 4.1044, 4.0274, 3.6048, 4.0209, 4.1504, 3.8546, 3.7878,\n",
       "                       4.0452, 4.0144, 4.0610, 3.9200, 3.9526, 3.7422, 3.9277, 4.0305, 3.8521,\n",
       "                       3.9780, 3.8433, 3.8884, 3.7833, 3.9730, 3.8623, 4.1472, 4.1335, 3.8669,\n",
       "                       4.0507, 3.8660, 3.4341, 4.2481, 3.9678, 4.0684, 4.0371, 3.9632, 4.1846,\n",
       "                       4.0027, 3.9622, 3.9054, 4.1190, 3.9601, 3.9053, 3.9314, 4.0380, 3.6088,\n",
       "                       4.0895, 4.0909, 4.0055, 3.8783, 4.0850, 4.0665, 3.8088, 4.1409, 4.0502,\n",
       "                       3.9118, 4.0842, 4.0544, 4.0304, 4.0780, 3.8959, 3.7013, 3.9863, 3.8794,\n",
       "                       3.8683, 3.4340, 4.0023, 3.9384, 4.1175, 4.1223, 4.0178, 3.8847, 4.0170,\n",
       "                       3.6781, 3.6597, 4.0644, 4.1422, 4.0187, 3.5637, 4.0010, 3.9719, 4.1094,\n",
       "                       3.9052, 3.9713, 3.9026, 4.1141, 4.0023, 3.8537, 3.9388, 4.1203, 3.9475,\n",
       "                       3.9013, 3.8406, 3.9683, 3.9466, 3.8926, 4.0728, 4.1180, 3.9477, 3.7936,\n",
       "                       4.0380, 4.0139, 3.9571, 2.9529, 3.8191, 3.9566, 4.0688, 3.9729, 3.8687,\n",
       "                       3.8578, 3.3058, 3.9229, 3.8943, 3.9373, 3.8785, 4.0388, 3.9563, 3.5756,\n",
       "                       4.0112, 3.8826, 3.8360, 3.7154, 3.7831, 3.9341, 3.8999, 3.7883, 3.7290,\n",
       "                       4.1018, 3.9060, 3.9071, 3.9572, 1.4031, 3.8470, 4.0883, 3.8607, 4.1696,\n",
       "                       2.9859, 3.9195, 3.9210, 3.6082, 3.9331, 3.7581, 3.9580, 4.1111, 4.2976,\n",
       "                       4.0273, 3.9618, 3.8646, 4.0742], device='mps:0')),\n",
       "              ('transformer.ln_f.bias',\n",
       "               tensor([-0.7324, -0.8034, -0.5550,  0.8682,  0.8317,  0.7026, -0.6801, -0.3049,\n",
       "                        0.6619, -0.8775, -0.3503, -0.6542, -0.7231, -0.6757,  0.7409, -0.8175,\n",
       "                       -0.7597,  0.1704,  0.5736, -0.9869, -0.6356, -0.3166, -0.5286,  0.4391,\n",
       "                       -0.7822,  0.5934, -0.6885,  0.8936,  0.7927,  0.4878, -0.7806, -0.7004,\n",
       "                        0.7261,  0.6769,  0.9230, -0.0128,  0.7872,  0.7512,  1.0101,  0.9388,\n",
       "                       -0.8863, -0.6356, -0.5374,  0.4303, -0.4318, -0.2590,  0.8357,  0.3919,\n",
       "                        0.6921, -0.6927,  0.6396, -0.7234, -0.8963,  0.7955,  0.6866,  0.8684,\n",
       "                       -0.4705, -0.8916, -0.5645, -0.4854,  0.6933,  0.9278, -0.7583,  0.9295,\n",
       "                        0.6523,  0.6169,  0.7728,  0.6752,  0.7455,  0.7004,  0.7783, -0.7521,\n",
       "                       -0.7742,  0.7262, -0.2555,  0.6998,  0.7296, -0.6854, -0.5756,  0.7271,\n",
       "                        0.5438, -0.8783,  0.8784, -0.5364, -0.6671, -0.8035,  0.7747, -0.6993,\n",
       "                        0.7790,  0.7269,  0.5546,  0.5301, -0.6246,  0.4427, -0.8680, -0.7227,\n",
       "                        0.5431,  0.6036, -0.8834, -0.8927, -0.8336, -0.8160,  0.6268, -0.9314,\n",
       "                        0.5441,  0.6090,  0.6598, -0.8564,  1.0100,  0.7360,  0.5124, -0.8227,\n",
       "                       -0.6903, -0.7934,  0.5768, -0.3744, -0.5668,  0.7295, -0.5320, -0.7493,\n",
       "                        0.4339,  0.5073,  0.8117,  0.6392, -0.6166,  0.6373,  0.6216,  0.9369,\n",
       "                       -0.7952,  0.6431,  0.7840,  0.9624,  0.6600,  0.6192, -0.5794, -0.7587,\n",
       "                        0.7707,  0.6844,  0.4723, -0.7771,  0.3144, -0.5933,  0.9131, -0.6629,\n",
       "                        0.6849, -0.7854,  0.6953, -0.6148,  0.7919,  0.8166, -0.4307,  0.7549,\n",
       "                       -0.5773,  0.6628, -1.0108,  0.8603,  0.7791,  0.7234,  0.7364,  0.4906,\n",
       "                        0.4590,  0.5795,  0.8084,  0.4243, -0.5887, -0.5137, -0.6771, -0.6919,\n",
       "                        0.8093,  0.6136, -0.8856,  0.8578, -0.6444,  1.0549, -0.6751,  0.8060,\n",
       "                        0.5996, -0.5775,  0.7402, -0.5693,  0.7502,  0.8048,  0.6813, -0.4922,\n",
       "                        0.7016, -0.6213, -0.2670,  0.6096,  0.6405, -0.3760, -0.7466,  0.5207,\n",
       "                       -0.5193,  0.5312, -0.6991, -0.7710, -0.5949,  0.7487, -0.8427, -0.7897,\n",
       "                       -1.0690,  0.4336, -0.7189, -0.6148, -0.8614, -0.8007, -0.5801, -0.7116,\n",
       "                       -0.1951,  0.7022,  0.6933, -0.8264, -0.8431,  0.7678,  0.5725, -0.3122,\n",
       "                       -0.6963, -0.9035, -0.7610, -0.7181, -0.6323,  0.7176, -0.6958,  0.7741,\n",
       "                       -0.7311,  0.8643, -0.6762,  0.8144, -0.7276, -0.6734, -0.4161,  0.9209,\n",
       "                       -0.7978,  0.9599, -0.7137,  0.4981, -0.4795,  0.8547,  1.6383, -0.3388,\n",
       "                        0.5878, -0.5003, -0.3730, -0.6260, -0.3599, -0.7777, -0.7856, -0.8368,\n",
       "                        0.4646,  0.6655,  0.6809, -0.7101,  0.8884,  0.7405, -0.7057, -0.8471],\n",
       "                      device='mps:0')),\n",
       "              ('lm_head.weight',\n",
       "               tensor([[-0.0798,  0.0386,  0.0366,  ...,  0.0552, -0.1121, -0.0635],\n",
       "                       [-0.1147, -0.0534, -0.0754,  ...,  0.0371, -0.0252, -0.0601],\n",
       "                       [-0.0950, -0.1011,  0.0130,  ..., -0.0467,  0.0059, -0.0047],\n",
       "                       ...,\n",
       "                       [-0.0793,  0.0227, -0.1568,  ...,  0.0597,  0.0132,  0.2156],\n",
       "                       [-0.0099,  0.0331,  0.1773,  ..., -0.0654,  0.1547, -0.0260],\n",
       "                       [ 0.1324,  0.1137,  0.0616,  ..., -0.0396,  0.1762,  0.0626]],\n",
       "                      device='mps:0'))]),\n",
       " 'epoch': 20}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(DEVICE)\n",
    "state_dict = torch.load('files/GPTe20.pth', map_location=DEVICE)\n",
    "state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1733226676489,
     "user": {
      "displayName": "Haihua Zhang",
      "userId": "02616694619268944742"
     },
     "user_tz": -480
    },
    "id": "7FNXydoon84m",
    "outputId": "106d63ee-e1dc-46e7-c134-94184269581d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 5.12M\n"
     ]
    }
   ],
   "source": [
    "num=sum(p.numel() for p in model.transformer.parameters())\n",
    "print(\"number of parameters: %.2fM\" % (num/1e6,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "jlAvmCLGn84m"
   },
   "outputs": [],
   "source": [
    "# lr = .0001\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1733226680806,
     "user": {
      "displayName": "Haihua Zhang",
      "userId": "02616694619268944742"
     },
     "user_tz": -480
    },
    "id": "xI81SF6en84m",
    "outputId": "a5e33574-3af6-41f6-9bd0-cc559a15d33d"
   },
   "outputs": [],
   "source": [
    "# model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3V1QCWlnn84m"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bvujm4Zen84m",
    "outputId": "632688fe-0fb7-4d83-91eb-460508bab8c7"
   },
   "outputs": [],
   "source": [
    "# for i in range(1, 41):\n",
    "#     if i<= previous_epoch:\n",
    "#       continue\n",
    "#     tloss = 0\n",
    "#     loop = tqdm(loader, leave=False)\n",
    "#     for idx, (x, y) in enumerate(loop):\n",
    "#         x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "#         output = model(x)\n",
    "#         loss = loss_func(output.view(-1,output.size(-1)), y.view(-1))\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "#         optimizer.step()\n",
    "#         tloss += loss.item()\n",
    "#         loop.set_postfix(epoch=i, loss=tloss/(idx+1))\n",
    "#     torch.save(\n",
    "#      {'state_dict': model.state_dict(), 'epoch': i},\n",
    "#       f'/content/drive/MyDrive/models/train_GPTe.pth'\n",
    "#     )\n",
    "#     if i%10==0:\n",
    "#         torch.save(\n",
    "#             {'state_dict': model.state_dict(), 'epoch': i},\n",
    "#             f'/content/drive/MyDrive/models/GPTe{i}.pth'\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "lcorXpLwMwKd"
   },
   "outputs": [],
   "source": [
    "def sample(idx, weights, max_new_tokens, temperature=1.0, top_k=None):\n",
    "    model.eval()\n",
    "    model.load_state_dict(weights)\n",
    "    # keep track of the length of the original indexes\n",
    "    original_length=len(idx[0])\n",
    "    # add a fixed number of tokens to prompt\n",
    "    for _ in range(max_new_tokens):\n",
    "        # if the text is more than 1024 tokenx, trim it\n",
    "        if idx.size(1) <= config.block_size:\n",
    "            idx_cond = idx  \n",
    "        else:\n",
    "            idx_cond = idx[:, -config.block_size:]\n",
    "        # predict the logits for the index in sequence\n",
    "        logits = model(idx_cond.to(DEVICE))\n",
    "        # pluck the logits at the final step; apply temperature \n",
    "        logits = logits[:, -1, :] / temperature\n",
    "        # crop the logits to only the top k options\n",
    "        if top_k is not None:\n",
    "            v, _ = torch.topk(logits, top_k)\n",
    "            logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "        # apply softmax to get probabilities\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        idx_next=torch.multinomial(probs,num_samples=1)\n",
    "        idx = torch.cat((idx, idx_next.cpu()), dim=1)\n",
    "    # keep only new tokens\n",
    "    return idx[:, original_length:]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "OHEZ1yGgn84m"
   },
   "outputs": [],
   "source": [
    "UNK=word_to_int[\"UNK\"]\n",
    "def generate(prompt, weights, max_new_tokens, temperature=1.0,\n",
    "             top_k=None):\n",
    "    assert len(prompt)>0, \"prompt must contain at least one token\"\n",
    "    text=prompt.lower().replace(\"\\n\", \" \")\n",
    "    for x in punctuations:\n",
    "        text=text.replace(f\"{x}\", f\" {x} \")\n",
    "    text_tokenized=text.split() \n",
    "    idx=[word_to_int.get(w,UNK) for w in text_tokenized]\n",
    "    idx=torch.LongTensor(idx).unsqueeze(0)\n",
    "    # add a fixed number of tokens to prompt\n",
    "    idx=sample(idx, weights, max_new_tokens, temperature=1.0, top_k=None)\n",
    "    # convert indexes to text\n",
    "    tokens=[int_to_word[i] for i in idx.squeeze().numpy()] \n",
    "    text=\" \".join(tokens)\n",
    "    for x in '''”).:;!?,-‘’''':\n",
    "        text=text.replace(f\" {x}\", f\"{x}\") \n",
    "    for x in '''“(-‘’''':\n",
    "        text=text.replace(f\"{x} \", f\"{x}\")     \n",
    "    return prompt+\" \"+text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cognac. “you are already a glass of grappa?” “nay.” “i am very\n",
      "--------------------------------------------------\n",
      ". nor make it go easier. i do not want to think you will tell me.” “\n",
      "--------------------------------------------------\n",
      ". she could not tell. i paid for her. for a moment we were together. along both\n",
      "--------------------------------------------------\n",
      ",” anselmo said almost sadly. “he is an old man who is never a man as a\n",
      "--------------------------------------------------\n",
      "for the fish and the old man watched for a fish’s jumps but only heard the breaking of\n",
      "--------------------------------------------------\n",
      ", i should have an order to take that many things to read and write. what a man must\n",
      "--------------------------------------------------\n",
      "the rings that would release the levers on the hand grenades. he checked that the grenades, lashed on\n",
      "--------------------------------------------------\n",
      "and he said it was true. he was too good for them to be light the sun and an\n",
      "--------------------------------------------------\n",
      ",” i said. “and why did you fail inside the bar. she is a boy who\n",
      "--------------------------------------------------\n",
      "table. “very,” pilar said. “you are a gift to any man if you could\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt=\"UNK\"\n",
    "weights = torch.load('files/GPTe40.pth', map_location=DEVICE)['state_dict']\n",
    "for i in range(10):\n",
    "    torch.manual_seed(i)\n",
    "    print(generate(prompt,weights,max_new_tokens=20)[4:])\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mac-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
