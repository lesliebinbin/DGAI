{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EedyOTzQn84a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21000,
     "status": "ok",
     "timestamp": 1733226635585,
     "user": {
      "displayName": "Haihua Zhang",
      "userId": "02616694619268944742"
     },
     "user_tz": -480
    },
    "id": "yMbiTTseoOXH",
    "outputId": "16f0d760-942b-47a5-c7ba-8a6af0a3e64b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ax4EQKq5n84b"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "t6Xa4NHZn84b"
   },
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1733226641079,
     "user": {
      "displayName": "Haihua Zhang",
      "userId": "02616694619268944742"
     },
     "user_tz": -480
    },
    "id": "A8a5M9oun84c",
    "outputId": "184e11d8-c9cc-4e6f-ebde-0a567a47ab37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4_pV_2BTn84d"
   },
   "outputs": [],
   "source": [
    "with open(\"files/OldManAndSea.txt\",\"r\", encoding='utf-8-sig') as f:\n",
    "    text=f.read()\n",
    "text=list(text)    #A\n",
    "for i in range(len(text)):\n",
    "    if text[i]=='\"':\n",
    "        if text[i+1]==' ' or text[i+1]=='\\n':\n",
    "            text[i]='”'    #B\n",
    "        if text[i+1]!=' ' and text[i+1]!='\\n':\n",
    "            text[i]='“'    #C\n",
    "    if text[i]==\"'\":\n",
    "        if text[i-1]!=' ' and text[i-1]!='\\n':\n",
    "            text[i]='’'    #D\n",
    "text=\"\".join(text)    #E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RJ1acBl1n84e"
   },
   "outputs": [],
   "source": [
    "with open(\"files/ToWhomTheBellTolls.txt\",\"r\", encoding='utf-8-sig') as f:\n",
    "    text1=f.read()\n",
    "with open(\"files/FarewellToArms.txt\",\"r\", encoding='utf-8-sig') as f:\n",
    "    text2=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1733226641079,
     "user": {
      "displayName": "Haihua Zhang",
      "userId": "02616694619268944742"
     },
     "user_tz": -480
    },
    "id": "zt6tmqwYn84e",
    "outputId": "4ee40021-7093-4855-f677-8e4da992505a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He was an old man who fished alone in a skiff in the Gulf Stream and he\n",
      "had gone eighty-four days now without taking a fish.  In the first\n",
      "forty days a boy had been with him.  But after forty days without a\n",
      "fish the boy’s parents had told him that th\n"
     ]
    }
   ],
   "source": [
    "text=text+\" \"+text1+\" \"+text2\n",
    "with open(\"files/ThreeNovels.txt\",\"w\", encoding='utf-8-sig') as f:\n",
    "    f.write(text)\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1733226641079,
     "user": {
      "displayName": "Haihua Zhang",
      "userId": "02616694619268944742"
     },
     "user_tz": -480
    },
    "id": "HD0t4TUVn84f",
    "outputId": "0dfa5833-5958-4b57-f3df-1931d9be1a6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['“', '’', '‘', '.', ' ', '-', ',', '&', '!', ')', '”', ';', '?', ':', '(']\n",
      "10599\n"
     ]
    }
   ],
   "source": [
    "text=text.lower().replace(\"\\n\", \" \")\n",
    "chars=set(text.lower())\n",
    "punctuations=[i for i in chars if i.isalpha()==False\n",
    "and i.isdigit()==False]\n",
    "print(punctuations)\n",
    "for x in punctuations:\n",
    "    text=text.replace(f\"{x}\", f\" {x} \")\n",
    "text_tokenized=text.split()\n",
    "unique_tokens=set(text_tokenized)\n",
    "print(len(unique_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PkeUAs-Dn84g"
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fkOsfHoJn84h"
   },
   "outputs": [],
   "source": [
    "word_counts = Counter(text_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WBUTDN5Kn84h"
   },
   "outputs": [],
   "source": [
    "words = sorted(word_counts, key=word_counts.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "fu9HA-Iqn84h"
   },
   "outputs": [],
   "source": [
    "words.append(\"UNK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "sZQtUE_xn84h"
   },
   "outputs": [],
   "source": [
    "text_length=len(text_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1733226641580,
     "user": {
      "displayName": "Haihua Zhang",
      "userId": "02616694619268944742"
     },
     "user_tz": -480
    },
    "id": "aA2Swx1Dn84i",
    "outputId": "bb655cea-ea05-4a7d-ae72-500b0e9b2b59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364463"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1733226641580,
     "user": {
      "displayName": "Haihua Zhang",
      "userId": "02616694619268944742"
     },
     "user_tz": -480
    },
    "id": "ErR57AkOn84i",
    "outputId": "96aa253f-b923-4772-fbac-1ae875674edf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the text contains 364463 words\n",
      "there are 10600 unique tokens\n",
      "{'.': 0, 'the': 1, ',': 2, '“': 3, '”': 4, 'and': 5, 'i': 6, 'he': 7, 'to': 8, 'it': 9}\n",
      "{0: '.', 1: 'the', 2: ',', 3: '“', 4: '”', 5: 'and', 6: 'i', 7: 'he', 8: 'to', 9: 'it'}\n"
     ]
    }
   ],
   "source": [
    "ntokens=len(words)\n",
    "print(f\"the text contains {text_length} words\")\n",
    "print(f\"there are {ntokens} unique tokens\")\n",
    "word_to_int={v:k for k,v in enumerate(words)}\n",
    "int_to_word={v:k for k,v in word_to_int.items()}\n",
    "print({k:v for k,v in word_to_int.items() if k in words[:10]})\n",
    "print({k:v for k,v in int_to_word.items() if v in words[:10]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1733226641581,
     "user": {
      "displayName": "Haihua Zhang",
      "userId": "02616694619268944742"
     },
     "user_tz": -480
    },
    "id": "80WqkqwNn84i",
    "outputId": "04f681a4-7656-4682-9f74-9fef74ae3d36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'was', 'an', 'old', 'man', 'who', 'fished', 'alone', 'in', 'a', 'skiff', 'in', 'the', 'gulf', 'stream', 'and', 'he', 'had', 'gone', 'eighty']\n"
     ]
    }
   ],
   "source": [
    "print(text_tokenized[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "dnzqoUBLn84i"
   },
   "outputs": [],
   "source": [
    "wordidx=[word_to_int[w] for w in text_tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1733226641581,
     "user": {
      "displayName": "Haihua Zhang",
      "userId": "02616694619268944742"
     },
     "user_tz": -480
    },
    "id": "7Q2rHdESn84i",
    "outputId": "dc95365d-22e4-48d3-b9f4-5584873eb0da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 14, 99, 93, 63, 85, 3818, 311, 15, 11, 657, 15, 1, 2369, 514, 5, 7, 24, 220, 2016]\n"
     ]
    }
   ],
   "source": [
    "print([word_to_int[w] for w in text_tokenized[0:20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "kv3WugmKn84i"
   },
   "outputs": [],
   "source": [
    "seq_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Nrt4FQ1Fn84j"
   },
   "outputs": [],
   "source": [
    "xys = []\n",
    "for n in range(0, len(wordidx)-seq_length -1):\n",
    "    x = wordidx[n:n+seq_length]\n",
    "    y = wordidx[n+1:n+seq_length+1]\n",
    "    xys.append((torch.tensor(x), torch.tensor(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "rHk_63jhn84j"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "RhUQrtQ_n84j"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "batch_size=32\n",
    "loader = DataLoader(dataset=xys, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "4Jbgnc1sn84j"
   },
   "outputs": [],
   "source": [
    "x, y = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1733226671858,
     "user": {
      "displayName": "Haihua Zhang",
      "userId": "02616694619268944742"
     },
     "user_tz": -480
    },
    "id": "AdD4IACGn84j",
    "outputId": "321e50ad-6b1d-4668-bf7d-4ba7b54fc0f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1112,  734,   84,  ...,  208,   31,  432],\n",
       "        [   1, 1404,   15,  ...,   32,    7,  722],\n",
       "        [   3,  158,  412,  ...,    1,  617,   50],\n",
       "        ...,\n",
       "        [   8,  237,   17,  ...,    9,   21,   20],\n",
       "        [  89,   30,    0,  ...,    3,  105,  430],\n",
       "        [  49,   42,   12,  ...,    0,    4,    3]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1733226671858,
     "user": {
      "displayName": "Haihua Zhang",
      "userId": "02616694619268944742"
     },
     "user_tz": -480
    },
    "id": "y4g1Ra84n84j",
    "outputId": "adba0fa4-3595-472e-fce1-a88f4551a9f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 734,   84,   70,  ...,   31,  432,  665],\n",
       "        [1404,   15,    1,  ...,    7,  722,   19],\n",
       "        [ 158,  412, 2120,  ...,  617,   50,  703],\n",
       "        ...,\n",
       "        [ 237,   17,   51,  ...,   21,   20,   73],\n",
       "        [  30,    0,    3,  ...,  105,  430,   49],\n",
       "        [  42,   12,  167,  ...,    4,    3,   17]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Ms6zRSQGn84k"
   },
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return 0.5*x*(1.0+torch.tanh(np.sqrt(2.0/np.pi)* (x + 0.044715 * torch.pow(x, 3.0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "69vfzIJTn84k"
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.n_layer = 3\n",
    "        self.n_head = 4\n",
    "        self.n_embd = 256\n",
    "        self.vocab_size = ntokens\n",
    "        self.block_size = 128\n",
    "        self.embd_pdrop = 0.1\n",
    "        self.resid_pdrop = 0.1\n",
    "        self.attn_pdrop = 0.1\n",
    "config = Config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Qbsl2pmln84k"
   },
   "outputs": [],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
    "        self.attn_dropout = nn.Dropout(config.attn_pdrop)\n",
    "        self.resid_dropout = nn.Dropout(config.resid_pdrop)\n",
    "        self.register_buffer(\n",
    "            \"bias\",\n",
    "            torch.tril(torch.ones(config.block_size, config.block_size)).view(\n",
    "                1, 1, config.block_size, config.block_size\n",
    "            ),\n",
    "        )\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size()\n",
    "        q, k, v = self.c_attn(x).split(self.n_embd, dim=2)\n",
    "        hs = C // self.n_head\n",
    "        k = k.view(B, T, self.n_head, hs).transpose(1, 2)\n",
    "        q = q.view(B, T, self.n_head, hs).transpose(1, 2)\n",
    "        v = v.view(B, T, self.n_head, hs).transpose(1, 2)\n",
    "        att = (q @ k.transpose(-2, -1)) * (1.0 / np.sqrt(k.size(-1)))\n",
    "        att = att.masked_fill(self.bias[:, :, :T, :T] == 0, float(\"-inf\"))\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        att = self.attn_dropout(att)\n",
    "        y = att @ v\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        y = self.resid_dropout(self.c_proj(y))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "rWKY_g8pn84k"
   },
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
    "        self.mlp = nn.ModuleDict(\n",
    "            dict(\n",
    "                c_fc=nn.Linear(config.n_embd, 4 * config.n_embd),\n",
    "                c_proj=nn.Linear(4 * config.n_embd, config.n_embd),\n",
    "                act=GELU(),\n",
    "                dropout=nn.Dropout(config.resid_pdrop),\n",
    "            )\n",
    "        )\n",
    "        m = self.mlp\n",
    "        self.mlpf = lambda x: m.dropout(m.c_proj(m.act(m.c_fc(x))))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlpf(self.ln_2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "FVE1MLKen84k"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.block_size = config.block_size\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
    "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
    "            drop = nn.Dropout(config.embd_pdrop),\n",
    "            h = nn.ModuleList([Block(config)\n",
    "                               for _ in range(config.n_layer)]),\n",
    "            ln_f = nn.LayerNorm(config.n_embd),))\n",
    "        self.lm_head = nn.Linear(config.n_embd,\n",
    "                                 config.vocab_size, bias=False)\n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('c_proj.weight'):\n",
    "                torch.nn.init.normal_(p, mean=0.0,\n",
    "                  std=0.02/np.sqrt(2 * config.n_layer))\n",
    "    def forward(self, idx, targets=None):\n",
    "        b, t = idx.size()\n",
    "        pos = torch.arange(0,t,dtype=torch.long).unsqueeze(0).to(DEVICE)\n",
    "        tok_emb = self.transformer.wte(idx)\n",
    "        pos_emb = self.transformer.wpe(pos)\n",
    "        x = self.transformer.drop(tok_emb + pos_emb)\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "        x = self.transformer.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "UE9y7nBKn84l"
   },
   "outputs": [],
   "source": [
    "model = Model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4253,
     "status": "ok",
     "timestamp": 1733226676488,
     "user": {
      "displayName": "Haihua Zhang",
      "userId": "02616694619268944742"
     },
     "user_tz": -480
    },
    "id": "2DmOE0i5NSEQ",
    "outputId": "55147325-a851-4eee-e6c9-86c6c6c686b2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1733226676489,
     "user": {
      "displayName": "Haihua Zhang",
      "userId": "02616694619268944742"
     },
     "user_tz": -480
    },
    "id": "Uzmvxrzmn84l",
    "outputId": "b2376849-9b9a-4370-c80c-f2f397e0fd39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(10600, 256)\n",
       "    (wpe): Embedding(128, 256)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-2): 3 x Block(\n",
       "        (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=256, out_features=768, bias=True)\n",
       "          (c_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (c_proj): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=256, out_features=10600, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(DEVICE)\n",
    "# state_dict = torch.load('files/GPTe20.pth', map_location=DEVICE)\n",
    "# state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1733226676489,
     "user": {
      "displayName": "Haihua Zhang",
      "userId": "02616694619268944742"
     },
     "user_tz": -480
    },
    "id": "7FNXydoon84m",
    "outputId": "106d63ee-e1dc-46e7-c134-94184269581d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 5.12M\n"
     ]
    }
   ],
   "source": [
    "num=sum(p.numel() for p in model.transformer.parameters())\n",
    "print(\"number of parameters: %.2fM\" % (num/1e6,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "jlAvmCLGn84m"
   },
   "outputs": [],
   "source": [
    "lr = .0001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1733226680806,
     "user": {
      "displayName": "Haihua Zhang",
      "userId": "02616694619268944742"
     },
     "user_tz": -480
    },
    "id": "xI81SF6en84m",
    "outputId": "a5e33574-3af6-41f6-9bd0-cc559a15d33d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(10600, 256)\n",
       "    (wpe): Embedding(128, 256)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-2): 3 x Block(\n",
       "        (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=256, out_features=768, bias=True)\n",
       "          (c_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (c_proj): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (act): GELU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=256, out_features=10600, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3V1QCWlnn84m"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bvujm4Zen84m",
    "outputId": "632688fe-0fb7-4d83-91eb-460508bab8c7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 3121/11386 [01:55<04:51, 28.34it/s, epoch=1, loss=4.59] "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for i in range(1, 41):\n",
    "    tloss = 0\n",
    "    loop = tqdm(loader, leave=False)\n",
    "    for idx, (x, y) in enumerate(loop):\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        output = model(x)\n",
    "        loss = loss_func(output.view(-1,output.size(-1)), y.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        tloss += loss.item()\n",
    "        loop.set_postfix(epoch=i, loss=tloss/(idx+1))\n",
    "    torch.save(\n",
    "     {'state_dict': model.state_dict(), 'epoch': i},\n",
    "      f'files/models/train_GPTe.pth'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lcorXpLwMwKd"
   },
   "outputs": [],
   "source": [
    "def sample(idx, weights, max_new_tokens, temperature=1.0, top_k=None):\n",
    "    model.eval()\n",
    "    model.load_state_dict(weights)\n",
    "    # keep track of the length of the original indexes\n",
    "    original_length=len(idx[0])\n",
    "    # add a fixed number of tokens to prompt\n",
    "    for _ in range(max_new_tokens):\n",
    "        # if the text is more than 1024 tokenx, trim it\n",
    "        if idx.size(1) <= config.block_size:\n",
    "            idx_cond = idx  \n",
    "        else:\n",
    "            idx_cond = idx[:, -config.block_size:]\n",
    "        # predict the logits for the index in sequence\n",
    "        logits = model(idx_cond.to(DEVICE))\n",
    "        # pluck the logits at the final step; apply temperature \n",
    "        logits = logits[:, -1, :] / temperature\n",
    "        # crop the logits to only the top k options\n",
    "        if top_k is not None:\n",
    "            v, _ = torch.topk(logits, top_k)\n",
    "            logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "        # apply softmax to get probabilities\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        idx_next=torch.multinomial(probs,num_samples=1)\n",
    "        idx = torch.cat((idx, idx_next.cpu()), dim=1)\n",
    "    # keep only new tokens\n",
    "    return idx[:, original_length:]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OHEZ1yGgn84m"
   },
   "outputs": [],
   "source": [
    "UNK=word_to_int[\"UNK\"]\n",
    "def generate(prompt, weights, max_new_tokens, temperature=1.0,\n",
    "             top_k=None):\n",
    "    assert len(prompt)>0, \"prompt must contain at least one token\"\n",
    "    text=prompt.lower().replace(\"\\n\", \" \")\n",
    "    for x in punctuations:\n",
    "        text=text.replace(f\"{x}\", f\" {x} \")\n",
    "    text_tokenized=text.split() \n",
    "    idx=[word_to_int.get(w,UNK) for w in text_tokenized]\n",
    "    idx=torch.LongTensor(idx).unsqueeze(0)\n",
    "    # add a fixed number of tokens to prompt\n",
    "    idx=sample(idx, weights, max_new_tokens, temperature=1.0, top_k=None)\n",
    "    # convert indexes to text\n",
    "    tokens=[int_to_word[i] for i in idx.squeeze().numpy()] \n",
    "    text=\" \".join(tokens)\n",
    "    for x in '''”).:;!?,-‘’''':\n",
    "        text=text.replace(f\" {x}\", f\"{x}\") \n",
    "    for x in '''“(-‘’''':\n",
    "        text=text.replace(f\"{x} \", f\"{x}\")     \n",
    "    return prompt+\" \"+text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt=\"UNK\"\n",
    "weights = torch.load('files/GPTe40.pth', map_location=DEVICE)['state_dict']\n",
    "for i in range(10):\n",
    "    torch.manual_seed(i)\n",
    "    print(generate(prompt,weights,max_new_tokens=20)[4:])\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nvidia-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
